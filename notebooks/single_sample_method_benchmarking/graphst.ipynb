{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "364a9ebc-3e3c-4645-9049-a34bd084c8a8",
   "metadata": {},
   "source": [
    "# GraphST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c55227-147e-417f-b0dd-bb0b7f322930",
   "metadata": {},
   "source": [
    "- **Creator**: Sebastian Birk (<sebastian.birk@helmholtz-munich.de>).\n",
    "- **Affiliation:** Helmholtz Munich, Institute of Computational Biology (ICB), Talavera-LÃ³pez Lab\n",
    "- **Date of Creation:** 11.01.2023\n",
    "- **Date of Last Modification:** 23.08.2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbeec0fc-2605-4bd7-92f9-97b2bb62f4d9",
   "metadata": {},
   "source": [
    "- The GraphST source code is available at https://github.com/JinmiaoChenLab/GraphST.\n",
    "- The corresponding preprint is \"Long, Y. et al. DeepST: A versatile graph contrastive learning framework for spatially informed clustering, integration, and deconvolution of spatial transcriptomics. Preprint at https://doi.org/10.1101/2022.08.02.502407\".\n",
    "- The workflow of this notebook follows the tutorial from https://deepst-tutorials.readthedocs.io/en/latest/Tutorial%201_10X%20Visium.html.\n",
    "- The authors use raw counts as input to GraphST (stored in adata.X). Therefore, we also use raw counts.\n",
    "- To define the spatial neighborhood graph, the original GraphST paper uses the 3 nearest neighbors of a cell as neighbors and the union of all neighbors is used as final spatial neighborhood graph (the adjacency matrix is made symmetric). We use the same method but vary the number of neighbors between 4, 8, 12, 16 and 20."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7529cde5-be12-403b-a94c-07561774b86c",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faad87bd-fef5-4429-a175-d714c491ae76",
   "metadata": {},
   "source": [
    "### 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7f93960-c759-424f-8cb2-1d8698acae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scipy.sparse as sp\n",
    "import squidpy as sq\n",
    "import torch\n",
    "from GraphST import GraphST\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b5efa5-2052-4986-8ae5-89cfab018515",
   "metadata": {},
   "source": [
    "### 1.2 Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5c8b48a-ed5e-48b5-8c5c-c1de11493aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"graphst\"\n",
    "latent_key = f\"{model_name}_latent\"\n",
    "leiden_resolution = 0.3 # used for Leiden clustering of latent space\n",
    "random_seed = 0 # used for Leiden clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28adc110-0f41-4a71-9838-dc7f0687809a",
   "metadata": {},
   "source": [
    "### 1.3 Run Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "334b87ca-3387-4ba9-8567-84bc4754ff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.set_figure_params(figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ab6b302-1c0b-4937-8624-40629ada2e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get time of notebook execution for timestamping saved artifacts\n",
    "now = datetime.now()\n",
    "current_timestamp = now.strftime(\"%d%m%Y_%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85538952-006b-4b0b-a50c-fe7445ce22e2",
   "metadata": {},
   "source": [
    "### 1.4 Configure Paths and Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ddcc49c-ba22-4155-acd5-05b5b810e091",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_path = \"../../datasets/srt_data/gold/\"\n",
    "benchmarking_folder_path = \"../../artifacts/single_sample_method_benchmarking\"\n",
    "figure_folder_path = f\"../../figures\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d974cd00-eafa-4432-b172-fafc4058a619",
   "metadata": {},
   "source": [
    "## 3. GraphST Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ea5162-09ab-4c19-8ac8-b342218ed7db",
   "metadata": {},
   "source": [
    "### 2.1 Define Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e416f486-07fe-4218-be3d-141a2043b18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_graphst_models(dataset,\n",
    "                         cell_type_key,\n",
    "                         adata_new=None,\n",
    "                         n_start_run=1,\n",
    "                         n_end_run=8,\n",
    "                         n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16],\n",
    "                         plot_latent_umaps: bool=False):\n",
    "    # Configure figure folder path\n",
    "    dataset_figure_folder_path = f\"{figure_folder_path}/{dataset}/single_sample_method_benchmarking/\" \\\n",
    "                                 f\"{model_name}/{current_timestamp}\"\n",
    "    os.makedirs(dataset_figure_folder_path, exist_ok=True)\n",
    "    \n",
    "    # Create new adata to store results from training runs in storage-efficient way\n",
    "    if adata_new is None:\n",
    "        adata_original = sc.read_h5ad(data_folder_path + f\"{dataset}.h5ad\")\n",
    "        adata_new = sc.AnnData(sp.csr_matrix(\n",
    "            (adata_original.shape[0], adata_original.shape[1]),\n",
    "            dtype=np.float32))\n",
    "        adata_new.var_names = adata_original.var_names\n",
    "        adata_new.obs_names = adata_original.obs_names\n",
    "        adata_new.obs[\"cell_type\"] = adata_original.obs[cell_type_key].values\n",
    "        adata_new.obsm[\"spatial\"] = adata_original.obsm[\"spatial\"]\n",
    "        del(adata_original)\n",
    "\n",
    "    model_seeds = list(range(10))\n",
    "    for run_number, n_neighbors in zip(np.arange(n_start_run, n_end_run+1), n_neighbor_list):\n",
    "        # Load data\n",
    "        adata = sc.read_h5ad(data_folder_path + f\"{dataset}.h5ad\")\n",
    "\n",
    "        # Store raw counts in adata.X\n",
    "        adata.X = adata.layers[\"counts\"]\n",
    "        if \"log1p\" in adata.uns:\n",
    "            del(adata.uns[\"log1p\"])\n",
    "\n",
    "        # Compute spatial neighborhood graph\n",
    "        sq.gr.spatial_neighbors(adata,\n",
    "                                coord_type=\"generic\",\n",
    "                                spatial_key=\"spatial\",\n",
    "                                n_neighs=n_neighbors)\n",
    "        adata.obsm[\"graph_neigh\"] = adata.obsp[\"spatial_connectivities\"]\n",
    "        \n",
    "        # Make adjacency matrix symmetric\n",
    "        adata.obsm[\"adj\"] = adata.obsm[\"graph_neigh\"].maximum(\n",
    "            adata.obsm[\"graph_neigh\"].T)\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Define model\n",
    "        model = GraphST.GraphST(adata,\n",
    "                                device=device,\n",
    "                                random_seed=model_seeds[run_number-1])\n",
    "\n",
    "        # Train model\n",
    "        adata = model.train()\n",
    "        \n",
    "        # Measure time for model training\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        hours, rem = divmod(elapsed_time, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        print(f\"Duration of model training in run {run_number}: \"\n",
    "              f\"{int(hours)} hours, {int(minutes)} minutes and {int(seconds)} seconds.\")\n",
    "        adata_new.uns[f\"{model_name}_model_training_duration_run{run_number}\"] = (\n",
    "            elapsed_time)\n",
    "\n",
    "        if plot_latent_umaps:\n",
    "            # Use GraphST latent space for UMAP generation\n",
    "            sc.pp.neighbors(adata,\n",
    "                            use_rep=\"emb\",\n",
    "                            n_neighbors=n_neighbors)\n",
    "            sc.tl.umap(adata)\n",
    "            fig = sc.pl.umap(adata,\n",
    "                             color=[cell_type_key],\n",
    "                             title=\"Latent Space with Cell Types: GraphST\",\n",
    "                             return_fig=True)\n",
    "            fig.savefig(f\"{dataset_figure_folder_path}/latent_{model_name}\"\n",
    "                        f\"_cell_types_run{run_number}.png\",\n",
    "                        bbox_inches=\"tight\")\n",
    "\n",
    "            # Compute latent Leiden clustering\n",
    "            sc.tl.leiden(adata=adata,\n",
    "                         resolution=leiden_resolution,\n",
    "                         random_state=random_seed,\n",
    "                         key_added=f\"latent_graphst_leiden_{str(leiden_resolution)}\")\n",
    "\n",
    "            # Create subplot of latent Leiden cluster annotations in physical and latent space\n",
    "            fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(6, 12))\n",
    "            title = fig.suptitle(t=\"Latent and Physical Space with Leiden Clusters: GraphST\")\n",
    "            sc.pl.umap(adata=adata,\n",
    "                       color=[f\"latent_{model_name}_leiden_{str(leiden_resolution)}\"],\n",
    "                       title=f\"Latent Space with Leiden Clusters\",\n",
    "                       ax=axs[0],\n",
    "                       show=False)\n",
    "            sq.pl.spatial_scatter(adata=adata,\n",
    "                                  color=[f\"latent_{model_name}_leiden_{str(leiden_resolution)}\"],\n",
    "                                  title=f\"Physical Space with Leiden Clusters\",\n",
    "                                  shape=None,\n",
    "                                  ax=axs[1])\n",
    "\n",
    "            # Create and position shared legend\n",
    "            handles, labels = axs[0].get_legend_handles_labels()\n",
    "            lgd = fig.legend(handles, labels, bbox_to_anchor=(1.25, 0.9185))\n",
    "            axs[0].get_legend().remove()\n",
    "            axs[1].get_legend().remove()\n",
    "\n",
    "            # Adjust, save and display plot\n",
    "            plt.subplots_adjust(wspace=0, hspace=0.2)\n",
    "            fig.savefig(f\"{dataset_figure_folder_path}/latent_physical_comparison_\"\n",
    "                        f\"{model_name}_run{run_number}.png\",\n",
    "                        bbox_extra_artists=(lgd, title),\n",
    "                        bbox_inches=\"tight\")\n",
    "            plt.show()\n",
    "\n",
    "        adata_new.obsm[latent_key + f\"_run{run_number}\"] = adata.obsm[\"emb\"]\n",
    "\n",
    "        # Store intermediate adata to disk\n",
    "        adata_new.write(f\"{benchmarking_folder_path}/{dataset}_{model_name}.h5ad\")\n",
    "\n",
    "    # Store final adata to disk\n",
    "    adata_new.write(f\"{benchmarking_folder_path}/{dataset}_{model_name}.h5ad\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13028407-263e-4918-afb3-a38e6d9227ec",
   "metadata": {},
   "source": [
    "### 2.2 Train Models on Benchmarking Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b63fd7-1713-4bf9-a34a-9df809520c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run device. By default, the package is implemented on 'cpu'. It is recommended to use GPU.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_graphst_models(dataset=\"seqfish_mouse_organogenesis_embryo2\",\n",
    "                     cell_type_key=\"celltype_mapped_refined\",\n",
    "                     adata_new=None,\n",
    "                     n_start_run=1,\n",
    "                     n_end_run=8,\n",
    "                     n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ec784b-b5e6-4249-bd26-10eb317433f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run device. By default, the package is implemented on 'cpu'. It is recommended to use GPU.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for subsample_pct in [50, 25, 10, 5, 1]:\n",
    "    train_graphst_models(dataset=f\"seqfish_mouse_organogenesis_subsample_{subsample_pct}pct_embryo2\",\n",
    "                         cell_type_key=\"celltype_mapped_refined\",\n",
    "                         adata_new=None,\n",
    "                         n_start_run=1,\n",
    "                         n_end_run=8,\n",
    "                         n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e0b44ce1-0ee9-4b11-a8a5-9df3fd581d9e",
   "metadata": {},
   "source": [
    "# This does not work because of memory exhaustion\n",
    "# Tesla V100S-PCIE-32GB GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\") # way too slow\n",
    "\n",
    "train_graphst_models(dataset=\"nanostring_cosmx_human_nsclc_batch5\",\n",
    "                     cell_type_key=\"cell_type\",\n",
    "                     adata_new=None,\n",
    "                     n_start_run=1,\n",
    "                     n_end_run=8,\n",
    "                     n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5a1def-fea5-4145-94bd-1730098893ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run device. By default, the package is implemented on 'cpu'. It is recommended to use GPU.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for subsample_pct in [50, 25, 10, 5, 1]:\n",
    "    train_graphst_models(dataset=f\"nanostring_cosmx_human_nsclc_subsample_{subsample_pct}pct_batch5\",\n",
    "                         cell_type_key=\"cell_type\",\n",
    "                         adata_new=None,\n",
    "                         n_start_run=1,\n",
    "                         n_end_run=8,\n",
    "                         n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7d3daf1a-7a09-4c23-9c7e-8ac0c2a624cb",
   "metadata": {},
   "source": [
    "# This does not work because of memory exhaustion\n",
    "# Tesla V100S-PCIE-32GB GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\") # also exhausts 120GB CPU memory\n",
    "\n",
    "train_graphst_models(dataset=\"vizgen_merfish_mouse_liver\",\n",
    "                     cell_type_key=\"Cell_Type\",\n",
    "                     adata_new=None,\n",
    "                     n_start_run=1,\n",
    "                     n_end_run=8,\n",
    "                     n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19268ca8-4b5f-463e-a5f7-5dd9cda94eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run device. By default, the package is implemented on 'cpu'. It is recommended to use GPU.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for subsample_pct in [10, 5, 1]: # 50, 25 pct exhaust memory\n",
    "    train_graphst_models(dataset=f\"vizgen_merfish_mouse_liver_subsample_{subsample_pct}pct\",\n",
    "                         cell_type_key=\"Cell_Type\",\n",
    "                         adata_new=None,\n",
    "                         n_start_run=1,\n",
    "                         n_end_run=8,\n",
    "                         n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b61a33-8061-4b93-bbcc-f3ae48e1dba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run device. By default, the package is implemented on 'cpu'. It is recommended to use GPU.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_graphst_models(dataset=\"slideseqv2_mouse_hippocampus\",\n",
    "                     cell_type_key=\"cell_type\",\n",
    "                     adata_new=None,\n",
    "                     n_start_run=1,\n",
    "                     n_end_run=8,\n",
    "                     n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea8bf80-6f5c-4e87-805b-fb84c5a59b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run device. By default, the package is implemented on 'cpu'. It is recommended to use GPU.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 1 pct did not run: \"There are other near singularities as well\"\n",
    "for subsample_pct in [50, 25, 10, 5]:\n",
    "    train_graphst_models(dataset=f\"slideseqv2_mouse_hippocampus_subsample_{subsample_pct}pct\",\n",
    "                         cell_type_key=\"cell_type\",\n",
    "                         adata_new=None,\n",
    "                         n_start_run=1,\n",
    "                         n_end_run=8,\n",
    "                         n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeca6424-060d-43cd-8533-1201d4212ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
