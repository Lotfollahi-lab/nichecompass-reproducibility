{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "364a9ebc-3e3c-4645-9049-a34bd084c8a8",
   "metadata": {},
   "source": [
    "# expiMap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c55227-147e-417f-b0dd-bb0b7f322930",
   "metadata": {},
   "source": [
    "- **Creator**: Sebastian Birk (<sebastian.birk@helmholtz-munich.de>).\n",
    "- **Affiliation:** Helmholtz Munich, Institute of Computational Biology (ICB), Talavera-López Lab\n",
    "- **Date of Creation:** 05.01.2023\n",
    "- **Date of Last Modification:** 18.08.2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa669117-f347-4666-b112-8ea6669fd9e9",
   "metadata": {},
   "source": [
    "- The expiMap source code is available at https://github.com/theislab/scarches.\n",
    "- The corresponding preprint is \"Lotfollahi, M. et al. Biologically informed deep learning to infer gene program activity in single cells. bioRxiv 2022.02.05.479217 (2022) doi:10.1101/2022.02.05.479217\".\n",
    "- The workflow of this notebook follows the tutorial from https://scarches.readthedocs.io/en/latest/expimap_surgery_pipeline_basic.html.\n",
    "- We use a modified version of the NicheCompass gene program mask with only target genes as the gene program mask for expimap. The reasons are that it is relevant for cell communication, to improve comparability and since the expiMap method did not work well on this dataset with the reactome gene program used in the above cited tutorial.\n",
    "- The authors use raw counts as input to expiMap. Therefore, we also use raw counts (stored in adata.X)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7529cde5-be12-403b-a94c-07561774b86c",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faad87bd-fef5-4429-a175-d714c491ae76",
   "metadata": {},
   "source": [
    "### 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f93960-c759-424f-8cb2-1d8698acae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import gdown\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import scarches as sca\n",
    "import scipy.sparse as sp\n",
    "import squidpy as sq\n",
    "from nichecompass.utils import (add_gps_from_gp_dict_to_adata,\n",
    "                                extract_gp_dict_from_mebocost_es_interactions,\n",
    "                                extract_gp_dict_from_nichenet_lrt_interactions,\n",
    "                                extract_gp_dict_from_omnipath_lr_interactions,\n",
    "                                filter_and_combine_gp_dict_gps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b5efa5-2052-4986-8ae5-89cfab018515",
   "metadata": {},
   "source": [
    "### 1.2 Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c8b48a-ed5e-48b5-8c5c-c1de11493aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"expimap\"\n",
    "latent_key = f\"{model_name}_latent\"\n",
    "leiden_resolution = 0.5 # used for Leiden clustering of latent space\n",
    "random_seed = 0 # used for Leiden clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28adc110-0f41-4a71-9838-dc7f0687809a",
   "metadata": {},
   "source": [
    "### 1.3 Run Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334b87ca-3387-4ba9-8567-84bc4754ff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.set_figure_params(figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab6b302-1c0b-4937-8624-40629ada2e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get time of notebook execution for timestamping saved artifacts\n",
    "now = datetime.now()\n",
    "current_timestamp = now.strftime(\"%d%m%Y_%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85538952-006b-4b0b-a50c-fe7445ce22e2",
   "metadata": {},
   "source": [
    "### 1.4 Configure Paths and Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddcc49c-ba22-4155-acd5-05b5b810e091",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_path = \"../../datasets/srt_data/gold/\"\n",
    "benchmarking_folder_path = \"../../artifacts/single_sample_method_benchmarking\"\n",
    "figure_folder_path = f\"../../figures\"\n",
    "gp_data_folder_path = \"../../datasets/gp_data\" # gene program data\n",
    "ga_data_folder_path = \"../../datasets/ga_data\" # gene annotation data\n",
    "\n",
    "# Create required directories\n",
    "os.makedirs(gp_data_folder_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d974cd00-eafa-4432-b172-fafc4058a619",
   "metadata": {},
   "source": [
    "## 2. expiMap Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8791f7bf-e9f3-4384-9cef-2d6719d2d1fd",
   "metadata": {},
   "source": [
    "### 2.1 Prepare Gene Program Mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d721fdf-088a-4726-a10c-df7105c967bc",
   "metadata": {},
   "source": [
    "#### 2.1.1 Mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd3a336-6522-43f7-94c0-9eca6ddd489b",
   "metadata": {},
   "outputs": [],
   "source": [
    "species = \"mouse\"\n",
    "\n",
    "nichenet_lr_network_file_path = gp_data_folder_path + \\\n",
    "                                \"/nichenet_lr_network_v2_\" \\\n",
    "                                f\"{species}.csv\"\n",
    "nichenet_ligand_target_matrix_file_path = gp_data_folder_path + \\\n",
    "                                          \"/nichenet_ligand_target_matrix_\" \\\n",
    "                                          f\"v2_{species}.csv\"\n",
    "omnipath_lr_network_file_path = gp_data_folder_path + \\\n",
    "                                     \"/omnipath_lr_network.csv\"\n",
    "gene_orthologs_mapping_file_path = ga_data_folder_path + \\\n",
    "                                   \"/human_mouse_gene_orthologs.csv\"\n",
    "\n",
    "print(\"\\nPreparing the gene program mask...\")\n",
    "# OmniPath gene programs\n",
    "mouse_omnipath_gp_dict = extract_gp_dict_from_omnipath_lr_interactions(\n",
    "    species=species,\n",
    "    min_curation_effort=0,\n",
    "    load_from_disk=True,\n",
    "    save_to_disk=False,\n",
    "    lr_network_file_path=omnipath_lr_network_file_path,\n",
    "    gene_orthologs_mapping_file_path=gene_orthologs_mapping_file_path,\n",
    "    plot_gp_gene_count_distributions=False)\n",
    "\n",
    "# NicheNet gene programs\n",
    "mouse_nichenet_gp_dict = extract_gp_dict_from_nichenet_lrt_interactions(\n",
    "    species=species,\n",
    "    version=\"v2\",\n",
    "    keep_target_genes_ratio=1.0,\n",
    "    max_n_target_genes_per_gp=250,\n",
    "    load_from_disk=True,\n",
    "    save_to_disk=False,\n",
    "    lr_network_file_path=nichenet_lr_network_file_path,\n",
    "    ligand_target_matrix_file_path=nichenet_ligand_target_matrix_file_path,\n",
    "    gene_orthologs_mapping_file_path=gene_orthologs_mapping_file_path,\n",
    "    plot_gp_gene_count_distributions=False)\n",
    "\n",
    "# Combine gene programs into one dictionary\n",
    "mouse_combined_gp_dict = dict(mouse_omnipath_gp_dict)\n",
    "mouse_combined_gp_dict.update(mouse_nichenet_gp_dict)\n",
    "\n",
    "mouse_mebocost_gp_dict = extract_gp_dict_from_mebocost_es_interactions(\n",
    "    dir_path=f\"{gp_data_folder_path}/metabolite_enzyme_sensor_gps\",\n",
    "    species=species,\n",
    "    plot_gp_gene_count_distributions=False)\n",
    "\n",
    "mouse_combined_gp_dict.update(mouse_mebocost_gp_dict)\n",
    "    \n",
    "# Filter and combine gene programs\n",
    "mouse_combined_new_gp_dict = filter_and_combine_gp_dict_gps(\n",
    "    gp_dict=mouse_combined_gp_dict,\n",
    "    gp_filter_mode=\"subset\",\n",
    "    combine_overlap_gps=True,\n",
    "    overlap_thresh_source_genes=0.9,\n",
    "    overlap_thresh_target_genes=0.9,\n",
    "    overlap_thresh_genes=0.9,\n",
    "    verbose=False)\n",
    "\n",
    "print(\"Number of gene programs before filtering and combining: \"\n",
    "      f\"{len(mouse_combined_new_gp_dict)}.\")\n",
    "print(f\"Number of gene programs after filtering and combining: \"\n",
    "      f\"{len(mouse_combined_new_gp_dict)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69401d81-1893-4a20-a70b-6623778bb797",
   "metadata": {},
   "source": [
    "#### 2.1.2 Human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9460b8e-9247-44f9-9d85-54cb40c0f851",
   "metadata": {},
   "outputs": [],
   "source": [
    "species = \"human\"\n",
    "\n",
    "nichenet_lr_network_file_path = gp_data_folder_path + \\\n",
    "                                \"/nichenet_lr_network_v2_\" \\\n",
    "                                f\"{species}.csv\"\n",
    "nichenet_ligand_target_matrix_file_path = gp_data_folder_path + \\\n",
    "                                          \"/nichenet_ligand_target_matrix_\" \\\n",
    "                                          f\"v2_{species}.csv\"\n",
    "omnipath_lr_network_file_path = gp_data_folder_path + \\\n",
    "                                     \"/omnipath_lr_network.csv\"\n",
    "gene_orthologs_mapping_file_path = ga_data_folder_path + \\\n",
    "                                   \"/human_mouse_gene_orthologs.csv\"\n",
    "\n",
    "print(\"\\nPreparing the gene program mask...\")\n",
    "# OmniPath gene programs\n",
    "human_omnipath_gp_dict = extract_gp_dict_from_omnipath_lr_interactions(\n",
    "    species=species,\n",
    "    min_curation_effort=0,\n",
    "    load_from_disk=True,\n",
    "    save_to_disk=False,\n",
    "    lr_network_file_path=omnipath_lr_network_file_path,\n",
    "    gene_orthologs_mapping_file_path=gene_orthologs_mapping_file_path,\n",
    "    plot_gp_gene_count_distributions=False)\n",
    "\n",
    "# NicheNet gene programs\n",
    "human_nichenet_gp_dict = extract_gp_dict_from_nichenet_lrt_interactions(\n",
    "    species=species,\n",
    "    version=\"v2\",\n",
    "    keep_target_genes_ratio=1.0,\n",
    "    max_n_target_genes_per_gp=250,\n",
    "    load_from_disk=True,\n",
    "    save_to_disk=False,\n",
    "    lr_network_file_path=nichenet_lr_network_file_path,\n",
    "    ligand_target_matrix_file_path=nichenet_ligand_target_matrix_file_path,\n",
    "    gene_orthologs_mapping_file_path=gene_orthologs_mapping_file_path,\n",
    "    plot_gp_gene_count_distributions=False)\n",
    "\n",
    "# Combine gene programs into one dictionary\n",
    "human_combined_gp_dict = dict(human_omnipath_gp_dict)\n",
    "human_combined_gp_dict.update(human_nichenet_gp_dict)\n",
    "\n",
    "human_mebocost_gp_dict = extract_gp_dict_from_mebocost_es_interactions(\n",
    "    dir_path=f\"{gp_data_folder_path}/metabolite_enzyme_sensor_gps\",\n",
    "    species=species,\n",
    "    plot_gp_gene_count_distributions=False)\n",
    "\n",
    "human_combined_gp_dict.update(human_mebocost_gp_dict)\n",
    "    \n",
    "# Filter and combine gene programs\n",
    "human_combined_new_gp_dict = filter_and_combine_gp_dict_gps(\n",
    "    gp_dict=human_combined_gp_dict,\n",
    "    gp_filter_mode=\"subset\",\n",
    "    combine_overlap_gps=True,\n",
    "    overlap_thresh_source_genes=0.9,\n",
    "    overlap_thresh_target_genes=0.9,\n",
    "    overlap_thresh_genes=0.9,\n",
    "    verbose=False)\n",
    "\n",
    "print(\"Number of gene programs before filtering and combining: \"\n",
    "      f\"{len(human_combined_new_gp_dict)}.\")\n",
    "print(f\"Number of gene programs after filtering and combining: \"\n",
    "      f\"{len(human_combined_new_gp_dict)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df82c18e-4444-4e82-88d9-afc843f5e480",
   "metadata": {},
   "source": [
    "### 2.2 Define Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea39b0f-9c9a-459a-ba2e-c843802a8e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_expimap_models(dataset,\n",
    "                         gp_dict,\n",
    "                         cell_type_key,\n",
    "                         adata_new=None,\n",
    "                         n_start_run=1,\n",
    "                         n_end_run=8,\n",
    "                         n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16],\n",
    "                         plot_latent_umaps: bool=False):\n",
    "    \n",
    "    # Configure figure folder path\n",
    "    dataset_figure_folder_path = f\"{figure_folder_path}/{dataset}/method_benchmarking/expimap/{current_timestamp}\"\n",
    "    os.makedirs(dataset_figure_folder_path, exist_ok=True)\n",
    "    \n",
    "    # Create new adata to store results from training runs in storage-efficient way\n",
    "    if adata_new is None:\n",
    "        adata_original = sc.read_h5ad(data_folder_path + f\"{dataset}.h5ad\")\n",
    "        adata_new = sc.AnnData(sp.csr_matrix(\n",
    "            (adata_original.shape[0], adata_original.shape[1]),\n",
    "            dtype=np.float32))\n",
    "        adata_new.var_names = adata_original.var_names\n",
    "        adata_new.obs_names = adata_original.obs_names\n",
    "        adata_new.obs[\"cell_type\"] = adata_original.obs[cell_type_key].values\n",
    "        adata_new.obsm[\"spatial\"] = adata_original.obsm[\"spatial\"]\n",
    "        del(adata_original)\n",
    "    \n",
    "    model_seeds = list(range(10))\n",
    "    for run_number, n_neighbors in zip(np.arange(n_start_run, n_end_run+1), n_neighbor_list):\n",
    "        # n_neighbors is here only used for the latent neighbor graph construction used for\n",
    "        # UMAP generation and clustering as expiMap is not a spatial method\n",
    "        \n",
    "        # Load data\n",
    "        adata = sc.read_h5ad(data_folder_path + f\"{dataset}.h5ad\")\n",
    "        \n",
    "        # Store raw counts in optimized format in adata.X\n",
    "        adata.layers[\"counts\"] = adata.layers[\"counts\"].tocsr()\n",
    "        adata.X = adata.layers[\"counts\"]\n",
    "        \n",
    "        adata.obs[\"batch\"] == \"batch1\"  \n",
    "        \n",
    "        # Add the gene program dictionary as binary masks to the adata for model training\n",
    "        # Use only target genes from the NicheCompass gene program mask\n",
    "        add_gps_from_gp_dict_to_adata(\n",
    "            gp_dict=gp_dict,\n",
    "            adata=adata,\n",
    "            genes_uppercase=True,\n",
    "            gp_targets_mask_key=\"I\",\n",
    "            gp_sources_mask_key=\"_\",\n",
    "            gp_names_key=\"terms\",\n",
    "            min_genes_per_gp=1,\n",
    "            min_source_genes_per_gp=0,\n",
    "            min_target_genes_per_gp=0,\n",
    "            max_genes_per_gp=None,\n",
    "            max_source_genes_per_gp=None,\n",
    "            max_target_genes_per_gp=None)\n",
    "\n",
    "        # Determine dimensionality of hidden encoder\n",
    "        n_hidden_encoder = len(adata.uns[\"terms\"])\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Initialize model\n",
    "        intr_cvae = sca.models.EXPIMAP(adata=adata,\n",
    "                                       condition_key=\"batch\",\n",
    "                                       hidden_layer_sizes=[256, 256, 256],\n",
    "                                       recon_loss=\"nb\")\n",
    "\n",
    "        # Train model\n",
    "        early_stopping_kwargs = {\n",
    "            \"early_stopping_metric\": \"val_unweighted_loss\",\n",
    "            \"threshold\": 0,\n",
    "            \"patience\": 50,\n",
    "            \"reduce_lr\": True,\n",
    "            \"lr_patience\": 13,\n",
    "            \"lr_factor\": 0.1}\n",
    "        intr_cvae.train(\n",
    "            n_epochs=400,\n",
    "            alpha_epoch_anneal=100,\n",
    "            alpha=0.7,\n",
    "            alpha_kl=0.5,\n",
    "            weight_decay=0.,\n",
    "            early_stopping_kwargs=early_stopping_kwargs,\n",
    "            use_early_stopping=True,\n",
    "            monitor_only_val=False,\n",
    "            seed=model_seeds[run_number-1])\n",
    "\n",
    "        # Store latent representation\n",
    "        adata.obsm[latent_key] = intr_cvae.get_latent(mean=False, only_active=True)\n",
    "        \n",
    "        # Measure time for model training\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        hours, rem = divmod(elapsed_time, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        print(f\"Duration of model training in run {run_number}: {int(hours)} hours, {int(minutes)} minutes and {int(seconds)} seconds.\")\n",
    "        adata_new.uns[f\"{model_name}_model_training_duration_run{run_number}\"] = (\n",
    "            elapsed_time)\n",
    "\n",
    "        if plot_latent_umaps:\n",
    "            # Use expiMap latent space for UMAP generation\n",
    "            sc.pp.neighbors(adata,\n",
    "                            use_rep=latent_key,\n",
    "                            n_neighbors=n_neighbors)\n",
    "            sc.tl.umap(adata)\n",
    "            fig = sc.pl.umap(adata,\n",
    "                             color=[cell_type_key],\n",
    "                             title=\"Latent Space with Cell Types: expiMap\",\n",
    "                             return_fig=True)\n",
    "            fig.savefig(f\"{dataset_figure_folder_path}/latent_{model_name}\"\n",
    "                        f\"_cell_types_run{run_number}.png\",\n",
    "                        bbox_inches=\"tight\")\n",
    "\n",
    "            # Compute latent Leiden clustering\n",
    "            sc.tl.leiden(adata=adata,\n",
    "                         resolution=leiden_resolution,\n",
    "                         random_state=random_seed,\n",
    "                         key_added=f\"latent_{model_name}_leiden_{str(leiden_resolution)}\")\n",
    "\n",
    "            # Create subplot of latent Leiden cluster annotations in physical and latent space\n",
    "            fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(6, 12))\n",
    "            title = fig.suptitle(t=\"Latent and Physical Space with Leiden Clusters: expiMap\")\n",
    "            sc.pl.umap(adata=adata,\n",
    "                       color=[f\"latent_{model_name}_leiden_{str(leiden_resolution)}\"],\n",
    "                       title=f\"Latent Space with Leiden Clusters\",\n",
    "                       ax=axs[0],\n",
    "                       show=False)\n",
    "            sq.pl.spatial_scatter(adata=adata,\n",
    "                                  color=[f\"latent_{model_name}_leiden_{str(leiden_resolution)}\"],\n",
    "                                  title=f\"Physical Space with Leiden Clusters\",\n",
    "                                  shape=None,\n",
    "                                  ax=axs[1])\n",
    "\n",
    "            # Create and position shared legend\n",
    "            handles, labels = axs[0].get_legend_handles_labels()\n",
    "            lgd = fig.legend(handles, labels, bbox_to_anchor=(1.25, 0.9185))\n",
    "            axs[0].get_legend().remove()\n",
    "            axs[1].get_legend().remove()\n",
    "\n",
    "            # Adjust, save and display plot\n",
    "            plt.subplots_adjust(wspace=0, hspace=0.2)\n",
    "            fig.savefig(f\"{dataset_figure_folder_path}/latent_physical_comparison_\"\n",
    "                        f\"{model_name}_run{run_number}.png\",\n",
    "                        bbox_extra_artists=(lgd, title),\n",
    "                        bbox_inches=\"tight\")\n",
    "            plt.show()\n",
    "\n",
    "        # Store latent representation\n",
    "        adata_new.obsm[latent_key + f\"_run{run_number}\"] = adata.obsm[latent_key]\n",
    "\n",
    "        # Store intermediate adata to disk\n",
    "        adata_new.write(f\"{benchmarking_folder_path}/{dataset}_{model_name}4.h5ad\")\n",
    "\n",
    "    # Store final adata to disk\n",
    "    adata_new.write(f\"{benchmarking_folder_path}/{dataset}_{model_name}4.h5ad\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f25415-e54e-4d2e-a6e3-bd6f3eef0d72",
   "metadata": {},
   "source": [
    "### 2.3 Train Models on Benchmarking Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4db49c6-c78d-472f-9d4a-9fe22a948623",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_expimap_models(dataset=\"vizgen_merfish_mouse_liver\",\n",
    "                     gp_dict=mouse_combined_new_gp_dict,\n",
    "                     cell_type_key=\"Cell_Type\",\n",
    "                     adata_new=None,\n",
    "                     n_start_run=4,\n",
    "                     n_end_run=4,\n",
    "                     n_neighbor_list=[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7cd035-1727-4316-98f2-d8652f717699",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_expimap_models(dataset=\"seqfish_mouse_organogenesis_embryo2\",\n",
    "                     gp_dict=mouse_combined_new_gp_dict,\n",
    "                     cell_type_key=\"celltype_mapped_refined\",\n",
    "                     adata_new=None,\n",
    "                     n_start_run=1,\n",
    "                     n_end_run=8,\n",
    "                     n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1659054d-fa4b-4e42-807f-1ec2e0fba87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subsample_pct in [50, 25, 10, 5, 1]:\n",
    "    train_expimap_models(dataset=f\"seqfish_mouse_organogenesis_subsample_{subsample_pct}pct_embryo2\",\n",
    "                         gp_dict=mouse_combined_new_gp_dict,\n",
    "                         cell_type_key=\"celltype_mapped_refined\",\n",
    "                         adata_new=None,\n",
    "                         n_start_run=1,\n",
    "                         n_end_run=8,\n",
    "                         n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb5a9622-d5e9-49a4-aa2b-3cc26b801fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 2098 × 4000\n",
       "    obs: 'cell_type'\n",
       "    uns: 'expimap_model_training_duration_run1', 'expimap_model_training_duration_run2', 'expimap_model_training_duration_run3', 'expimap_model_training_duration_run4', 'expimap_model_training_duration_run5', 'expimap_model_training_duration_run6', 'expimap_model_training_duration_run7', 'expimap_model_training_duration_run8'\n",
       "    obsm: 'expimap_latent_run1', 'expimap_latent_run2', 'expimap_latent_run3', 'expimap_latent_run4', 'expimap_latent_run5', 'expimap_latent_run6', 'expimap_latent_run7', 'expimap_latent_run8', 'spatial'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a61a165-ad03-4422-b383-1b2d79218bf6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = '../../artifacts/single_sample_method_benchmarking/slideseqv2_mouse_hippocampus_subsample_1pct_expimap.h5ad', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m adata_new \u001b[38;5;241m=\u001b[39m \u001b[43msc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_h5ad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../../artifacts/single_sample_method_benchmarking/slideseqv2_mouse_hippocampus_subsample_1pct_expimap.h5ad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nichecompass-reproducibility/lib/python3.9/site-packages/anndata/_io/h5ad.py:219\u001b[0m, in \u001b[0;36mread_h5ad\u001b[0;34m(filename, backed, as_sparse, as_sparse_fmt, chunk_size)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    212\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrently only `X` and `raw/X` can be read as sparse.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    213\u001b[0m         )\n\u001b[1;32m    215\u001b[0m rdasp \u001b[38;5;241m=\u001b[39m partial(\n\u001b[1;32m    216\u001b[0m     read_dense_as_sparse, sparse_format\u001b[38;5;241m=\u001b[39mas_sparse_fmt, axis_chunk\u001b[38;5;241m=\u001b[39mchunk_size\n\u001b[1;32m    217\u001b[0m )\n\u001b[0;32m--> 219\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcallback\u001b[39m(func, elem_name: \u001b[38;5;28mstr\u001b[39m, elem, iospec):\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m iospec\u001b[38;5;241m.\u001b[39mencoding_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manndata\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m elem_name\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/nichecompass-reproducibility/lib/python3.9/site-packages/h5py/_hl/files.py:567\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    558\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    559\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    560\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    561\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    562\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    563\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    564\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    565\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    566\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 567\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m~/miniconda3/envs/nichecompass-reproducibility/lib/python3.9/site-packages/h5py/_hl/files.py:231\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    230\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 231\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    233\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:106\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = '../../artifacts/single_sample_method_benchmarking/slideseqv2_mouse_hippocampus_subsample_1pct_expimap.h5ad', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "adata_new = sc.read_h5ad(\"../../artifacts/single_sample_method_benchmarking/slideseqv2_mouse_hippocampus_subsample_1pct_expimap.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e5f46fb-6527-4f6b-a42b-d272ffad1f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INITIALIZING NEW NETWORK..............\n",
      "Encoder Architecture:\n",
      "\tInput Layer in, out and cond: 4000 256 1\n",
      "\tHidden Layer 1 in/out: 256 256\n",
      "\tHidden Layer 2 in/out: 256 256\n",
      "\tMean/Var Layer in/out: 256 1519\n",
      "Decoder Architecture:\n",
      "\tMasked linear layer in, ext_m, ext, cond, out:  1519 0 0 1 4000\n",
      "\twith hard mask.\n",
      "Last Decoder layer: softmax\n",
      "Preparing (388, 4000)\n",
      "Instantiating dataset\n",
      "Init the group lasso proximal operator for the main terms.\n",
      " |████████████████----| 80.8%  - epoch_loss: 305.7067159017 - epoch_recon_loss: 290.5423482259 - epoch_kl_loss: 30.3287359873 - val_loss: 264.4175720215 - val_recon_loss: 253.8696746826 - val_kl_loss: 21.09581947334\n",
      "ADJUSTED LR\n",
      " |█████████████████---| 88.2%  - epoch_loss: 314.2516886393 - epoch_recon_loss: 299.4213460286 - epoch_kl_loss: 29.6606839498 - val_loss: 264.2754211426 - val_recon_loss: 253.4388427734 - val_kl_loss: 21.6731624603\n",
      "ADJUSTED LR\n",
      " |██████████████████--| 91.5%  - epoch_loss: 306.0850219727 - epoch_recon_loss: 291.2105712891 - epoch_kl_loss: 29.7489039103 - val_loss: 263.1822509766 - val_recon_loss: 252.4455718994 - val_kl_loss: 21.4733543396\n",
      "ADJUSTED LR\n",
      " |███████████████████-| 95.5%  - epoch_loss: 303.7466125488 - epoch_recon_loss: 289.2620646159 - epoch_kl_loss: 28.9690774282 - val_loss: 262.7971496582 - val_recon_loss: 252.0451354980 - val_kl_loss: 21.5040149689\n",
      "ADJUSTED LR\n",
      " |███████████████████-| 98.8%  - epoch_loss: 301.4266866048 - epoch_recon_loss: 286.3922932943 - epoch_kl_loss: 30.0687808990 - val_loss: 262.7398986816 - val_recon_loss: 251.9863281250 - val_kl_loss: 21.5071315765\n",
      "ADJUSTED LR\n",
      " |████████████████████| 100.0%  - epoch_loss: 297.0226440430 - epoch_recon_loss: 282.4521077474 - epoch_kl_loss: 29.1410668691 - val_loss: 262.9718322754 - val_recon_loss: 252.2182312012 - val_kl_loss: 21.5072154999\n",
      "Saving best state of network...\n",
      "Best State was in Epoch 367\n",
      "Duration of model training in run 1: 0 hours, 0 minutes and 24 seconds.\n",
      "\n",
      "INITIALIZING NEW NETWORK..............\n",
      "Encoder Architecture:\n",
      "\tInput Layer in, out and cond: 4000 256 1\n",
      "\tHidden Layer 1 in/out: 256 256\n",
      "\tHidden Layer 2 in/out: 256 256\n",
      "\tMean/Var Layer in/out: 256 1519\n",
      "Decoder Architecture:\n",
      "\tMasked linear layer in, ext_m, ext, cond, out:  1519 0 0 1 4000\n",
      "\twith hard mask.\n",
      "Last Decoder layer: softmax\n",
      "Preparing (388, 4000)\n",
      "Instantiating dataset\n",
      "Init the group lasso proximal operator for the main terms.\n",
      " |██████████████████--| 90.0%  - epoch_loss: 310.8898111979 - epoch_recon_loss: 297.7730305990 - epoch_kl_loss: 26.2335720062 - val_loss: 255.4274139404 - val_recon_loss: 246.5141601562 - val_kl_loss: 17.82650947576\n",
      "ADJUSTED LR\n",
      " |███████████████████-| 95.0%  - epoch_loss: 299.3856099447 - epoch_recon_loss: 286.8030192057 - epoch_kl_loss: 25.1651560465 - val_loss: 253.1731872559 - val_recon_loss: 244.6223754883 - val_kl_loss: 17.1016387939\n",
      "ADJUSTED LR\n",
      " |███████████████████-| 98.2%  - epoch_loss: 303.6088256836 - epoch_recon_loss: 290.5032450358 - epoch_kl_loss: 26.2111721039 - val_loss: 252.5849914551 - val_recon_loss: 243.8906555176 - val_kl_loss: 17.3886775970\n",
      "ADJUSTED LR\n",
      " |████████████████████| 100.0%  - epoch_loss: 292.8110555013 - epoch_recon_loss: 279.9465738932 - epoch_kl_loss: 25.7289562225 - val_loss: 254.4492645264 - val_recon_loss: 245.7557067871 - val_kl_loss: 17.3871040344\n",
      "Saving best state of network...\n",
      "Best State was in Epoch 365\n",
      "Duration of model training in run 2: 0 hours, 0 minutes and 24 seconds.\n",
      "\n",
      "INITIALIZING NEW NETWORK..............\n",
      "Encoder Architecture:\n",
      "\tInput Layer in, out and cond: 4000 256 1\n",
      "\tHidden Layer 1 in/out: 256 256\n",
      "\tHidden Layer 2 in/out: 256 256\n",
      "\tMean/Var Layer in/out: 256 1519\n",
      "Decoder Architecture:\n",
      "\tMasked linear layer in, ext_m, ext, cond, out:  1519 0 0 1 4000\n",
      "\twith hard mask.\n",
      "Last Decoder layer: softmax\n",
      "Preparing (388, 4000)\n",
      "Instantiating dataset\n",
      "Init the group lasso proximal operator for the main terms.\n",
      " |████████████--------| 61.8%  - epoch_loss: 319.0267232259 - epoch_recon_loss: 304.3416442871 - epoch_kl_loss: 29.3701553345 - val_loss: 270.9399108887 - val_recon_loss: 259.9615478516 - val_kl_loss: 21.95670700079\n",
      "ADJUSTED LR\n",
      " |█████████████-------| 66.8%  - epoch_loss: 315.4815673828 - epoch_recon_loss: 301.0947570801 - epoch_kl_loss: 28.7736396790 - val_loss: 270.9852905273 - val_recon_loss: 260.1171875000 - val_kl_loss: 21.7361850739\n",
      "ADJUSTED LR\n",
      " |██████████████------| 73.8%  - epoch_loss: 311.7387797038 - epoch_recon_loss: 297.4867146810 - epoch_kl_loss: 28.5041370392 - val_loss: 271.9993591309 - val_recon_loss: 261.2477416992 - val_kl_loss: 21.5032329559\n",
      "ADJUSTED LR\n",
      " |███████████████-----| 77.0%  - epoch_loss: 311.9326273600 - epoch_recon_loss: 297.5657552083 - epoch_kl_loss: 28.7337354024 - val_loss: 270.5411987305 - val_recon_loss: 259.7925720215 - val_kl_loss: 21.4972515106\n",
      "ADJUSTED LR\n",
      " |████████████████----| 80.2%  - epoch_loss: 322.6198832194 - epoch_recon_loss: 308.1789042155 - epoch_kl_loss: 28.8819554647 - val_loss: 270.1015625000 - val_recon_loss: 259.3528442383 - val_kl_loss: 21.4974479675\n",
      "ADJUSTED LR\n",
      " |████████████████----| 83.0%  - epoch_loss: 318.1540425618 - epoch_recon_loss: 303.9440612793 - epoch_kl_loss: 28.4199536641 - val_loss: 271.4169311523 - val_recon_loss: 260.6681823730 - val_kl_loss: 21.4975013733\n",
      "Stopping early: no improvement of more than 0 nats in 50 epochs\n",
      "If the early stopping criterion is too strong, please instantiate it with different parameters in the train method.\n",
      "Saving best state of network...\n",
      "Best State was in Epoch 280\n",
      "Duration of model training in run 3: 0 hours, 0 minutes and 20 seconds.\n",
      "\n",
      "INITIALIZING NEW NETWORK..............\n",
      "Encoder Architecture:\n",
      "\tInput Layer in, out and cond: 4000 256 1\n",
      "\tHidden Layer 1 in/out: 256 256\n",
      "\tHidden Layer 2 in/out: 256 256\n",
      "\tMean/Var Layer in/out: 256 1519\n",
      "Decoder Architecture:\n",
      "\tMasked linear layer in, ext_m, ext, cond, out:  1519 0 0 1 4000\n",
      "\twith hard mask.\n",
      "Last Decoder layer: softmax\n",
      "Preparing (388, 4000)\n",
      "Instantiating dataset\n",
      "Init the group lasso proximal operator for the main terms.\n",
      " |█████████████████---| 85.8%  - epoch_loss: 302.3538818359 - epoch_recon_loss: 289.1894632975 - epoch_kl_loss: 26.3288345337 - val_loss: 261.6828002930 - val_recon_loss: 252.7582244873 - val_kl_loss: 17.84916877752\n",
      "ADJUSTED LR\n",
      " |██████████████████--| 91.8%  - epoch_loss: 306.5311279297 - epoch_recon_loss: 294.3047281901 - epoch_kl_loss: 24.4528090159 - val_loss: 259.2428283691 - val_recon_loss: 250.4286651611 - val_kl_loss: 17.6283226013\n",
      "ADJUSTED LR\n",
      " |███████████████████-| 95.0%  - epoch_loss: 303.4898986816 - epoch_recon_loss: 290.1978759766 - epoch_kl_loss: 26.5840479533 - val_loss: 259.8588867188 - val_recon_loss: 251.0120239258 - val_kl_loss: 17.6937217712\n",
      "ADJUSTED LR\n",
      " |████████████████████| 100.0%  - epoch_loss: 298.6517130534 - epoch_recon_loss: 285.5033060710 - epoch_kl_loss: 26.2968184153 - val_loss: 259.1011657715 - val_recon_loss: 250.2518005371 - val_kl_loss: 17.6987209320\n",
      "Saving best state of network...\n",
      "Best State was in Epoch 395\n",
      "Duration of model training in run 4: 0 hours, 0 minutes and 25 seconds.\n",
      "\n",
      "INITIALIZING NEW NETWORK..............\n",
      "Encoder Architecture:\n",
      "\tInput Layer in, out and cond: 4000 256 1\n",
      "\tHidden Layer 1 in/out: 256 256\n",
      "\tHidden Layer 2 in/out: 256 256\n",
      "\tMean/Var Layer in/out: 256 1519\n",
      "Decoder Architecture:\n",
      "\tMasked linear layer in, ext_m, ext, cond, out:  1519 0 0 1 4000\n",
      "\twith hard mask.\n",
      "Last Decoder layer: softmax\n",
      "Preparing (388, 4000)\n",
      "Instantiating dataset\n",
      "Init the group lasso proximal operator for the main terms.\n",
      " |███████████████████-| 97.2%  - epoch_loss: 306.4742329915 - epoch_recon_loss: 291.4864298503 - epoch_kl_loss: 29.9756100972 - val_loss: 263.7538146973 - val_recon_loss: 252.8850555420 - val_kl_loss: 21.73749923717\n",
      "ADJUSTED LR\n",
      " |████████████████████| 100.0%  - epoch_loss: 296.2195536296 - epoch_recon_loss: 281.3476359049 - epoch_kl_loss: 29.7438309987 - val_loss: 262.1904602051 - val_recon_loss: 251.4675750732 - val_kl_loss: 21.4457569122\n",
      "Saving best state of network...\n",
      "Best State was in Epoch 392\n",
      "Duration of model training in run 5: 0 hours, 0 minutes and 24 seconds.\n",
      "\n",
      "INITIALIZING NEW NETWORK..............\n",
      "Encoder Architecture:\n",
      "\tInput Layer in, out and cond: 4000 256 1\n",
      "\tHidden Layer 1 in/out: 256 256\n",
      "\tHidden Layer 2 in/out: 256 256\n",
      "\tMean/Var Layer in/out: 256 1519\n",
      "Decoder Architecture:\n",
      "\tMasked linear layer in, ext_m, ext, cond, out:  1519 0 0 1 4000\n",
      "\twith hard mask.\n",
      "Last Decoder layer: softmax\n",
      "Preparing (388, 4000)\n",
      "Instantiating dataset\n",
      "Init the group lasso proximal operator for the main terms.\n",
      " |████████████████████| 100.0%  - epoch_loss: 303.7599283854 - epoch_recon_loss: 290.1217142741 - epoch_kl_loss: 27.2764116923 - val_loss: 260.7281188965 - val_recon_loss: 251.9053802490 - val_kl_loss: 17.6454734802\n",
      "Saving best state of network...\n",
      "Best State was in Epoch 394\n",
      "Duration of model training in run 6: 0 hours, 0 minutes and 25 seconds.\n",
      "\n",
      "INITIALIZING NEW NETWORK..............\n",
      "Encoder Architecture:\n",
      "\tInput Layer in, out and cond: 4000 256 1\n",
      "\tHidden Layer 1 in/out: 256 256\n",
      "\tHidden Layer 2 in/out: 256 256\n",
      "\tMean/Var Layer in/out: 256 1519\n",
      "Decoder Architecture:\n",
      "\tMasked linear layer in, ext_m, ext, cond, out:  1519 0 0 1 4000\n",
      "\twith hard mask.\n",
      "Last Decoder layer: softmax\n",
      "Preparing (388, 4000)\n",
      "Instantiating dataset\n",
      "Init the group lasso proximal operator for the main terms.\n",
      " |████████████████████| 100.0%  - epoch_loss: 304.7427978516 - epoch_recon_loss: 289.6192728678 - epoch_kl_loss: 30.2470347087 - val_loss: 258.6831665039 - val_recon_loss: 248.0315399170 - val_kl_loss: 21.3032283783\n",
      "Saving best state of network...\n",
      "Best State was in Epoch 394\n",
      "Duration of model training in run 7: 0 hours, 0 minutes and 25 seconds.\n",
      "\n",
      "INITIALIZING NEW NETWORK..............\n",
      "Encoder Architecture:\n",
      "\tInput Layer in, out and cond: 4000 256 1\n",
      "\tHidden Layer 1 in/out: 256 256\n",
      "\tHidden Layer 2 in/out: 256 256\n",
      "\tMean/Var Layer in/out: 256 1519\n",
      "Decoder Architecture:\n",
      "\tMasked linear layer in, ext_m, ext, cond, out:  1519 0 0 1 4000\n",
      "\twith hard mask.\n",
      "Last Decoder layer: softmax\n",
      "Preparing (388, 4000)\n",
      "Instantiating dataset\n",
      "Init the group lasso proximal operator for the main terms.\n",
      " |████████████████████| 100.0%  - epoch_loss: 312.7583414714 - epoch_recon_loss: 299.4529927572 - epoch_kl_loss: 26.6107088725 - val_loss: 258.1654663086 - val_recon_loss: 248.8043365479 - val_kl_loss: 18.7222862244\n",
      "Saving best state of network...\n",
      "Best State was in Epoch 398\n",
      "Duration of model training in run 8: 0 hours, 0 minutes and 24 seconds.\n"
     ]
    }
   ],
   "source": [
    "for subsample_pct in [1]:\n",
    "    train_expimap_models(dataset=f\"slideseqv2_mouse_hippocampus_subsample_{subsample_pct}pct\",\n",
    "                         cell_type_key=\"cell_type\",\n",
    "                         gp_dict=mouse_combined_new_gp_dict,\n",
    "                         adata_new=None,\n",
    "                         n_start_run=1,\n",
    "                         n_end_run=8,\n",
    "                         n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db492dc-56da-4ae1-806d-dea051e5eb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aa8428-5193-46e3-8eba-75a991ca2a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_expimap_models(dataset=\"slideseqv2_mouse_hippocampus\",\n",
    "                     cell_type_key=\"cell_type\",\n",
    "                     gp_dict=mouse_combined_new_gp_dict,\n",
    "                     adata_new=adata_new,\n",
    "                     n_start_run=5,\n",
    "                     n_end_run=8,\n",
    "                     n_neighbor_list=[12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0716d8a-fdc9-4308-950d-decc145cef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_expimap_models(dataset=\"nanostring_cosmx_human_nsclc_batch5\",\n",
    "                     gp_dict=human_combined_new_gp_dict,\n",
    "                     cell_type_key=\"cell_type\",\n",
    "                     adata_new=None,\n",
    "                     n_start_run=1,\n",
    "                     n_end_run=8,\n",
    "                     n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b3d1af-a005-4790-bbd9-65e7c286ab1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subsample_pct in [50, 25, 10, 5, 1]:\n",
    "    train_expimap_models(dataset=f\"nanostring_cosmx_human_nsclc_subsample_{subsample_pct}pct_batch5\",\n",
    "                         gp_dict=human_combined_new_gp_dict,\n",
    "                         cell_type_key=\"cell_type\",\n",
    "                         adata_new=None,\n",
    "                         n_start_run=1,\n",
    "                         n_end_run=8,\n",
    "                         n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c63c2f3-38ca-476d-bf2e-cac68c30f9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_expimap_models(dataset=\"vizgen_merfish_mouse_liver\",\n",
    "                     gp_dict=mouse_combined_new_gp_dict,\n",
    "                     cell_type_key=\"Cell_Type\",\n",
    "                     adata_new=None,\n",
    "                     n_start_run=1,\n",
    "                     n_end_run=8,\n",
    "                     n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2bfa53-80b3-4ba3-8da4-47b06443e731",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subsample_pct in [50, 25, 10, 5, 1]:\n",
    "    train_expimap_models(dataset=f\"vizgen_merfish_mouse_liver_subsample_{subsample_pct}pct\",\n",
    "                         cell_type_key=\"Cell_Type\",\n",
    "                         gp_dict=mouse_combined_new_gp_dict,\n",
    "                         adata_new=None,\n",
    "                         n_start_run=1,\n",
    "                         n_end_run=8,\n",
    "                         n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167e90f9-a124-4180-a142-f295f4ca7128",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_expimap_models(dataset=\"slideseqv2_mouse_hippocampus\",\n",
    "                     cell_type_key=\"cell_type\",\n",
    "                     gp_dict=mouse_combined_new_gp_dict,\n",
    "                     adata_new=None,\n",
    "                     n_start_run=1,\n",
    "                     n_end_run=8,\n",
    "                     n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f389a8-62e6-4d1f-bcb6-2ded4e4d346c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subsample_pct in [50, 25, 10, 5, 1]:\n",
    "    train_expimap_models(dataset=f\"slideseqv2_mouse_hippocampus_subsample_{subsample_pct}pct\",\n",
    "                         cell_type_key=\"cell_type\",\n",
    "                         gp_dict=mouse_combined_new_gp_dict,\n",
    "                         adata_new=None,\n",
    "                         n_start_run=1,\n",
    "                         n_end_run=8,\n",
    "                         n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861c4cb2-757a-44ca-acf1-b677b8308841",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
