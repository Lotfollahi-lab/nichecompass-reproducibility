{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STACI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Creator**: Sebastian Birk (<sebastian.birk@helmholtz-munich.de>).\n",
    "- **Affiliation:** Helmholtz Munich, Institute of AI for Health (AIH), Talavera-López Lab\n",
    "- **Date of Creation:** 16.11.2023\n",
    "- **Date of Last Modification:** 31.01.2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The STACI source code is available at https://github.com/uhlerlab/STACI/blob/master.\n",
    "- The corresponding publication is \"Zhang, X., Wang, X., Shivashankar, G. V. & Uhler, C. Graph-based autoencoder integrates spatial transcriptomics with chromatin images and identifies joint biomarkers for Alzheimer’s disease. Nat. Commun. 13, 7480 (2022)\". Publication at https://www.nature.com/articles/s41467-022-35233-1.\n",
    "- The workflow of this notebook follows the notebook from https://github.com/uhlerlab/STACI/blob/master/train_gae_starmap_multisamples.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import time\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import scanpy as sc\n",
    "import squidpy as sq\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "import gae.gae.optimizer as optimizer\n",
    "import gae.gae.model\n",
    "import gae.gae.preprocessing as preprocessing\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import umap\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"staci\"\n",
    "latent_key = f\"{model_name}_latent\"\n",
    "spatial_key = \"spatial\"\n",
    "adj_key = \"spatial_connectivities\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Run Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.set_figure_params(figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get time of notebook execution for timestamping saved artifacts\n",
    "now = datetime.now()\n",
    "current_timestamp = now.strftime(\"%d%m%Y_%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Configure Paths and Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_path = \"../../../datasets/srt_data/gold/\"\n",
    "benchmarking_folder_path = \"../../../artifacts/sample_integration_method_benchmarking\"\n",
    "figure_folder_path = f\"../../../figures\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. STACI Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Define Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_staci_models(dataset,\n",
    "                       cell_type_key,\n",
    "                       adata_new=None,\n",
    "                       n_start_run=1,\n",
    "                       n_end_run=8,\n",
    "                       n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16],\n",
    "                       plot_latent_umaps: bool=False):\n",
    "    \n",
    "    # Settings\n",
    "    use_cuda=True #set to true if GPU is used \n",
    "    fastmode=True #Perform validation during training pass\n",
    "    useSavedMaskedEdges=False #some edges of the adjacency matrices are held-out for validation; set to True to save and use saved version of the edge masks\n",
    "    epochs=1000 #number of training epochs (default was 10000 but after 1000 no improvements achieved anymore)\n",
    "    saveFreq=30 #the model parameters will be saved during training at a frequency defined by this parameter\n",
    "    lr=0.001 #initial learning rate\n",
    "    lr_adv=0.001 #this is ignored if not using an adversarial loss in the latent space (i.e. it is ignored for the default setup of STACI. If a discriminator is trained to use the adversarial loss, this is the learning rate of the discriminator.)\n",
    "    weight_decay=0 #regularization term\n",
    "\n",
    "    dropout=0.01 #neural network dropout term\n",
    "    testNodes=0.1 #fraction of total cells used for testing\n",
    "    valNodes=0.05 #fraction of total cells used for validation\n",
    "    XreconWeight=20  #reconstruction weight of the gene expression\n",
    "    ridgeL=0.01 #regularization weight of the gene dropout parameter\n",
    "    shareGenePi=True #ignored in the default model; This is a parameter to specify how if the gene dropout term is shared for some variants of the ZINB distribution modeling as discussed in the original deep count autoencoder paper.\n",
    "\n",
    "    targetBatch=None #if adversarial loss is used, one possibility is to make all batches look like one target batch. None, if not using this option.\n",
    "    switchFreq=10 #the number of epochs spent on training the model using one sample, before switching to the next sample\n",
    "    name='newModel' #name of the model\n",
    "    \n",
    "    #provide the paths to save the training log, trained models, and plots, and the path to the directory where the data is stored\n",
    "    logsavepath=f'log/{dataset}/'+name\n",
    "    modelsavepath=f'models/{dataset}/'+name\n",
    "    plotsavepath=f'plots/{dataset}/'+name\n",
    "    savedir=f'adjacencies/{dataset}/'+name\n",
    "\n",
    "    if not os.path.exists(logsavepath):\n",
    "        os.makedirs(logsavepath)\n",
    "    if not os.path.exists(modelsavepath):\n",
    "        os.makedirs(modelsavepath)\n",
    "    if not os.path.exists(plotsavepath):\n",
    "        os.makedirs(plotsavepath)\n",
    "    if not os.path.exists(savedir):\n",
    "        os.makedirs(savedir)\n",
    "    \n",
    "    # Configure figure folder path\n",
    "    dataset_figure_folder_path = f\"{figure_folder_path}/{dataset}/single_sample_method_benchmarking/\" \\\n",
    "                                 f\"{model_name}/{current_timestamp}\"\n",
    "    os.makedirs(dataset_figure_folder_path, exist_ok=True)\n",
    "    \n",
    "    # Create new adata to store results from training runs in storage-efficient way\n",
    "    if adata_new is None:\n",
    "        adata_original = sc.read_h5ad(data_folder_path + f\"{dataset}.h5ad\")\n",
    "        \n",
    "        adata_new = sc.AnnData(sp.csr_matrix(\n",
    "            (adata_original.shape[0], adata_original.shape[1]),\n",
    "            dtype=np.float32))\n",
    "        adata_new.var_names = adata_original.var_names\n",
    "        adata_new.obs_names = adata_original.obs_names\n",
    "        adata_new.obs[\"cell_type\"] = adata_original.obs[cell_type_key].values\n",
    "        adata_new.obsm[\"spatial\"] = adata_original.obsm[\"spatial\"]\n",
    "        del(adata_original)\n",
    "        gc.collect()\n",
    "\n",
    "    model_seeds = list(range(0, 10))\n",
    "    for run_number, n_neighbors in zip(np.arange(n_start_run, n_end_run+1), n_neighbor_list):\n",
    "        # Load data\n",
    "        adata = sc.read_h5ad(data_folder_path + f\"{dataset}.h5ad\")\n",
    "        \n",
    "        if \"seqfish\" in dataset:\n",
    "            adata.obs[\"batch\"] = adata.obs[\"sample\"]\n",
    "        training_samples = adata.obs[\"batch\"].unique().tolist()\n",
    "        sampleidx = {sample: sample for sample in training_samples}\n",
    "        \n",
    "        # Store raw counts in adata.X\n",
    "        adata.X = adata.layers[\"counts\"]\n",
    "        adata.X = adata.X.toarray()\n",
    "        if \"log1p\" in adata.uns:\n",
    "            del(adata.uns[\"log1p\"])\n",
    "\n",
    "        # Compute spatial neighborhood graph\n",
    "        sq.gr.spatial_neighbors(adata,\n",
    "                                coord_type=\"generic\",\n",
    "                                spatial_key=\"spatial\",\n",
    "                                n_neighs=n_neighbors)\n",
    "        \n",
    "        maskedgeName = f'knn{n_neighbors}_connectivity'\n",
    "        \n",
    "        # Make adjacency matrix symmetric\n",
    "        adata.obsp[adj_key] = adata.obsp[adj_key].maximum(\n",
    "            adata.obsp[adj_key].T)\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        #normalize the gene expression\n",
    "        #batch information should be stored in the metadata as 'sample'\n",
    "        featureslist={}\n",
    "        adj_list = {}\n",
    "        for s in sampleidx.keys():\n",
    "            adata_sample=adata[adata.obs['batch']==sampleidx[s]]\n",
    "            featurelog_train=np.log2(adata_sample.X+1/2)\n",
    "            scaler = MinMaxScaler()\n",
    "            featurelog_train_minmax=np.transpose(scaler.fit_transform(np.transpose(featurelog_train)))\n",
    "            featureslist[s+'X_logminmax']=torch.tensor(featurelog_train_minmax)\n",
    "\n",
    "            adj_list[sampleidx[s]] = adata_sample.obsp[adj_key]\n",
    "            del(adata_sample)\n",
    "            gc.collect()\n",
    "\n",
    "        num_features = adata.shape[1]\n",
    "        \n",
    "        hidden1=3*num_features #Number of units in hidden layer 1\n",
    "        hidden2=3*num_features #Number of units in hidden layer 2\n",
    "        fc_dim1=3*num_features #Number of units in the fully connected layer of the decoder\n",
    "        \n",
    "        if not plot_latent_umaps:\n",
    "            del(adata)\n",
    "            gc.collect()\n",
    "\n",
    "        adjnormlist={}\n",
    "        pos_weightlist={}\n",
    "\n",
    "        normlist={}\n",
    "        for ai in adj_list.keys():\n",
    "            adjnormlist[ai]=preprocessing.preprocess_graph(adj_list[ai])\n",
    "\n",
    "            pos_weightlist[ai] = torch.tensor(float(adj_list[ai].shape[0] * adj_list[ai].shape[0] - adj_list[ai].sum()) / adj_list[ai].sum()) #using full unmasked adj\n",
    "            normlist[ai] = adj_list[ai].shape[0] * adj_list[ai].shape[0] / float((adj_list[ai].shape[0] * adj_list[ai].shape[0] - adj_list[ai].sum()) * 2)\n",
    "            \n",
    "            adj_label=adj_list[ai] + sp.eye(adj_list[ai].shape[0])\n",
    "            adj_list[ai]=torch.tensor(adj_label.todense()) # very memory intensive\n",
    "\n",
    "        rawdata=sc.read_h5ad(data_folder_path + f\"{dataset}.h5ad\")\n",
    "        rawdata.X = rawdata.X.toarray()\n",
    "        if \"seqfish\" in dataset:\n",
    "            rawdata.obs[\"batch\"] = rawdata.obs[\"sample\"]\n",
    "        \n",
    "        features_raw_list={}\n",
    "        for s in sampleidx.keys():\n",
    "            features_raw_list[s+'X_'+'raw']=torch.tensor(rawdata.X[rawdata.obs['batch']==sampleidx[s]])\n",
    "\n",
    "        # Set cuda and seed\n",
    "        np.random.seed(model_seeds[run_number-1])\n",
    "        if use_cuda and (not torch.cuda.is_available()):\n",
    "            print('cuda not available')\n",
    "            use_cuda=False\n",
    "        torch.manual_seed(model_seeds[run_number-1])\n",
    "        if use_cuda:\n",
    "            torch.cuda.manual_seed(model_seeds[run_number-1])\n",
    "            torch.backends.cudnn.enabled = True\n",
    "\n",
    "        # loop over all train/validation sets\n",
    "        np.random.seed(model_seeds[run_number-1])\n",
    "        torch.manual_seed(model_seeds[run_number-1])\n",
    "        if use_cuda:\n",
    "            torch.cuda.manual_seed(model_seeds[run_number-1])\n",
    "            torch.backends.cudnn.enabled = True\n",
    "\n",
    "        mse=torch.nn.MSELoss()\n",
    "        # Create model\n",
    "        model = gae.gae.model.GCNModelVAE_XA_e2_d1_DCA(num_features, hidden1,hidden2,fc_dim1, dropout)\n",
    "        loss_kl=optimizer.optimizer_kl\n",
    "        loss_x=optimizer.optimizer_zinb\n",
    "        loss_a=optimizer.optimizer_CE\n",
    "\n",
    "        if use_cuda:\n",
    "            model.cuda()\n",
    "\n",
    "        optimizerVAEXA = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "        def train(epoch):\n",
    "            t = time.time()\n",
    "            model.train()\n",
    "            optimizerVAEXA.zero_grad()\n",
    "\n",
    "            adj_recon,mu,logvar,z,features_recon = model(features, adj_norm)\n",
    "\n",
    "            loss_kl_train=loss_kl(mu, logvar, train_nodes_idx)\n",
    "            loss_x_train=loss_x(features_recon, features,train_nodes_idx,XreconWeight,ridgeL,features_raw)\n",
    "            loss_a_train=loss_a(adj_recon, adj_label, pos_weight, norm,train_nodes_idx)\n",
    "\n",
    "            loss=loss_kl_train+loss_x_train #for lossXreconOnly_wKL only\n",
    "            loss=loss+loss_a_train\n",
    "\n",
    "            loss.backward()\n",
    "            optimizerVAEXA.step()\n",
    "\n",
    "            if not fastmode:\n",
    "                # Evaluate validation set performance separately,\n",
    "                # deactivates dropout during validation run & no variation in z.\n",
    "                model.eval()\n",
    "                adj_recon,mu,logvar,z, features_recon = model(features, adj_norm)\n",
    "\n",
    "\n",
    "            loss_x_val=loss_x(features_recon, features,val_nodes_idx,XreconWeight,ridgeL,features_raw)\n",
    "            loss_a_val=loss_a(adj_recon, adj_label, pos_weight, norm,val_nodes_idx)\n",
    "\n",
    "            loss_val=loss_x_val\n",
    "            loss_val=loss_val+loss_a_val\n",
    "\n",
    "            print(training_samples_t+' Epoch: {:04d}'.format(epoch),\n",
    "                  'loss_train: {:.4f}'.format(loss.item()),\n",
    "                  'loss_kl_train: {:.4f}'.format(loss_kl_train.item()),\n",
    "                  'loss_x_train: {:.4f}'.format(loss_x_train.item()),\n",
    "                  'loss_a_train: {:.4f}'.format(loss_a_train.item()),\n",
    "                  'loss_val: {:.4f}'.format(loss_val.item()),\n",
    "                  'loss_x_val: {:.4f}'.format(loss_x_val.item()),\n",
    "                  'loss_a_val: {:.4f}'.format(loss_a_val.item()),\n",
    "                  'time: {:.4f}s'.format(time.time() - t))\n",
    "\n",
    "            return loss.item(),loss_kl_train.item(),loss_x_train.item(),loss_a_train.item(),loss_val.item(),loss_x_val.item(),loss_a_val.item()        \n",
    "\n",
    "        # print('cross-validation ',seti)\n",
    "        train_loss_ep=[None]*epochs\n",
    "        train_loss_kl_ep=[None]*epochs\n",
    "        train_loss_x_ep=[None]*epochs\n",
    "        train_loss_a_ep=[None]*epochs\n",
    "        train_loss_adv_ep=[None]*epochs\n",
    "        train_loss_advD_ep=[None]*epochs\n",
    "        val_loss_ep=[None]*epochs\n",
    "        val_loss_x_ep=[None]*epochs\n",
    "        val_loss_a_ep=[None]*epochs\n",
    "        val_loss_adv_ep=[None]*epochs\n",
    "        val_loss_advD_ep=[None]*epochs\n",
    "        t_ep=time.time()\n",
    "\n",
    "        for ep in range(epochs):\n",
    "            t=int(ep/switchFreq)%len(training_samples)\n",
    "            training_samples_t=training_samples[t]\n",
    "\n",
    "            adj_norm=adjnormlist[training_samples_t].cuda().float()\n",
    "            adj_label=adj_list[training_samples_t].cuda().float()\n",
    "            features=featureslist[training_samples_t+'X_logminmax'].cuda().float()\n",
    "            pos_weight=pos_weightlist[training_samples_t]\n",
    "            norm=normlist[training_samples_t]\n",
    "            features_raw=features_raw_list[training_samples_t+'X_raw'].cuda()\n",
    "            num_nodes,_ = features.shape\n",
    "\n",
    "            maskpath=os.path.join(savedir,'trainMask',training_samples_t+'_'+maskedgeName+'_seed'+str(model_seeds[run_number-1])+'.pkl')\n",
    "            if useSavedMaskedEdges and os.path.exists(maskpath):\n",
    "                with open(maskpath, 'rb') as input:\n",
    "                    maskedgeres = pickle.load(input)\n",
    "            else:\n",
    "                # construct training, validation, and test sets\n",
    "                maskedgeres= preprocessing.mask_nodes_edges(features.shape[0],testNodeSize=testNodes,valNodeSize=valNodes,seed=model_seeds[run_number-1])\n",
    "                os.makedirs(savedir+\"/trainMask\", exist_ok=True)\n",
    "                with open(maskpath, 'wb') as output:\n",
    "                    pickle.dump(maskedgeres, output, pickle.HIGHEST_PROTOCOL)\n",
    "            train_nodes_idx,val_nodes_idx,test_nodes_idx = maskedgeres\n",
    "            if use_cuda:\n",
    "                train_nodes_idx=train_nodes_idx.cuda()\n",
    "                val_nodes_idx=val_nodes_idx.cuda()\n",
    "                test_nodes_idx=test_nodes_idx.cuda()\n",
    "\n",
    "            train_loss_ep[ep],train_loss_kl_ep[ep],train_loss_x_ep[ep],train_loss_a_ep[ep],val_loss_ep[ep],val_loss_x_ep[ep],val_loss_a_ep[ep]=train(ep)\n",
    "\n",
    "            if ep%saveFreq == 0:\n",
    "                torch.save(model.cpu().state_dict(), os.path.join(modelsavepath,str(ep)+'.pt'))\n",
    "            if use_cuda:\n",
    "                model.cuda()\n",
    "                torch.cuda.empty_cache()\n",
    "        print(' total time: {:.4f}s'.format(time.time() - t_ep))\n",
    "        \n",
    "        # Measure time for model training\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        hours, rem = divmod(elapsed_time, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        print(f\"Duration of model training in run {run_number}: \"\n",
    "              f\"{int(hours)} hours, {int(minutes)} minutes and {int(seconds)} seconds.\")\n",
    "        adata_new.uns[f\"{model_name}_model_training_duration_run{run_number}\"] = (\n",
    "            elapsed_time)\n",
    "\n",
    "        if plot_latent_umaps:\n",
    "            # Use GraphST latent space for UMAP generation\n",
    "            sc.pp.neighbors(adata,\n",
    "                            use_rep=\"emb\",\n",
    "                            n_neighbors=n_neighbors)\n",
    "            sc.tl.umap(adata)\n",
    "            fig = sc.pl.umap(adata,\n",
    "                             color=[cell_type_key],\n",
    "                             title=\"Latent Space with Cell Types: GraphST\",\n",
    "                             return_fig=True)\n",
    "            fig.savefig(f\"{dataset_figure_folder_path}/latent_{model_name}\"\n",
    "                        f\"_cell_types_run{run_number}.png\",\n",
    "                        bbox_inches=\"tight\")\n",
    "\n",
    "            # Compute latent Leiden clustering\n",
    "            sc.tl.leiden(adata=adata,\n",
    "                         resolution=leiden_resolution,\n",
    "                         random_state=model_seeds[run_number-1],\n",
    "                         key_added=f\"latent_{model_name}_leiden_{str(leiden_resolution)}\")\n",
    "\n",
    "            # Create subplot of latent Leiden cluster annotations in physical and latent space\n",
    "            fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(6, 12))\n",
    "            title = fig.suptitle(t=\"Latent and Physical Space with Leiden Clusters: STACI\")\n",
    "            sc.pl.umap(adata=adata,\n",
    "                       color=[f\"latent_{model_name}_leiden_{str(leiden_resolution)}\"],\n",
    "                       title=f\"Latent Space with Leiden Clusters\",\n",
    "                       ax=axs[0],\n",
    "                       show=False)\n",
    "            sq.pl.spatial_scatter(adata=adata,\n",
    "                                  color=[f\"latent_{model_name}_leiden_{str(leiden_resolution)}\"],\n",
    "                                  title=f\"Physical Space with Leiden Clusters\",\n",
    "                                  shape=None,\n",
    "                                  ax=axs[1])\n",
    "\n",
    "            # Create and position shared legend\n",
    "            handles, labels = axs[0].get_legend_handles_labels()\n",
    "            lgd = fig.legend(handles, labels, bbox_to_anchor=(1.25, 0.9185))\n",
    "            axs[0].get_legend().remove()\n",
    "            axs[1].get_legend().remove()\n",
    "\n",
    "            # Adjust, save and display plot\n",
    "            plt.subplots_adjust(wspace=0, hspace=0.2)\n",
    "            fig.savefig(f\"{dataset_figure_folder_path}/latent_physical_comparison_\"\n",
    "                        f\"{model_name}_run{run_number}.png\",\n",
    "                        bbox_extra_artists=(lgd, title),\n",
    "                        bbox_inches=\"tight\")\n",
    "            plt.show()\n",
    "\n",
    "        # Store latent representation in adata\n",
    "        adj_recon,mu,logvar,z,features_recon = model(features, adj_norm)\n",
    "        adata_new.obsm[latent_key + f\"_run{run_number}\"] = mu.cpu().detach().numpy()\n",
    "\n",
    "        # Store intermediate adata to disk\n",
    "        adata_new.write(f\"{benchmarking_folder_path}/{dataset}_{model_name}.h5ad\")\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    # Store final adata to disk\n",
    "    adata_new.write(f\"{benchmarking_folder_path}/{dataset}_{model_name}.h5ad\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Train Models on Benchmarking Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_staci_models(dataset=\"seqfish_mouse_organogenesis_embryo2\",\n",
    "                   cell_type_key=\"celltype_mapped_refined\",\n",
    "                   adata_new=None,\n",
    "                   n_start_run=1,\n",
    "                   n_end_run=8,\n",
    "                   n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subsample_pct in [50, 25, 10, 5, 1]:\n",
    "    train_staci_models(dataset=f\"seqfish_mouse_organogenesis_subsample_{subsample_pct}pct_embryo2\",\n",
    "                       cell_type_key=\"celltype_mapped_refined\",\n",
    "                       adata_new=None,\n",
    "                       n_start_run=1,\n",
    "                       n_end_run=8,\n",
    "                       n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# This does not work because of memory exhaustion\n",
    "# NVIDIA A100-PCIE-40GB GPU\n",
    "train_staci_models(dataset=\"nanostring_cosmx_human_nsclc_batch5\",\n",
    "                   cell_type_key=\"cell_type\",\n",
    "                   adata_new=None,\n",
    "                   n_start_run=1,\n",
    "                   n_end_run=8,\n",
    "                   n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subsample_pct in [10, 5, 1]: # 50, 25 pct exhausts memory\n",
    "    train_staci_models(dataset=f\"nanostring_cosmx_human_nsclc_subsample_{subsample_pct}pct_batch5\",\n",
    "                       cell_type_key=\"cell_type\",\n",
    "                       adata_new=None,\n",
    "                       n_start_run=1,\n",
    "                       n_end_run=8,\n",
    "                       n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# This does not work because of memory exhaustion\n",
    "# NVIDIA A100-PCIE-40GB GPU\n",
    "train_staci_models(dataset=\"vizgen_merfish_mouse_liver\",\n",
    "                   cell_type_key=\"Cell_Type\",\n",
    "                   adata_new=None,\n",
    "                   n_start_run=1,\n",
    "                   n_end_run=8,\n",
    "                   n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subsample_pct in [5, 1]: # 50, 25, 10 pct exhausts memory\n",
    "    train_staci_models(dataset=f\"vizgen_merfish_mouse_liver_subsample_{subsample_pct}pct\",\n",
    "                       cell_type_key=\"Cell_Type\",\n",
    "                       adata_new=None,\n",
    "                       n_start_run=1,\n",
    "                       n_end_run=8,\n",
    "                       n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# This does not work because of memory exhaustion\n",
    "# NVIDIA A100-PCIE-40GB GPU\n",
    "train_staci_models(dataset=\"slideseqv2_mouse_hippocampus\",\n",
    "                   cell_type_key=\"cell_type\",\n",
    "                   adata_new=None,\n",
    "                   n_start_run=1,\n",
    "                   n_end_run=8,\n",
    "                   n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subsample_pct in [25, 10, 5, 1]: # 50 pct exhausts memory\n",
    "    train_staci_models(dataset=f\"slideseqv2_mouse_hippocampus_subsample_{subsample_pct}pct\",\n",
    "                       cell_type_key=\"cell_type\",\n",
    "                       adata_new=None,\n",
    "                       n_start_run=1,\n",
    "                       n_end_run=8,\n",
    "                       n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
