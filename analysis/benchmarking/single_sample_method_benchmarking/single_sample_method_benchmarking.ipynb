{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "364a9ebc-3e3c-4645-9049-a34bd084c8a8",
   "metadata": {},
   "source": [
    "# Single Sample Method Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c55227-147e-417f-b0dd-bb0b7f322930",
   "metadata": {},
   "source": [
    "- **Creator**: Sebastian Birk (<sebastian.birk@helmholtz-munich.de>)\n",
    "- **Date of Creation:** 06.01.2023\n",
    "- **Date of Last Modification:** 07.10.2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3851f353-fdbf-45ff-b511-c4c173096337",
   "metadata": {},
   "source": [
    "Run this notebook in the nichecompass-reproducibility environment, installable from ```('../../../envs/environment.yaml')```.\n",
    "\n",
    "Before running this notebook:\n",
    "- Clone SDMBench from https://github.com/zhaofangyuan98/SDMBench/tree/main/SDMBench into ```('../benchmarking')``` (some slight modifications to the SDMBench source code were necessary to remove technical bugs).\n",
    "- Compute the single sample method benchmarking metrics by triggering the respective jobs (under **Single Sample Method Benchmarking** header) in ```('../../slurm_job_submission.ipynb')```.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7529cde5-be12-403b-a94c-07561774b86c",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faad87bd-fef5-4429-a175-d714c491ae76",
   "metadata": {},
   "source": [
    "### 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9533f18-f082-4dcc-8e93-117b9759133e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e0bf12-90ee-403e-8970-0d1ac2f47540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../../utils\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f93960-c759-424f-8cb2-1d8698acae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import plottable\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "#from cellcharter.tl import Cluster\n",
    "from scipy.spatial.distance import pdist\n",
    "from nichecompass.models import NicheCompass\n",
    "from nichecompass.utils import create_new_color_dict\n",
    "\n",
    "from benchmarking_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b5efa5-2052-4986-8ae5-89cfab018515",
   "metadata": {},
   "source": [
    "### 1.2 Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c513d2e5-7690-432e-a63f-c44bdbe0c11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_cols_single_sample = [\n",
    "    \"cas\", \"mlami\", # global spatial consistency\n",
    "    \"clisis\", \"gcs\", # local spatial consistency\n",
    "    \"nasw\", \"cnmi\", # niche coherence\n",
    "]\n",
    "metric_col_weights_single_sample = [ # separate for each category (later multiplied with category_col_weights)\n",
    "    (1/8), (1/8), # global spatial consistency\n",
    "    (1/8), (1/8), # local spatial consistency\n",
    "    (1/4), (1/4), # niche clustering performance\n",
    "]\n",
    "metric_col_titles_single_sample = [\n",
    "    \"CAS\", # \"Cell Type Affinity Similarity\",\n",
    "    \"MLAMI\", # \"Maximum Leiden Adjusted Mutual Info\",\n",
    "    \"CLISIS\", # \"Cell Type Local Inverse Simpson's Index Similarity\",\n",
    "    \"GCS\", # \"Graph Connectivity Similarity\",\n",
    "    \"NASW\", # \"Niche Average Silhouette Width\",\n",
    "    \"CNMI\", # \"Cell Type Normalized Mutual Info\",\n",
    "]\n",
    "\n",
    "category_cols_single_sample = [\n",
    "    \"Global Spatial Consistency Score\",\n",
    "    \"Local Spatial Consistency Score\",\n",
    "    \"Niche Coherence Score\"]\n",
    "category_col_weights_single_sample = [\n",
    "    0.25,\n",
    "    0.25,\n",
    "    0.5]\n",
    "category_col_titles_single_sample = [\n",
    "    \"Global Spatial Consistency Score\",\n",
    "    \"Local Spatial Consistency Score\",\n",
    "    \"Niche Coherence Score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76820751-42bd-4609-9467-1f2dbe7c4b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ground truth niche prediction metrics\n",
    "sdm_bench_metric_cols = [\"sdmbench_ari\",\n",
    "                         \"sdmbench_nmi\",\n",
    "                         \"sdmbench_hom\",\n",
    "                         \"sdmbench_com\"\n",
    "                        ]\n",
    "\n",
    "sdm_bench_metric_col_titles = [\"NARI\",\n",
    "                               \"NNMI\",\n",
    "                               \"HOM\",\n",
    "                               \"COM\"\n",
    "                              ]\n",
    "\n",
    "sdm_bench_metric_col_weights = [0.5,\n",
    "                                0.5,\n",
    "                                0.5,\n",
    "                                0.5\n",
    "                               ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28adc110-0f41-4a71-9838-dc7f0687809a",
   "metadata": {},
   "source": [
    "### 1.3 Run Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334b87ca-3387-4ba9-8567-84bc4754ff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.set_figure_params(figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3944b0c4-023b-4fcb-9b61-9293f08939b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore future warnings and user warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab6b302-1c0b-4937-8624-40629ada2e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get time of notebook execution for timestamping saved artifacts\n",
    "now = datetime.now()\n",
    "current_timestamp = now.strftime(\"%d%m%Y_%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85538952-006b-4b0b-a50c-fe7445ce22e2",
   "metadata": {},
   "source": [
    "### 1.4 Configure Paths and Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddcc49c-ba22-4155-acd5-05b5b810e091",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_path = \"../../../datasets/st_data/gold\"\n",
    "artifact_folder_path = f\"../../../artifacts\"\n",
    "benchmarking_folder_path = f\"{artifact_folder_path}/single_sample_method_benchmarking\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1f3798-2b4a-49ed-892c-a85d167d8ff1",
   "metadata": {},
   "source": [
    "## 2. Method Benchmarking Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed96ebf-922e-42c2-a8aa-778e59737bc0",
   "metadata": {},
   "source": [
    "- Run all model notebooks in this directory (```./```) before continuing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521e3095-f73f-446f-afed-c3d825cfbc2d",
   "metadata": {},
   "source": [
    "### 2.1 Retrieve NicheCompass Runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74899e5-1274-404f-8ec6-9ffef5e51b4e",
   "metadata": {},
   "source": [
    "#### 2.1.1 seqFISH Mouse Organogenesis"
   ]
  },
  {
   "cell_type": "raw",
   "id": "59257364-5393-49c9-82cd-ed933f83e379",
   "metadata": {},
   "source": [
    "# Store NicheCompass GCN encoder results in benchmarking folder\n",
    "task = \"single_sample_method_benchmarking\"\n",
    "conv_layer_encoder = \"gcnconv\"\n",
    "datasets = [\n",
    "    \"seqfish_mouse_organogenesis_embryo2\",\n",
    "    \"seqfish_mouse_organogenesis_subsample_50pct_embryo2\",\n",
    "    \"seqfish_mouse_organogenesis_subsample_25pct_embryo2\",\n",
    "    \"seqfish_mouse_organogenesis_subsample_10pct_embryo2\",\n",
    "    \"seqfish_mouse_organogenesis_subsample_5pct_embryo2\",\n",
    "    \"seqfish_mouse_organogenesis_subsample_1pct_embryo2\",\n",
    "]\n",
    "timestamps = [\n",
    "    \"17082023_113817_1\",\n",
    "    \"17082023_121306_1\",\n",
    "    \"17082023_121306_1\",\n",
    "    \"17082023_121309_1\",\n",
    "    \"17082023_121309_1\",\n",
    "    \"17082023_121309_1\",\n",
    "]\n",
    "\n",
    "for dataset, timestamp in zip(datasets, timestamps):\n",
    "    source_path = f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_{task}/{timestamp}/{dataset}_{conv_layer_encoder}_{task}.h5ad\"\n",
    "    destination_path = f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\"\n",
    "    shutil.copy(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f51939fa-a497-490b-8705-807b007c27f6",
   "metadata": {},
   "source": [
    "# Store NicheCompass GATv2 encoder results in benchmarking folder\n",
    "task = \"single_sample_method_benchmarking\"\n",
    "conv_layer_encoder = \"gatv2conv\"\n",
    "datasets = [\n",
    "    \"seqfish_mouse_organogenesis_embryo2\",\n",
    "    \"seqfish_mouse_organogenesis_subsample_50pct_embryo2\",\n",
    "    \"seqfish_mouse_organogenesis_subsample_25pct_embryo2\",\n",
    "    \"seqfish_mouse_organogenesis_subsample_10pct_embryo2\",\n",
    "    \"seqfish_mouse_organogenesis_subsample_5pct_embryo2\",\n",
    "    \"seqfish_mouse_organogenesis_subsample_1pct_embryo2\",\n",
    "]\n",
    "timestamps = [\n",
    "    \"16082023_153513_1\",\n",
    "    \"16082023_201308_1\",\n",
    "    \"16082023_201312_1\",\n",
    "    \"16082023_201320_1\",\n",
    "    \"16082023_201434_1\",\n",
    "    \"16082023_202321_1\",\n",
    "]\n",
    "\n",
    "for dataset, timestamp in zip(datasets, timestamps):\n",
    "    source_path = f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_{task}/{timestamp}/{dataset}_{conv_layer_encoder}_{task}.h5ad\"\n",
    "    destination_path = f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\"\n",
    "    shutil.copy(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18165ea-8b86-41d4-b4dc-09a2ac617f32",
   "metadata": {},
   "source": [
    "#### 2.1.2 nanoString CosMx SMI Human Non-Small-Cell Lung Cancer (NSCLC)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "30c0d336-b7a8-43e5-9a43-ee8eaede6334",
   "metadata": {},
   "source": [
    "# Store NicheCompass GCN encoder results in benchmarking folder\n",
    "task = \"single_sample_method_benchmarking\"\n",
    "conv_layer_encoder = \"gcnconv\"\n",
    "datasets = [\n",
    "    \"nanostring_cosmx_human_nsclc_batch5\",\n",
    "    \"nanostring_cosmx_human_nsclc_subsample_50pct_batch5\",\n",
    "    \"nanostring_cosmx_human_nsclc_subsample_25pct_batch5\",\n",
    "    \"nanostring_cosmx_human_nsclc_subsample_10pct_batch5\",\n",
    "    \"nanostring_cosmx_human_nsclc_subsample_5pct_batch5\",\n",
    "    \"nanostring_cosmx_human_nsclc_subsample_1pct_batch5\",\n",
    "]\n",
    "timestamps = [\n",
    "    \"16082023_174027_1\",\n",
    "    \"16082023_174028_1\",\n",
    "    \"16082023_174332_1\",\n",
    "    \"17082023_100851_1\",\n",
    "    \"17082023_101057_1\",\n",
    "    \"16082023_154030_1\",\n",
    "]\n",
    "\n",
    "for dataset, timestamp in zip(datasets, timestamps):\n",
    "    source_path = f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_{task}/{timestamp}/{dataset}_{conv_layer_encoder}_{task}.h5ad\"\n",
    "    destination_path = f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\"\n",
    "    shutil.copy(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "50c4f747-13a4-4f5c-909f-7c143f3868e3",
   "metadata": {},
   "source": [
    "# Store NicheCompass GATv2 encoder results in benchmarking folder\n",
    "task = \"single_sample_method_benchmarking\"\n",
    "conv_layer_encoder = \"gatv2conv\"\n",
    "datasets = [\n",
    "    \"nanostring_cosmx_human_nsclc_batch5\",\n",
    "    \"nanostring_cosmx_human_nsclc_subsample_50pct_batch5\",\n",
    "    \"nanostring_cosmx_human_nsclc_subsample_25pct_batch5\",\n",
    "    \"nanostring_cosmx_human_nsclc_subsample_10pct_batch5\",\n",
    "    \"nanostring_cosmx_human_nsclc_subsample_5pct_batch5\",\n",
    "    \"nanostring_cosmx_human_nsclc_subsample_1pct_batch5\",\n",
    "]\n",
    "timestamps = [\n",
    "    \"16082023_191755_1\", # only contains 4 runs due to 2 day limit\n",
    "    \"16082023_203456_1\",\n",
    "    \"18082023_100942_1\",\n",
    "    \"17082023_100713_1\",\n",
    "    \"16082023_203744_1\",\n",
    "    \"16082023_203926_1\",\n",
    "]\n",
    "\n",
    "for dataset, timestamp in zip(datasets, timestamps):\n",
    "    source_path = f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_{task}/{timestamp}/{dataset}_{conv_layer_encoder}_{task}.h5ad\"\n",
    "    destination_path = f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\"\n",
    "    shutil.copy(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "20f6539c-785d-4962-ab8f-9cf9d1b12a03",
   "metadata": {},
   "source": [
    "# Add missing runs for 'nanostring_cosmx_human_nsclc_batch5'\n",
    "dataset = \"nanostring_cosmx_human_nsclc_batch5\"\n",
    "conv_layer_encoder = \"gatv2conv\"\n",
    "timestamp = \"18082023_185135_1\"\n",
    "\n",
    "adata1 = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_single_sample_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_single_sample_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [1, 2, 3, 4]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "adata1.write(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b6d996-956a-4033-862e-bc29a4d3b110",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.1.3 Vizgen MERFISH Mouse Liver"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6df22e43-77b3-40eb-8586-f58e8c33df19",
   "metadata": {},
   "source": [
    "# Store NicheCompass GCN encoder results in benchmarking folder\n",
    "task = \"single_sample_method_benchmarking\"\n",
    "conv_layer_encoder = \"gcnconv\"\n",
    "datasets = [\n",
    "    \"vizgen_merfish_mouse_liver\",\n",
    "    \"vizgen_merfish_mouse_liver_subsample_50pct\",\n",
    "    \"vizgen_merfish_mouse_liver_subsample_25pct\",\n",
    "    \"vizgen_merfish_mouse_liver_subsample_10pct\",\n",
    "    \"vizgen_merfish_mouse_liver_subsample_5pct\",\n",
    "    \"vizgen_merfish_mouse_liver_subsample_1pct\",\n",
    "]\n",
    "timestamps = [\n",
    "    \"16082023_165031_1\",\n",
    "    \"16082023_165038_1\",\n",
    "    \"16082023_165031_1\",\n",
    "    \"16082023_165031_1\",\n",
    "    \"16082023_165031_1\",\n",
    "    \"16082023_170911_1\",\n",
    "]\n",
    "\n",
    "for dataset, timestamp in zip(datasets, timestamps):\n",
    "    source_path = f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_{task}/{timestamp}/{dataset}_{conv_layer_encoder}_{task}.h5ad\"\n",
    "    destination_path = f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\"\n",
    "    shutil.copy(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "073deaa7-352a-46e9-afd1-77feb3c8574a",
   "metadata": {},
   "source": [
    "# Add missing runs for 'vizgen_merfish_mouse_liver'\n",
    "dataset = \"vizgen_merfish_mouse_liver\"\n",
    "conv_layer_encoder = \"gcnconv\"\n",
    "timestamp = \"18082023_171011_2\"\n",
    "\n",
    "adata1 = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_single_sample_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_single_sample_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [1, 2, 3]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "adata1.write(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "73b35896-4efc-468a-9b89-45cd83a41240",
   "metadata": {},
   "source": [
    "# Store NicheCompass GATv2 encoder results in benchmarking folder\n",
    "task = \"single_sample_method_benchmarking\"\n",
    "conv_layer_encoder = \"gatv2conv\"\n",
    "datasets = [\n",
    "    \"vizgen_merfish_mouse_liver\",\n",
    "    \"vizgen_merfish_mouse_liver_subsample_50pct\",\n",
    "    \"vizgen_merfish_mouse_liver_subsample_25pct\",\n",
    "    \"vizgen_merfish_mouse_liver_subsample_10pct\",\n",
    "    \"vizgen_merfish_mouse_liver_subsample_5pct\",\n",
    "    \"vizgen_merfish_mouse_liver_subsample_1pct\",\n",
    "]\n",
    "timestamps = [\n",
    "    \"18082023_191958_4\",\n",
    "    \"18082023_192011_1\",\n",
    "    \"18082023_211554_1\",\n",
    "    \"19082023_141238_1\",\n",
    "    \"19082023_150452_1\",\n",
    "    \"18082023_193358_1\",\n",
    "]\n",
    "\n",
    "for dataset, timestamp in zip(datasets, timestamps):\n",
    "    source_path = f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_{task}/{timestamp}/{dataset}_{conv_layer_encoder}_{task}.h5ad\"\n",
    "    destination_path = f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\"\n",
    "    shutil.copy(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4b4b4b1b-6866-422c-a16b-da2d1e788299",
   "metadata": {},
   "source": [
    "# Add missing runs for 'vizgen_merfish_mouse_liver'\n",
    "dataset = \"vizgen_merfish_mouse_liver\"\n",
    "conv_layer_encoder = \"gatv2conv\"\n",
    "timestamp = \"18082023_191942_3\"\n",
    "\n",
    "adata1 = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_single_sample_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_single_sample_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [3, 4]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "\n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"21082023_131701_2\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_single_sample_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_single_sample_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [5, 6]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "\n",
    "del(adata2)\n",
    "gc.collect()\n",
    "    \n",
    "timestamp = \"21082023_125245_1\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_single_sample_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_single_sample_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [7]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "\n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"21082023_125034_1\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_single_sample_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_single_sample_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [8]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "adata1.write(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "119bd143-034b-49fb-a96b-7695a508e3ac",
   "metadata": {},
   "source": [
    "# Add missing runs for 'vizgen_merfish_mouse_liver_subsample_50pct'\n",
    "dataset = \"vizgen_merfish_mouse_liver_subsample_50pct\"\n",
    "conv_layer_encoder = \"gatv2conv\"\n",
    "timestamp = \"21082023_163421_1\"\n",
    "\n",
    "adata1 = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_single_sample_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_single_sample_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [5]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "\n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"21082023_131701_1\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_single_sample_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_single_sample_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [6]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "    \n",
    "timestamp = \"18082023_192011_1\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_single_sample_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_single_sample_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [7, 8]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "adata1.write(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5b8cbf71-a0e3-46e4-aa63-2866aaf3ab8b",
   "metadata": {},
   "source": [
    "# Add missing runs for 'vizgen_merfish_mouse_liver_subsample_25pct'\n",
    "dataset = \"vizgen_merfish_mouse_liver_subsample_25pct\"\n",
    "conv_layer_encoder = \"gatv2conv\"\n",
    "timestamp = \"21082023_132619_1\"\n",
    "\n",
    "adata1 = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_single_sample_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_single_sample_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [1, 2]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "adata1.write(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68b309e-653e-479f-8932-fbe0b8d9bc3d",
   "metadata": {},
   "source": [
    "#### 2.1.4 Slide-seqV2 Mouse Hippocampus"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e5f18179-4be7-4f2c-a6b8-6e27c47b5da3",
   "metadata": {},
   "source": [
    "# Store NicheCompass GCN encoder results in benchmarking folder\n",
    "task = \"single_sample_method_benchmarking\"\n",
    "conv_layer_encoder = \"gcnconv\"\n",
    "datasets = [\n",
    "    \"slideseqv2_mouse_hippocampus\",\n",
    "    \"slideseqv2_mouse_hippocampus_subsample_50pct\",\n",
    "    \"slideseqv2_mouse_hippocampus_subsample_25pct\",\n",
    "    \"slideseqv2_mouse_hippocampus_subsample_10pct\",\n",
    "    \"slideseqv2_mouse_hippocampus_subsample_5pct\",\n",
    "    \"slideseqv2_mouse_hippocampus_subsample_1pct\",\n",
    "]\n",
    "timestamps = [\n",
    "    \"16082023_205838_1\",\n",
    "    \"16082023_210004_1\",\n",
    "    \"16082023_210005_1\",\n",
    "    \"16082023_210304_1\",\n",
    "    \"16082023_211128_1\",\n",
    "    \"16082023_211128_1\",\n",
    "]\n",
    "\n",
    "for dataset, timestamp in zip(datasets, timestamps):\n",
    "    source_path = f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_{task}/{timestamp}/{dataset}_{conv_layer_encoder}_{task}.h5ad\"\n",
    "    destination_path = f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\"\n",
    "    shutil.copy(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0da6aa9d-b5c6-4b70-a60c-af776ab35468",
   "metadata": {},
   "source": [
    "# Store NicheCompass GATv2 encoder results in benchmarking folder\n",
    "task = \"single_sample_method_benchmarking\"\n",
    "conv_layer_encoder = \"gatv2conv\"\n",
    "datasets = [\n",
    "    \"slideseqv2_mouse_hippocampus\",\n",
    "    \"slideseqv2_mouse_hippocampus_subsample_50pct\",\n",
    "    \"slideseqv2_mouse_hippocampus_subsample_25pct\",\n",
    "    \"slideseqv2_mouse_hippocampus_subsample_10pct\",\n",
    "    \"slideseqv2_mouse_hippocampus_subsample_5pct\",\n",
    "    \"slideseqv2_mouse_hippocampus_subsample_1pct\",\n",
    "]\n",
    "timestamps = [\n",
    "    \"17082023_104409_1\",\n",
    "    \"18082023_095235_1\",\n",
    "    \"17082023_110554_1\",\n",
    "    \"16082023_212040_1\",\n",
    "    \"16082023_212145_1\",\n",
    "    \"16082023_212338_1\",\n",
    "]\n",
    "\n",
    "for dataset, timestamp in zip(datasets, timestamps):\n",
    "    source_path = f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_{task}/{timestamp}/{dataset}_{conv_layer_encoder}_{task}.h5ad\"\n",
    "    destination_path = f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\"\n",
    "    shutil.copy(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb9ed47-8b16-49e2-b639-023e58f55485",
   "metadata": {},
   "source": [
    "#### 2.1.5 Simulation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68db53b3-1233-41fd-83d4-6af7b97efb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store NicheCompass GCN encoder results in benchmarking folder\n",
    "task = \"single_sample_method_benchmarking\"\n",
    "conv_layer_encoder = \"gcnconv\"\n",
    "datasets = [\n",
    "    \"sim1_1105genes_10000locs_strongincrements\"\n",
    "]\n",
    "timestamps = [\n",
    "    \"26072024_145309_1\"\n",
    "]\n",
    "\n",
    "for dataset, timestamp in zip(datasets, timestamps):\n",
    "    source_path = f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_{task}/{timestamp}/{dataset}_{conv_layer_encoder}_{task}.h5ad\"\n",
    "    destination_path = f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\"\n",
    "    shutil.copy(source_path, destination_path)\n",
    "\n",
    "# Add niche types\n",
    "adata = sc.read_h5ad(f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")\n",
    "adata_original = sc.read_h5ad(f\"{data_folder_path}/{dataset}.h5ad\")\n",
    "adata.obs[\"niche_type\"] = adata_original.obs[\"niche_types\"]\n",
    "adata.write(f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58335daa-c1ed-401d-80e1-e0f513614681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store NicheCompass GCN encoder results in benchmarking folder\n",
    "task = \"single_sample_method_benchmarking\"\n",
    "conv_layer_encoder = \"gatv2conv\"\n",
    "datasets = [\n",
    "    \"sim1_1105genes_10000locs_strongincrements\"\n",
    "]\n",
    "timestamps = [\n",
    "    \"26072024_145319_1\",\n",
    "]\n",
    "\n",
    "for dataset, timestamp in zip(datasets, timestamps):\n",
    "    source_path = f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_{task}/{timestamp}/{dataset}_{conv_layer_encoder}_{task}.h5ad\"\n",
    "    destination_path = f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\"\n",
    "    shutil.copy(source_path, destination_path)\n",
    "\n",
    "# Add niche types\n",
    "adata = sc.read_h5ad(f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")\n",
    "adata_original = sc.read_h5ad(f\"{data_folder_path}/{dataset}.h5ad\")\n",
    "adata.obs[\"niche_type\"] = adata_original.obs[\"niche_types\"]\n",
    "adata.write(f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2184436a-d8c0-4201-bf37-faab80753818",
   "metadata": {},
   "source": [
    "#### 2.1.6 SDMBench Data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "48c0443f-d416-4de7-8417-9d831c4f4944",
   "metadata": {},
   "source": [
    "# Store NicheCompass GCN encoder results in benchmarking folder\n",
    "task = \"single_sample_method_benchmarking\"\n",
    "conv_layer_encoder = \"gcnconv\"\n",
    "datasets = [\n",
    "    \"starmap_mouse_mpfc\"\n",
    "]\n",
    "timestamps = [\n",
    "    \"26072024_212300_1\"\n",
    "    #\"26072024_223116_1\",\n",
    "]\n",
    "\n",
    "for dataset, timestamp in zip(datasets, timestamps):\n",
    "    source_path = f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_{task}/{timestamp}/{dataset}_{conv_layer_encoder}_{task}.h5ad\"\n",
    "    destination_path = f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\"\n",
    "    shutil.copy(source_path, destination_path)\n",
    "\n",
    "# Add niche types\n",
    "adata = sc.read_h5ad(f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")\n",
    "adata_original = sc.read_h5ad(f\"{data_folder_path}/{dataset}.h5ad\")\n",
    "adata.obs[\"niche_type\"] = adata_original.obs[\"niche_type\"]\n",
    "adata.write(f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1d63a8b7-342e-48ec-a255-38a6b8a9d51e",
   "metadata": {},
   "source": [
    "# Store NicheCompass GCN encoder results in benchmarking folder\n",
    "task = \"single_sample_method_benchmarking\"\n",
    "conv_layer_encoder = \"gatv2conv\"\n",
    "datasets = [\n",
    "    \"starmap_mouse_mpfc\"\n",
    "]\n",
    "timestamps = [\n",
    "    \"26072024_212258_1\"\n",
    "]\n",
    "\n",
    "for dataset, timestamp in zip(datasets, timestamps):\n",
    "    source_path = f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_{task}/{timestamp}/{dataset}_{conv_layer_encoder}_{task}.h5ad\"\n",
    "    destination_path = f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\"\n",
    "    shutil.copy(source_path, destination_path)\n",
    "\n",
    "# Add niche types\n",
    "adata = sc.read_h5ad(f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")\n",
    "adata_original = sc.read_h5ad(f\"{data_folder_path}/{dataset}.h5ad\")\n",
    "adata.obs[\"niche_type\"] = adata_original.obs[\"niche_type\"]\n",
    "adata.write(f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec471f72-062d-4e68-884f-12ee21d4ecd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store NicheCompass GCN encoder results in benchmarking folder\n",
    "task = \"single_sample_method_benchmarking\"\n",
    "conv_layer_encoder = \"gcnconv\"\n",
    "datasets = [\n",
    "    \"stereoseq_mouse_embryo\"\n",
    "]\n",
    "timestamps = [\n",
    "    \"26072024_145308_1\"\n",
    "]\n",
    "\n",
    "for dataset, timestamp in zip(datasets, timestamps):\n",
    "    source_path = f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_{task}/{timestamp}/{dataset}_{conv_layer_encoder}_{task}.h5ad\"\n",
    "    destination_path = f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\"\n",
    "    shutil.copy(source_path, destination_path)\n",
    "\n",
    "# Add niche types\n",
    "adata = sc.read_h5ad(f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")\n",
    "adata_original = sc.read_h5ad(f\"{data_folder_path}/{dataset}.h5ad\")\n",
    "adata.obs[\"niche_type\"] = adata_original.obs[\"niche_type\"]\n",
    "adata.write(f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685172fa-c5e5-4ef3-9c06-884fb879d4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store NicheCompass GCN encoder results in benchmarking folder\n",
    "task = \"single_sample_method_benchmarking\"\n",
    "conv_layer_encoder = \"gatv2conv\"\n",
    "datasets = [\n",
    "    \"stereoseq_mouse_embryo\"\n",
    "]\n",
    "timestamps = [\n",
    "    \"26072024_151239_1\",\n",
    "]\n",
    "\n",
    "for dataset, timestamp in zip(datasets, timestamps):\n",
    "    source_path = f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_{task}/{timestamp}/{dataset}_{conv_layer_encoder}_{task}.h5ad\"\n",
    "    destination_path = f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\"\n",
    "    shutil.copy(source_path, destination_path)\n",
    "\n",
    "# Add niche types\n",
    "adata = sc.read_h5ad(f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")\n",
    "adata_original = sc.read_h5ad(f\"{data_folder_path}/{dataset}.h5ad\")\n",
    "adata.obs[\"niche_type\"] = adata_original.obs[\"niche_type\"]\n",
    "adata.write(f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ff99c4-ab55-4b85-90e9-d73eaa88f282",
   "metadata": {},
   "source": [
    "### 2.1 Create Benchmarking Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc9cd49-0005-42d9-9c9c-c9e019bcf1c2",
   "metadata": {},
   "source": [
    "#### 2.1.1 Slide-seqV2 Mouse Hippocampus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b98ef0e-8395-4780-9c57-93a67111a3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supplementary fig. 12e: spatial clusters ###\n",
    "adata = sc.read_h5ad(f\"{data_folder_path}/slideseqv2_mouse_hippocampus.h5ad\")\n",
    "adata.obs[\"sample\"] = \"sample1\"\n",
    "\n",
    "leiden_resolution = 0.1\n",
    "\n",
    "print(\"\\nComputing neighbor graph...\")\n",
    "sc.pp.neighbors(adata,\n",
    "                use_rep=\"spatial\",\n",
    "                key_added=\"spatial_knn\")\n",
    "\n",
    "print(\"\\nComputing UMAP embedding...\")\n",
    "sc.tl.umap(adata,\n",
    "           neighbors_key=\"spatial_knn\")\n",
    "\n",
    "print(\"\\nComputing Leiden clustering...\")\n",
    "sc.tl.leiden(adata=adata,\n",
    "             resolution=leiden_resolution,\n",
    "             key_added=f\"spatial_leiden_{leiden_resolution}\",\n",
    "             neighbors_key=\"spatial_knn\")\n",
    "\n",
    "spatial_cluster_colors = create_new_color_dict(\n",
    "    adata=adata,\n",
    "    cat_key=f\"spatial_leiden_{leiden_resolution}\")\n",
    "\n",
    "plot_category_in_latent_and_physical_space(\n",
    "        adata=adata,\n",
    "        plot_label=\"Spatial Clusters\",\n",
    "        model_label=None,\n",
    "        cat_key=f\"spatial_leiden_{leiden_resolution}\",\n",
    "        groups=None,\n",
    "        sample_key=\"sample\",\n",
    "        samples=[\"sample1\"], # =None for latent UMAP\n",
    "        cat_colors=spatial_cluster_colors,\n",
    "        size=(720000 / len(adata)),\n",
    "        spot_size=30,\n",
    "        save_fig=True,\n",
    "        file_path=f\"{benchmarking_folder_path}/spatial_clusters.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c753fe-441a-447c-98ce-20a2379bf97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fig. 3d: metrics ###\n",
    "datasets = [\"slideseqv2_mouse_hippocampus\"]\n",
    "models = [#\"nichecompass_gcnconv\",\n",
    "          \"nichecompass_gatv2conv\",\n",
    "          #\"staci\", # did not run\n",
    "          \"graphst\",\n",
    "          \"deeplinc\",\n",
    "          \"cellcharter\",\n",
    "          \"banksy\"\n",
    "]\n",
    "\n",
    "summary_df = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    dataset_df = pd.DataFrame()\n",
    "    for model in models:\n",
    "        try:\n",
    "            benchmark_df = pd.read_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\")\n",
    "            #adata = sc.read_h5ad(f\"../../artifacts/single_sample_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "            #training_durations = []\n",
    "            #for run_number in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "            #    training_durations.append(adata.uns[f\"{model.split('_')[0]}_model_training_duration_run{run_number}\"])\n",
    "            #benchmark_df[\"run_time\"] = training_durations\n",
    "            #benchmark_df = benchmark_df[[\"dataset\", \"run_number\", \"run_time\", \"gcs\", \"mlami\", \"cas\", \"clisis\", \"nasw\", \"cnmi\", \"cari\", \"casw\", \"clisi\"]]\n",
    "            #benchmark_df.to_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\", index=False)\n",
    "            benchmark_df[\"model\"] = model\n",
    "            dataset_df = pd.concat([dataset_df, benchmark_df], ignore_index=True)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Did not find file {benchmarking_folder_path}/{dataset}_{model}_metrics.csv. Continuing...\")\n",
    "            missing_run_data = {\n",
    "                \"dataset\": [dataset] * 8,\n",
    "                \"model\": [model] * 8,\n",
    "                \"run_number\": [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "                \"run_time\": [np.nan] * 8\n",
    "            }\n",
    "            missing_run_df = pd.DataFrame(missing_run_data)\n",
    "            dataset_df = pd.concat([dataset_df, missing_run_df], ignore_index=True)\n",
    "            \n",
    "    # Apply min-max scaling to metric columns\n",
    "    for i in range(len(metric_cols_single_sample)):\n",
    "        min_val = dataset_df[metric_cols_single_sample[i]].min()\n",
    "        max_val = dataset_df[metric_cols_single_sample[i]].max()\n",
    "        dataset_df[metric_cols_single_sample[i] + \"_scaled\"] = ((\n",
    "            dataset_df[metric_cols_single_sample[i]] - min_val) / (max_val - min_val))\n",
    "\n",
    "    summary_df = pd.concat([summary_df, dataset_df], ignore_index=True)\n",
    "    continue\n",
    "    \n",
    "cat_0_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[0:2]]\n",
    "cat_1_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[2:4]]\n",
    "cat_2_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[4:6]]\n",
    "    \n",
    "summary_df[category_cols_single_sample[0]] = np.average(summary_df[cat_0_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[0:2],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_single_sample[1]] = np.average(summary_df[cat_1_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[2:4],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_single_sample[2]] = np.average(summary_df[cat_2_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[4:6],\n",
    "                                                        axis=1)\n",
    "summary_df[\"Overall Score\"] = np.average(summary_df[category_cols_single_sample[:3]],\n",
    "                                         weights=category_col_weights_single_sample[:3],\n",
    "                                         axis=1)\n",
    " \n",
    "# Reformat for plot\n",
    "summary_df.replace({\"nichecompass_gatv2conv\": \"NicheCompass\",\n",
    "                    #\"nichecompass_gcnconv\": \"NicheCompass Light\",\n",
    "                    \"staci\": \"STACI\",\n",
    "                    \"deeplinc\": \"DeepLinc\",\n",
    "                    \"expimap\": \"expiMap\",\n",
    "                    \"graphst\": \"GraphST\",\n",
    "                    \"cellcharter\": \"CellCharter\",\n",
    "                    \"banksy\": \"BANKSY\"},\n",
    "                   inplace=True)\n",
    "\n",
    "# Filter for just second run\n",
    "summary_df = summary_df[summary_df[\"run_number\"] == 2]\n",
    "\n",
    "# Plot over all loss weights combinations\n",
    "# Prepare metrics table plot\n",
    "group_cols = [\"dataset\", \"model\"]\n",
    "aggregate_df = summary_df.groupby(group_cols).mean(\"Overall Score\").sort_values(\"Overall Score\", ascending=False)[\n",
    "    metric_cols_single_sample + [\"Overall Score\"]].reset_index()\n",
    "\n",
    "unrolled_df = pd.melt(aggregate_df, \n",
    "   id_vars=group_cols,\n",
    "   value_vars=metric_cols_single_sample + [\"Overall Score\"],\n",
    "   var_name=\"score_type\", \n",
    "   value_name=\"score\")\n",
    "\n",
    "# Create spatial indicator column\n",
    "def is_spatially_aware_model(row):\n",
    "    if row[\"model\"] in [\"NicheCompass\", \"STACI\", \"DeepLinc\", \"GraphST\", \"SageNet\"]:\n",
    "        return True\n",
    "    return False\n",
    "unrolled_df[\"spatially_aware\"] = unrolled_df.apply(lambda row: is_spatially_aware_model(row), axis=1)\n",
    "unrolled_df = unrolled_df[[\"dataset\", \"spatially_aware\", \"model\", \"score_type\", \"score\"]]\n",
    "\n",
    "# Order datasets\n",
    "unrolled_df[\"dataset\"] = pd.Categorical(unrolled_df[\"dataset\"], categories=datasets, ordered=True)\n",
    "unrolled_df = unrolled_df.sort_values(by=\"dataset\")\n",
    "\n",
    "unrolled_df[\"model\"] = unrolled_df[\"model\"].replace(\"NicheCompass GATv2\", \"NicheCompass\")\n",
    "#unrolled_df[\"model\"] = unrolled_df[\"model\"].replace(\"NicheCompass GCN\", \"NicheCompass Light\")\n",
    "\n",
    "# Plot table\n",
    "plot_simple_metrics_table(\n",
    "    df=unrolled_df,\n",
    "    model_col=\"model\",\n",
    "    model_col_width=1.6,\n",
    "    group_col=\"dataset\",\n",
    "    metric_cols=metric_cols_single_sample, # metric_cols_single_sample, category_cols_single_sample\n",
    "    metric_col_weights=metric_col_weights_single_sample, # metric_col_weights_single_sample, category_col_weights_single_sample\n",
    "    metric_col_titles=[col.replace(\" \", \"\\n\") for col in metric_col_titles_single_sample], # category_col_titles_single_sample\n",
    "    metric_col_width=0.7, # 0.8,\n",
    "    aggregate_col_width=1.2,\n",
    "    plot_width=8, # 8.5, # 32,\n",
    "    plot_height=7,# 8,\n",
    "    show=True,\n",
    "    save_dir=benchmarking_folder_path,\n",
    "    save_name=f\"benchmarking_metrics_slideseqv2_mouse_hippocampus_run2.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8472245a-e6f0-4fe8-a571-3eecb7d4bfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supplementary fig. 13b: 25% subsample metrics ###\n",
    "datasets = [\"slideseqv2_mouse_hippocampus_subsample_25pct\"]\n",
    "models = [#\"nichecompass_gcnconv\",\n",
    "          \"nichecompass_gatv2conv\",\n",
    "          \"staci\",\n",
    "          \"graphst\",\n",
    "          \"deeplinc\",\n",
    "          \"cellcharter\",\n",
    "          \"banksy\"\n",
    "]\n",
    "\n",
    "summary_df = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    dataset_df = pd.DataFrame()\n",
    "    for model in models:\n",
    "        try:\n",
    "            benchmark_df = pd.read_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\")\n",
    "            #adata = sc.read_h5ad(f\"../../artifacts/single_sample_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "            #training_durations = []\n",
    "            #for run_number in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "            #    training_durations.append(adata.uns[f\"{model.split('_')[0]}_model_training_duration_run{run_number}\"])\n",
    "            #benchmark_df[\"run_time\"] = training_durations\n",
    "            #benchmark_df = benchmark_df[[\"dataset\", \"run_number\", \"run_time\", \"gcs\", \"mlami\", \"cas\", \"clisis\", \"nasw\", \"cnmi\", \"cari\", \"casw\", \"clisi\"]]\n",
    "            #benchmark_df.to_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\", index=False)\n",
    "            benchmark_df[\"model\"] = model\n",
    "            dataset_df = pd.concat([dataset_df, benchmark_df], ignore_index=True)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Did not find file {benchmarking_folder_path}/{dataset}_{model}_metrics.csv. Continuing...\")\n",
    "            missing_run_data = {\n",
    "                \"dataset\": [dataset] * 8,\n",
    "                \"model\": [model] * 8,\n",
    "                \"run_number\": [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "                \"run_time\": [np.nan] * 8\n",
    "            }\n",
    "            missing_run_df = pd.DataFrame(missing_run_data)\n",
    "            dataset_df = dataset_df.append(missing_run_df, ignore_index=True)\n",
    "            \n",
    "    # Apply min-max scaling to metric columns\n",
    "    for i in range(len(metric_cols_single_sample)):\n",
    "        min_val = dataset_df[metric_cols_single_sample[i]].min()\n",
    "        max_val = dataset_df[metric_cols_single_sample[i]].max()\n",
    "        dataset_df[metric_cols_single_sample[i] + \"_scaled\"] = ((\n",
    "            dataset_df[metric_cols_single_sample[i]] - min_val) / (max_val - min_val))\n",
    "\n",
    "    summary_df = pd.concat([summary_df, dataset_df], ignore_index=True)\n",
    "    continue\n",
    "    \n",
    "cat_0_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[0:2]]\n",
    "cat_1_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[2:4]]\n",
    "cat_2_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[4:6]]\n",
    "    \n",
    "summary_df[category_cols_single_sample[0]] = np.average(summary_df[cat_0_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[0:2],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_single_sample[1]] = np.average(summary_df[cat_1_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[2:4],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_single_sample[2]] = np.average(summary_df[cat_2_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[4:6],\n",
    "                                                        axis=1)\n",
    "summary_df[\"Overall Score\"] = np.average(summary_df[category_cols_single_sample[:3]],\n",
    "                                         weights=category_col_weights_single_sample[:3],\n",
    "                                         axis=1)\n",
    " \n",
    "# Reformat for plot\n",
    "summary_df.replace({\"nichecompass_gatv2conv\": \"NicheCompass\",\n",
    "                    \"nichecompass_gcnconv\": \"NicheCompass Light\",\n",
    "                    \"staci\": \"STACI\",\n",
    "                    \"deeplinc\": \"DeepLinc\",\n",
    "                    \"expimap\": \"expiMap\",\n",
    "                    \"graphst\": \"GraphST\",\n",
    "                    \"cellcharter\": \"CellCharter\",\n",
    "                    \"banksy\": \"BANKSY\"}, inplace=True)\n",
    "\n",
    "# Filter for just second run\n",
    "summary_df = summary_df[summary_df[\"run_number\"] == 2]\n",
    "\n",
    "# Plot over all loss weights combinations\n",
    "# Prepare metrics table plot\n",
    "group_cols = [\"dataset\", \"model\"]\n",
    "aggregate_df = summary_df.groupby(group_cols).mean(\"Overall Score\").sort_values(\"Overall Score\", ascending=False)[\n",
    "    metric_cols_single_sample + [\"Overall Score\"]].reset_index()\n",
    "\n",
    "unrolled_df = pd.melt(aggregate_df, \n",
    "   id_vars=group_cols,\n",
    "   value_vars=metric_cols_single_sample + [\"Overall Score\"],\n",
    "   var_name=\"score_type\", \n",
    "   value_name=\"score\")\n",
    "\n",
    "# Create spatial indicator column\n",
    "def is_spatially_aware_model(row):\n",
    "    if row[\"model\"] in [\"NicheCompass\", \"STACI\", \"DeepLinc\", \"GraphST\", \"CellCharter\"]:\n",
    "        return True\n",
    "    return False\n",
    "unrolled_df[\"spatially_aware\"] = unrolled_df.apply(lambda row: is_spatially_aware_model(row), axis=1)\n",
    "unrolled_df = unrolled_df[[\"dataset\", \"spatially_aware\", \"model\", \"score_type\", \"score\"]]\n",
    "\n",
    "# Order datasets\n",
    "unrolled_df[\"dataset\"] = pd.Categorical(unrolled_df[\"dataset\"], categories=datasets, ordered=True)\n",
    "unrolled_df = unrolled_df.sort_values(by=\"dataset\")\n",
    "\n",
    "unrolled_df[\"model\"] = unrolled_df[\"model\"].replace(\"NicheCompass GATv2\", \"NicheCompass\")\n",
    "#unrolled_df[\"model\"] = unrolled_df[\"model\"].replace(\"NicheCompass GCN\", \"Mini NicheCompass\")\n",
    "\n",
    "# Plot table\n",
    "plot_simple_metrics_table(\n",
    "    df=unrolled_df,\n",
    "    model_col=\"model\",\n",
    "    model_col_width=1.6,\n",
    "    group_col=\"dataset\",\n",
    "    metric_cols=metric_cols_single_sample, # metric_cols_single_sample, category_cols_single_sample\n",
    "    metric_col_weights=metric_col_weights_single_sample, # metric_col_weights_single_sample, category_col_weights_single_sample\n",
    "    metric_col_titles=[col.replace(\" \", \"\\n\") for col in metric_col_titles_single_sample], # category_col_titles_single_sample\n",
    "    metric_col_width=0.8, # 0.8,\n",
    "    aggregate_col_width=1.2,\n",
    "    plot_width=8.5, # 32,\n",
    "    plot_height=8,\n",
    "    show=True,\n",
    "    save_dir=benchmarking_folder_path,\n",
    "    save_name=f\"benchmarking_metrics_slideseqv2_mouse_hippocampus_subsample_25pct_run2.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549166eb-1c9e-40fc-be42-8ccc705060e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fig. 3a: NicheCompass niches ###\n",
    "dataset = \"slideseqv2_mouse_hippocampus\"\n",
    "models = [\"nichecompass_gatv2conv\"]\n",
    "run_number = 2\n",
    "leiden_resolutions = [0.35]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    adata = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_{model}.h5ad\")\n",
    "    model = model.replace(\"_gcnconv\", \"\").replace(\"_gatv2conv\", \"\")\n",
    "    adata.obs[\"sample\"] = \"sample1\"\n",
    "    \n",
    "    print(\"\\nComputing neighbor graph...\")\n",
    "    # Use latent representation for UMAP generation\n",
    "    sc.pp.neighbors(adata,\n",
    "                    use_rep=f\"{model}_latent_run{run_number}\",\n",
    "                    key_added=f\"{model}_latent_run{run_number}\")\n",
    "\n",
    "    print(\"\\nComputing UMAP embedding...\")\n",
    "    sc.tl.umap(adata,\n",
    "               neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "        \n",
    "    print(\"\\nComputing Leiden clustering...\")\n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=leiden_resolutions[i],\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=0.125,\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[0]}\",\n",
    "                 restrict_to=(f\"run{run_number}_leiden_{leiden_resolutions[0]}\", [\"7\"]),\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=0.125,\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[0]}\",\n",
    "                 restrict_to=(f\"run{run_number}_leiden_{leiden_resolutions[0]}\", [\"7,1\"]),\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    niche_annotations = {\n",
    "        \"0\": \"Stratum\",\n",
    "        \"1\": \"Thalamus LD\",\n",
    "        \"2\": \"Cortical layer 5\",\n",
    "        \"3\": \"Thalamus LP\", \n",
    "        \"4\": \"Cortical layer 6b\",\n",
    "        \"5\": \"Corpus callosum\",\n",
    "        \"6\": \"Cortical layer 6a\",\n",
    "        \"7,0\": \"CA1\",\n",
    "        \"7,1,0\": \"CA1\",\n",
    "        \"7,1,1\": \"Fasciola cinerea (FC)\",\n",
    "        \"8\": \"CA2 & CA3\",\n",
    "        \"9\": \"Dentate gyrus\",\n",
    "        \"10\": \"Medial habenula (MH)\",\n",
    "        \"11\": \"Lateral habenula (LH)\",\n",
    "        \"12\": \"Cortical layer 2/3\",\n",
    "        \"13\": \"V3/CP\", # \"Third ventricle (V3) / choroid plexus (CP)\"\n",
    "    }\n",
    "\n",
    "    adata.obs[\"niche\"] = adata.obs[f\"run{run_number}_leiden_{leiden_resolutions[0]}\"].map(niche_annotations)\n",
    "\n",
    "    latent_cluster_colors = create_new_color_dict(\n",
    "        adata=adata,\n",
    "        cat_key=f\"run{run_number}_leiden_{leiden_resolutions[i]}\")\n",
    "    \n",
    "    niche_colors = {niche: latent_cluster_colors[cluster] for cluster, niche in niche_annotations.items()}\n",
    "    \n",
    "    plot_category_in_latent_and_physical_space(\n",
    "            adata=adata,\n",
    "            #figsize=(10, 20), for latent UMAP\n",
    "            plot_label=\"Latent Clusters\",\n",
    "            model_label={model},\n",
    "            cat_key=f\"niche\",\n",
    "            groups=None,\n",
    "            sample_key=\"sample\",\n",
    "            samples=[\"sample1\"], # =None for latent UMAP\n",
    "            cat_colors=niche_colors,\n",
    "            size=(720000 / len(adata)),\n",
    "            spot_size=30,\n",
    "            save_fig=True,\n",
    "            file_path=f\"{benchmarking_folder_path}/latent_clusters_{model}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfea977-b4c9-4bf6-b142-9cc384f7d1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fig. 3b: NicheCompass tissue niche hierarchy & composition ###\n",
    "model = \"nichecompass\"\n",
    "run_number = 2\n",
    "\n",
    "sc.tl.dendrogram(adata=adata,\n",
    "                 use_rep=f\"{model}_latent_run{run_number}\",\n",
    "                 linkage_method=\"ward\",\n",
    "                 groupby=\"niche\")\n",
    "\n",
    "fig, (ax) = plt.subplots(1, 1, figsize=(2, 5))\n",
    "sc.pl.dendrogram(\n",
    "    adata=adata,\n",
    "    groupby=\"niche\",\n",
    "    orientation=\"left\",\n",
    "    show=False,\n",
    "    save=f\"_{dataset}_{model}_run{run_number}\",\n",
    "    ax=ax)\n",
    "plt.show()\n",
    "if os.path.exists(benchmarking_folder_path + f\"/dendrogram_{dataset}_{model}_run{run_number}.pdf\"):\n",
    "    os.remove(benchmarking_folder_path + f\"/dendrogram_{dataset}_{model}_run{run_number}.pdf\")\n",
    "shutil.move(f\"./figures/dendrogram_{dataset}_{model}_run{run_number}.pdf\", benchmarking_folder_path)\n",
    "shutil.rmtree(\"./figures/\")\n",
    "\n",
    "cell_type_colors = create_new_color_dict(\n",
    "    adata=adata,\n",
    "    color_palette=\"cell_type_30\",\n",
    "    cat_key=\"cell_type\")\n",
    "\n",
    "tmp = pd.crosstab(adata.obs[\"niche\"], adata.obs[\"cell_type\"], normalize='index')\n",
    "tmp = tmp.reindex(adata.uns[\"dendrogram_niche\"][\"categories_ordered\"][::])\n",
    "ax = tmp.plot.barh(color=cell_type_colors, stacked=True, figsize=(6, 10)).legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "plt.yticks(fontsize=24)\n",
    "plt.xticks(fontsize=24)\n",
    "plt.xlabel(\"Cell Type Proportions\", fontsize=24)\n",
    "plt.savefig(f\"{benchmarking_folder_path}/niche_cell_type_proportions_{model}.svg\", bbox_inches='tight')\n",
    "\n",
    "# Compute cluster centroids for cortical layer niches\n",
    "embeddings = adata.obsm[f\"{model}_latent_run{run_number}\"]\n",
    "cluster_labels = adata.obs[\"niche\"]\n",
    "embeddings_df = pd.DataFrame(embeddings, index=adata.obs_names)\n",
    "embeddings_df['cluster_labels'] = cluster_labels.values\n",
    "centroids = embeddings_df.groupby('cluster_labels').mean()\n",
    "cortical_layers_centroids = centroids[centroids.index.str.contains(\"Cortical\")]\n",
    "\n",
    "# Compute average pairwise distance between centroids\n",
    "pairwise_distances = pdist(cortical_layers_centroids.to_numpy(), metric='euclidean')\n",
    "average_distance = np.mean(pairwise_distances)\n",
    "print(average_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea09eed-3b79-4364-a805-7bebb6fc0e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fig. 3c: GraphST niches ###\n",
    "dataset = \"slideseqv2_mouse_hippocampus\"\n",
    "models = [\"graphst\"]\n",
    "run_number = 2\n",
    "leiden_resolutions = [0.93]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    adata = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_{model}.h5ad\")\n",
    "    model = model.replace(\"_gcnconv\", \"\").replace(\"_gatv2conv\", \"\")\n",
    "    adata.obs[\"sample\"] = \"sample1\"\n",
    "    \n",
    "    print(\"\\nComputing neighbor graph...\")\n",
    "    # Use latent representation for UMAP generation\n",
    "    sc.pp.neighbors(adata,\n",
    "                    use_rep=f\"{model}_latent_run{run_number}\",\n",
    "                    key_added=f\"{model}_latent_run{run_number}\")\n",
    "\n",
    "    print(\"\\nComputing UMAP embedding...\")\n",
    "    sc.tl.umap(adata,\n",
    "               neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "        \n",
    "    print(\"\\nComputing Leiden clustering...\")\n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=leiden_resolutions[i],\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=0.4,\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[0]}\",\n",
    "                 restrict_to=(f\"run{run_number}_leiden_{leiden_resolutions[0]}\", [\"0\"]),\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=0.1,\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[0]}\",\n",
    "                 restrict_to=(f\"run{run_number}_leiden_{leiden_resolutions[0]}\", [\"7\"]),\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "\n",
    "    niche_annotations = {\n",
    "        \"0,0\": \"Cortical layer 2/3\",\n",
    "        \"0,1\": \"Cortical layer 5\",\n",
    "        \"0,2\": \"Cortical layer 6a\",\n",
    "        \"1\": \"Stratum\",\n",
    "        \"2\": \"Thalamus LD\",\n",
    "        \"3\": \"Corpus callosum\",\n",
    "        \"4\": \"Cortical layer 6b\",\n",
    "        \"5\": \"Thalamus LP\",\n",
    "        \"6\": \"CA1\",\n",
    "        \"7,0\": \"CA3\",\n",
    "        \"7,1\": \"Fasciola cinerea (FC) & CA2\",\n",
    "        \"8\": \"Dentate gyrus\",\n",
    "        \"9\": \"Artifact 1\",\n",
    "        \"10\": \"Third ventricle (V3) / choroid plexus (CP)\",\n",
    "        \"11\": \"Medial habenula (MH)\",\n",
    "        \"12\": \"Lateral habenula (LH)\",\n",
    "        \"13\": \"Artifact 2\"}\n",
    "\n",
    "    adata.obs[\"niche\"] = adata.obs[f\"run{run_number}_leiden_0.93\"].map(niche_annotations)\n",
    "\n",
    "    niche_colors = {            \n",
    "        'Stratum': '#8BE0A4',\n",
    "        'Thalamus LD': '#F6CF71',\n",
    "        'Cortical layer 6b': '#B497E7',\n",
    "        'Thalamus LP': '#87C55F',\n",
    "        'Corpus callosum': '#9D88A2',\n",
    "        'Cortical layer 5': '#9EB9F3',\n",
    "        'CA1': '#C38D9E',\n",
    "        'CA3': '#DCB0F2',\n",
    "        'Dentate gyrus': '#D3B484',\n",
    "        'Medial habenula (MH)': '#F89C74',\n",
    "        'Lateral habenula (LH)': '#C9DB74',\n",
    "        'Third ventricle (V3) / choroid plexus (CP)': '#B3B3B3',\n",
    "        'Cortical layer 2/3': '#DAB6C4',\n",
    "        'Cortical layer 6a': \"#66C5CC\",\n",
    "        'Fasciola cinerea (FC) & CA2': \"#276A8C\",\n",
    "        'Artifact 1': \"#FF4D4D\",\n",
    "        'Artifact 2': \"#D2691E\"}\n",
    "    \n",
    "    plot_category_in_latent_and_physical_space(\n",
    "            adata=adata,\n",
    "            figsize=(10, 20), #for latent UMAP\n",
    "            plot_label=\"Latent Clusters\",\n",
    "            model_label={model},\n",
    "            cat_key=f\"niche\",\n",
    "            groups=None,\n",
    "            sample_key=\"sample\",\n",
    "            samples=[\"sample1\"],\n",
    "            cat_colors=niche_colors,\n",
    "            size=(720000 / len(adata)),\n",
    "            spot_size=30,\n",
    "            save_fig=True,\n",
    "            file_path=f\"{benchmarking_folder_path}/latent_clusters_{model}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d3e014-6b0e-4e54-a1cc-09b9d02cfa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fig. 3c: GraphST tissue niche hierarchy ###\n",
    "model = \"graphst\"\n",
    "run_number = 2\n",
    "\n",
    "sc.tl.dendrogram(adata=adata,\n",
    "                 use_rep=f\"{model}_latent_run{run_number}\",\n",
    "                 linkage_method=\"ward\",\n",
    "                 groupby=\"niche\")\n",
    "\n",
    "fig, (ax) = plt.subplots(1, 1, figsize=(2, 5))\n",
    "sc.pl.dendrogram(\n",
    "    adata=adata,\n",
    "    groupby=\"niche\",\n",
    "    orientation=\"left\",\n",
    "    show=False,\n",
    "    save=f\"_{dataset}_{model}_run{run_number}\",\n",
    "    ax=ax)\n",
    "plt.show()\n",
    "if os.path.exists(benchmarking_folder_path + f\"/dendrogram_{dataset}_{model}_run{run_number}.pdf\"):\n",
    "    os.remove(benchmarking_folder_path + f\"/dendrogram_{dataset}_{model}_run{run_number}.pdf\")\n",
    "shutil.move(f\"./figures/dendrogram_{dataset}_{model}_run{run_number}.pdf\", benchmarking_folder_path)\n",
    "shutil.rmtree(\"./figures/\")\n",
    "\n",
    "cell_type_colors = create_new_color_dict(\n",
    "    adata=adata,\n",
    "    color_palette=\"cell_type_30\",\n",
    "    cat_key=\"cell_type\")\n",
    "\n",
    "tmp = pd.crosstab(adata.obs[\"niche\"], adata.obs[\"cell_type\"], normalize='index')\n",
    "tmp = tmp.reindex(adata.uns[\"dendrogram_niche\"][\"categories_ordered\"][::])\n",
    "ax = tmp.plot.barh(color=cell_type_colors, stacked=True, figsize=(6, 10)).legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "plt.yticks(fontsize=24)\n",
    "plt.xticks(fontsize=24)\n",
    "plt.xlabel(\"Cell Type Proportions\", fontsize=24)\n",
    "plt.savefig(f\"{benchmarking_folder_path}/niche_cell_type_proportions_{model}.svg\", bbox_inches='tight')\n",
    "\n",
    "# Compute cluster centroids for cortical layer niches\n",
    "embeddings = adata.obsm[f\"{model}_latent_run{run_number}\"]\n",
    "cluster_labels = adata.obs[\"niche\"]\n",
    "embeddings_df = pd.DataFrame(embeddings, index=adata.obs_names)\n",
    "embeddings_df['cluster_labels'] = cluster_labels.values\n",
    "centroids = embeddings_df.groupby('cluster_labels').mean()\n",
    "cortical_layers_centroids = centroids[centroids.index.str.contains(\"Cortical\")]\n",
    "\n",
    "# Compute average pairwise distance between centroids\n",
    "pairwise_distances = pdist(cortical_layers_centroids.to_numpy(), metric='euclidean')\n",
    "average_distance = np.mean(pairwise_distances)\n",
    "print(average_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d089d746-387b-4e78-8c7a-af3f07e2ebf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fig. 3c: CellCharter niches ###\n",
    "dataset = \"slideseqv2_mouse_hippocampus\"\n",
    "models = [\"cellcharter\"]\n",
    "run_number = 2\n",
    "leiden_resolutions = [0.8]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    adata = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_{model}.h5ad\")\n",
    "    model = model.replace(\"_gcnconv\", \"\").replace(\"_gatv2conv\", \"\")\n",
    "    adata.obs[\"sample\"] = \"sample1\"\n",
    "    \n",
    "    print(\"\\nComputing neighbor graph...\")\n",
    "    # Use latent representation for UMAP generation\n",
    "    sc.pp.neighbors(adata,\n",
    "                    use_rep=f\"{model}_latent_run{run_number}\",\n",
    "                    key_added=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    print(\"\\nComputing UMAP embedding...\")\n",
    "    sc.tl.umap(adata,\n",
    "               neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "\n",
    "    # Use cellcharter clustering\n",
    "    #gmm = Cluster(\n",
    "    #    n_clusters=12, \n",
    "    #    random_state=0,\n",
    "    #    # If running on GPU\n",
    "    #    #trainer_params=dict(accelerator='gpu', devices=1)\n",
    "    #)\n",
    "    #gmm.fit(adata, use_rep=f\"{model}_latent_run{run_number}\")\n",
    "    #adata.obs[\"spatial_clusters\"] = gmm.predict(adata, use_rep=f\"{model}_latent_run{run_number}\").astype(\"str\")\n",
    "    \n",
    "    print(\"\\nComputing Leiden clustering...\")\n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=leiden_resolutions[i],\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=0.3,\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "                 restrict_to=(f\"run{run_number}_leiden_{leiden_resolutions[i]}\", [\"0\"]),\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=0.05,\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "                 restrict_to=(f\"run{run_number}_leiden_{leiden_resolutions[i]}\", [\"12\"]),\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    niche_annotations = {\n",
    "        \"0,0\": \"Cortical layer 5\",\n",
    "        \"0,1\": \"Cortical layer 6a\",\n",
    "        \"1\": \"Thalamus LD\",\n",
    "        \"2\": \"Stratum\",\n",
    "        \"3\": \"Thalamus LP\",\n",
    "        \"4\": \"CA1\",\n",
    "        \"5\": \"Corpus callosum\", # \"Artifact 1\",\n",
    "        \"6\": \"Cortical layer 6b\",\n",
    "        \"7\": \"CA2 & CA3\",\n",
    "        \"8\": \"Dentate gyrus\",\n",
    "        \"9\": \"Lateral habenula (LH)\",\n",
    "        \"10\": \"Medial habenula (MH)\",\n",
    "        \"11\": \"Cortical layer 2/3\",\n",
    "        \"12,0\": \"Third ventricle (V3) / choroid plexus (CP)\",\n",
    "        \"12,1\": \"Fasciola cinerea (FC)\",\n",
    "        \"13\": \"Cell Type Artifact\",\n",
    "        \"14\": \"Thalamus Boundary\",\n",
    "        \"15\": \"Lateral Ventricle\"}\n",
    "\n",
    "    adata.obs[\"niche\"] = adata.obs[f\"run{run_number}_leiden_{leiden_resolutions[i]}\"].map(niche_annotations)\n",
    "\n",
    "    niche_colors = {            \n",
    "        'Stratum': '#8BE0A4',\n",
    "        'Thalamus LD': '#F6CF71',\n",
    "        'Cortical layer 6b': '#B497E7',\n",
    "        'Thalamus LP': '#87C55F',\n",
    "        'Corpus callosum': '#9D88A2',\n",
    "        'Cortical layer 5': '#9EB9F3',\n",
    "        'CA1': '#C38D9E',\n",
    "        'CA2 & CA3': '#DCB0F2',\n",
    "        'Dentate gyrus': '#D3B484',\n",
    "        'Medial habenula (MH)': '#F89C74',\n",
    "        'Lateral habenula (LH)': '#C9DB74',\n",
    "        'Third ventricle (V3) / choroid plexus (CP)': '#B3B3B3',\n",
    "        'Cortical layer 2/3': '#DAB6C4',\n",
    "        'Cortical layer 6a': \"#66C5CC\",\n",
    "        'Fasciola cinerea (FC)': \"#276A8C\",\n",
    "        'Thalamus Boundary': \"#FF4D4D\",\n",
    "        'Lateral Ventricle': \"#D2691E\",\n",
    "        'Artifact 1': \"#D2121E\"}\n",
    "    \n",
    "    plot_category_in_latent_and_physical_space(\n",
    "            adata=adata,\n",
    "            figsize=(10, 20), #for latent UMAP\n",
    "            plot_label=\"Latent Clusters\",\n",
    "            model_label=model,\n",
    "            cat_key=\"niche\",\n",
    "            groups=None,\n",
    "            sample_key=\"sample\",\n",
    "            samples=[\"sample1\"],\n",
    "            cat_colors=niche_colors,\n",
    "            size=(720000 / len(adata)),\n",
    "            spot_size=30,\n",
    "            save_fig=True,\n",
    "            file_path=f\"{benchmarking_folder_path}/latent_clusters_{model}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e030dc-47af-472d-82cf-77a478abe851",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fig. 3c: Cellcharter tissue niche hierarchy ###\n",
    "model = \"cellcharter\"\n",
    "run_number = 2\n",
    "\n",
    "sc.tl.dendrogram(adata=adata,\n",
    "                 use_rep=f\"{model}_latent_run{run_number}\",\n",
    "                 linkage_method=\"ward\",\n",
    "                 groupby=\"niche\")\n",
    "\n",
    "fig, (ax) = plt.subplots(1, 1, figsize=(2, 5))\n",
    "sc.pl.dendrogram(\n",
    "    adata=adata,\n",
    "    groupby=\"niche\",\n",
    "    orientation=\"left\",\n",
    "    show=False,\n",
    "    save=f\"_{dataset}_{model}_run{run_number}\",\n",
    "    ax=ax)\n",
    "plt.show()\n",
    "if os.path.exists(benchmarking_folder_path + f\"/dendrogram_{dataset}_{model}_run{run_number}.pdf\"):\n",
    "    os.remove(benchmarking_folder_path + f\"/dendrogram_{dataset}_{model}_run{run_number}.pdf\")\n",
    "shutil.move(f\"./figures/dendrogram_{dataset}_{model}_run{run_number}.pdf\", benchmarking_folder_path)\n",
    "shutil.rmtree(\"./figures/\")\n",
    "\n",
    "cell_type_colors = create_new_color_dict(\n",
    "    adata=adata,\n",
    "    color_palette=\"cell_type_30\",\n",
    "    cat_key=\"cell_type\")\n",
    "\n",
    "tmp = pd.crosstab(adata.obs[\"niche\"], adata.obs[\"cell_type\"], normalize='index')\n",
    "tmp = tmp.reindex(adata.uns[\"dendrogram_niche\"][\"categories_ordered\"][::])\n",
    "ax = tmp.plot.barh(color=cell_type_colors, stacked=True, figsize=(6, 10)).legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "plt.yticks(fontsize=24)\n",
    "plt.xticks(fontsize=24)\n",
    "plt.xlabel(\"Cell Type Proportions\", fontsize=24)\n",
    "plt.savefig(f\"{benchmarking_folder_path}/niche_cell_type_proportions_{model}.svg\", bbox_inches='tight')\n",
    "\n",
    "# Compute cluster centroids for cortical layer niches\n",
    "embeddings = adata.obsm[f\"{model}_latent_run{run_number}\"]\n",
    "cluster_labels = adata.obs[\"niche\"]\n",
    "embeddings_df = pd.DataFrame(embeddings, index=adata.obs_names)\n",
    "embeddings_df['cluster_labels'] = cluster_labels.values\n",
    "centroids = embeddings_df.groupby('cluster_labels').mean()\n",
    "cortical_layers_centroids = centroids[centroids.index.str.contains(\"Cortical\")]\n",
    "\n",
    "# Compute average pairwise distance between centroids\n",
    "pairwise_distances = pdist(cortical_layers_centroids.to_numpy(), metric='euclidean')\n",
    "average_distance = np.mean(pairwise_distances)\n",
    "print(average_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231be1cd-5d63-4780-804c-594c5683651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fig. 3c: BANKSY niches ###\n",
    "dataset = \"slideseqv2_mouse_hippocampus\"\n",
    "models = [\"banksy\"]\n",
    "run_number = 2\n",
    "leiden_resolutions = [0.35]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    adata = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_{model}.h5ad\")\n",
    "    model = model.replace(\"_gcnconv\", \"\").replace(\"_gatv2conv\", \"\")\n",
    "    adata.obs[\"sample\"] = \"sample1\"\n",
    "    \n",
    "    print(\"\\nComputing neighbor graph...\")\n",
    "    # Use latent representation for UMAP generation\n",
    "    sc.pp.neighbors(adata,\n",
    "                    use_rep=f\"{model}_latent_run{run_number}\",\n",
    "                    key_added=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    print(\"\\nComputing UMAP embedding...\")\n",
    "    sc.tl.umap(adata,\n",
    "               neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    print(\"\\nComputing Leiden clustering...\")\n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=leiden_resolutions[i],\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=0.2,\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[0]}\",\n",
    "                 restrict_to=(f\"run{run_number}_leiden_{leiden_resolutions[0]}\", [\"0\"]),\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=0.15,\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[0]}\",\n",
    "                 restrict_to=(f\"run{run_number}_leiden_{leiden_resolutions[0]}\", [\"1\"]),\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=0.05,\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[0]}\",\n",
    "                 restrict_to=(f\"run{run_number}_leiden_{leiden_resolutions[0]}\", [\"4\"]),\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    niche_annotations = {\n",
    "        \"0,0\": \"Cortical layer 6b\",\n",
    "        \"0,1\": \"Cortical layer 5\",\n",
    "        \"0,2\": \"Cortical layer 6a\",\n",
    "        \"1,0\": \"Thalamus LD\",\n",
    "        \"1,1\": \"Thalamus LP\",\n",
    "        \"1,2\": \"Artifact 2\",\n",
    "        \"2\": \"Stratum\",\n",
    "        \"3\": \"Corpus callosum\",\n",
    "        \"4,0\": \"CA2 & CA3\",\n",
    "        \"4,1\": \"Fasciola cinerea (FC)\",\n",
    "        \"5\": \"CA1\",\n",
    "        \"6\": \"Dentate gyrus\",\n",
    "        \"7\": \"Lateral habenula (LH)\", #\"Artifact 1\",\n",
    "        \"8\": \"Cortical layer 2/3\",\n",
    "        \"9\": \"Third ventricle (V3) / choroid plexus (CP)\",\n",
    "        \"10\": \"Artifact 1\",\n",
    "        \"11\": \"Dentate gyrus\",\n",
    "        \"12\": \"Medial habenula (MH)\"}\n",
    "\n",
    "    adata.obs[\"niche\"] = adata.obs[f\"run{run_number}_leiden_{leiden_resolutions[i]}\"].map(niche_annotations)\n",
    "\n",
    "    niche_colors = {            \n",
    "        'Stratum': '#8BE0A4',\n",
    "        'Thalamus LD': '#F6CF71',\n",
    "        'Cortical layer 6b': '#B497E7',\n",
    "        'Thalamus LP': '#87C55F',\n",
    "        'Corpus callosum': '#9D88A2',\n",
    "        'Cortical layer 5': '#9EB9F3',\n",
    "        'CA1': '#C38D9E',\n",
    "        'CA2 & CA3': '#DCB0F2',\n",
    "        'Dentate gyrus': '#D3B484',\n",
    "        'Medial habenula (MH)': '#F89C74',\n",
    "        'Lateral habenula (LH)': '#C9DB74',\n",
    "        'Third ventricle (V3) / choroid plexus (CP)': '#B3B3B3',\n",
    "        'Cortical layer 2/3': '#DAB6C4',\n",
    "        'Cortical layer 6a': \"#66C5CC\",\n",
    "        'Fasciola cinerea (FC)': \"#276A8C\",\n",
    "        'Artifact 1': \"#FF4D4D\",\n",
    "        'Artifact 2': \"#D2691E\"}\n",
    "    \n",
    "    plot_category_in_latent_and_physical_space(\n",
    "            adata=adata,\n",
    "            figsize=(10, 20), #for latent UMAP\n",
    "            plot_label=\"Latent Clusters\",\n",
    "            model_label={model},\n",
    "            cat_key=\"niche\",\n",
    "            groups=None,\n",
    "            sample_key=\"sample\",\n",
    "            samples=[\"sample1\"],\n",
    "            cat_colors=niche_colors,\n",
    "            size=(720000 / len(adata)),\n",
    "            spot_size=30,\n",
    "            save_fig=True,\n",
    "            file_path=f\"{benchmarking_folder_path}/latent_clusters_{model}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec302f9-d73c-4f6b-9809-7ae8a89740dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fig. 3c: Banksy tissue niche hierarchy ###\n",
    "model = \"banksy\"\n",
    "run_number = 2\n",
    "\n",
    "sc.tl.dendrogram(adata=adata,\n",
    "                 use_rep=f\"{model}_latent_run{run_number}\",\n",
    "                 linkage_method=\"ward\",\n",
    "                 groupby=\"niche\")\n",
    "\n",
    "fig, (ax) = plt.subplots(1, 1, figsize=(2, 5))\n",
    "sc.pl.dendrogram(\n",
    "    adata=adata,\n",
    "    groupby=\"niche\",\n",
    "    orientation=\"left\",\n",
    "    show=False,\n",
    "    save=f\"_{dataset}_{model}_run{run_number}\",\n",
    "    ax=ax)\n",
    "plt.show()\n",
    "if os.path.exists(benchmarking_folder_path + f\"/dendrogram_{dataset}_{model}_run{run_number}.pdf\"):\n",
    "    os.remove(benchmarking_folder_path + f\"/dendrogram_{dataset}_{model}_run{run_number}.pdf\")\n",
    "shutil.move(f\"./figures/dendrogram_{dataset}_{model}_run{run_number}.pdf\", benchmarking_folder_path)\n",
    "shutil.rmtree(\"./figures/\")\n",
    "\n",
    "cell_type_colors = create_new_color_dict(\n",
    "    adata=adata,\n",
    "    color_palette=\"cell_type_30\",\n",
    "    cat_key=\"cell_type\")\n",
    "\n",
    "tmp = pd.crosstab(adata.obs[\"niche\"], adata.obs[\"cell_type\"], normalize='index')\n",
    "tmp = tmp.reindex(adata.uns[\"dendrogram_niche\"][\"categories_ordered\"][::])\n",
    "ax = tmp.plot.barh(color=cell_type_colors, stacked=True, figsize=(6, 10)).legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "plt.yticks(fontsize=24)\n",
    "plt.xticks(fontsize=24)\n",
    "plt.xlabel(\"Cell Type Proportions\", fontsize=24)\n",
    "plt.savefig(f\"{benchmarking_folder_path}/niche_cell_type_proportions_{model}.svg\", bbox_inches='tight')\n",
    "\n",
    "# Compute cluster centroids for cortical layer niches\n",
    "embeddings = adata.obsm[f\"{model}_latent_run{run_number}\"]\n",
    "cluster_labels = adata.obs[\"niche\"]\n",
    "embeddings_df = pd.DataFrame(embeddings, index=adata.obs_names)\n",
    "embeddings_df['cluster_labels'] = cluster_labels.values\n",
    "centroids = embeddings_df.groupby('cluster_labels').mean()\n",
    "cortical_layers_centroids = centroids[centroids.index.str.contains(\"Cortical\")]\n",
    "\n",
    "# Compute average pairwise distance between centroids\n",
    "pairwise_distances = pdist(cortical_layers_centroids.to_numpy(), metric='euclidean')\n",
    "average_distance = np.mean(pairwise_distances)\n",
    "print(average_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc33d7d-e9dd-40b1-80e0-453071ffd25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fig. 3c: DeepLinc niches ###\n",
    "dataset = \"slideseqv2_mouse_hippocampus\"\n",
    "models = [\"deeplinc\"]\n",
    "run_number = 2\n",
    "leiden_resolutions = [1.1]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    adata = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_{model}.h5ad\")\n",
    "    model = model.replace(\"_gcnconv\", \"\").replace(\"_gatv2conv\", \"\")\n",
    "    adata.obs[\"sample\"] = \"sample1\"\n",
    "    \n",
    "    print(\"\\nComputing neighbor graph...\")\n",
    "    # Use latent representation for UMAP generation\n",
    "    sc.pp.neighbors(adata,\n",
    "                    use_rep=f\"{model}_latent_run{run_number}\",\n",
    "                    key_added=f\"{model}_latent_run{run_number}\")\n",
    "\n",
    "    print(\"\\nComputing UMAP embedding...\")\n",
    "    sc.tl.umap(adata,\n",
    "               neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "        \n",
    "    print(\"\\nComputing Leiden clustering...\")\n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=leiden_resolutions[i],\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=0.2,\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[0]}\",\n",
    "                 restrict_to=(f\"run{run_number}_leiden_{leiden_resolutions[0]}\", [\"0\"]),\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=0.125,\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[0]}\",\n",
    "                 restrict_to=(f\"run{run_number}_leiden_{leiden_resolutions[0]}\", [\"8\"]),\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    niche_annotations = {\n",
    "        \"0,0\": \"Cortical layer 6a\",\n",
    "        \"0,1\": \"Cortical layer 5\",\n",
    "        \"1\": \"Thalamus LD\",\n",
    "        \"2\": \"Cortical layer 6b\",\n",
    "        \"3\": \"Thalamus LP\",\n",
    "        \"4\": \"Corpus callosum\",\n",
    "        \"5\": \"Stratum\",\n",
    "        \"6\": \"CA1\",\n",
    "        \"7\": \"Dentate gyrus\",\n",
    "        \"8,0\": \"Lateral habenula (LH)\",\n",
    "        \"8,1\": \"Medial habenula (MH)\",\n",
    "        \"9\": \"CA2 & CA3\",\n",
    "        \"10\": \"Cortical layer 2/3\",\n",
    "        \"11\": \"Third ventricle (V3) / choroid plexus (CP)\",\n",
    "        \"12\": \"Thalamus Boundary\",\n",
    "        \"13\": \"Fasciola cinerea (FC)\"}\n",
    "\n",
    "    adata.obs[\"niche\"] = adata.obs[f\"run{run_number}_leiden_{leiden_resolutions[0]}\"].map(niche_annotations)\n",
    "    \n",
    "    niche_colors = {            \n",
    "        'Stratum': '#8BE0A4',\n",
    "        'Thalamus LD': '#F6CF71',\n",
    "        'Cortical layer 6b': '#B497E7',\n",
    "        'Thalamus LP': '#87C55F',\n",
    "        'Corpus callosum': '#9D88A2',\n",
    "        'Cortical layer 5': '#9EB9F3',\n",
    "        'CA1': '#C38D9E',\n",
    "        'CA2 & CA3': '#DCB0F2',\n",
    "        'Dentate gyrus': '#D3B484',\n",
    "        'Medial habenula (MH)': '#F89C74',\n",
    "        'Lateral habenula (LH)': '#C9DB74',\n",
    "        'Third ventricle (V3) / choroid plexus (CP)': '#B3B3B3',\n",
    "        'Cortical layer 2/3': '#DAB6C4',\n",
    "        'Cortical layer 6a': \"#66C5CC\",\n",
    "        'Fasciola cinerea (FC)': \"#276A8C\",\n",
    "        'Thalamus Boundary': \"#FF4D4D\"}\n",
    "    \n",
    "    plot_category_in_latent_and_physical_space(\n",
    "            adata=adata,\n",
    "            figsize=(10, 20), #for latent UMAP\n",
    "            plot_label=\"Latent Clusters\",\n",
    "            model_label={model},\n",
    "            cat_key=\"niche\",\n",
    "            groups=None,\n",
    "            sample_key=\"sample\",\n",
    "            samples=[\"sample1\"],\n",
    "            cat_colors=niche_colors,\n",
    "            size=(720000 / len(adata)),\n",
    "            spot_size=30,\n",
    "            save_fig=True,\n",
    "            file_path=f\"{benchmarking_folder_path}/latent_clusters_{model}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e8aa8e-34bb-4535-8727-6ac5ed7404fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fig. 3c: DeepLinc tissue niche hierarchy ###\n",
    "model = \"deeplinc\"\n",
    "run_number = 2\n",
    "\n",
    "sc.tl.dendrogram(adata=adata,\n",
    "                 use_rep=f\"{model}_latent_run{run_number}\",\n",
    "                 linkage_method=\"ward\",\n",
    "                 groupby=\"niche\")\n",
    "\n",
    "fig, (ax) = plt.subplots(1, 1, figsize=(2, 5))\n",
    "sc.pl.dendrogram(\n",
    "    adata=adata,\n",
    "    groupby=\"niche\",\n",
    "    orientation=\"left\",\n",
    "    show=False,\n",
    "    save=f\"_{dataset}_{model}_run{run_number}\",\n",
    "    ax=ax)\n",
    "plt.show()\n",
    "if os.path.exists(benchmarking_folder_path + f\"/dendrogram_{dataset}_{model}_run{run_number}.pdf\"):\n",
    "    os.remove(benchmarking_folder_path + f\"/dendrogram_{dataset}_{model}_run{run_number}.pdf\")\n",
    "shutil.move(f\"./figures/dendrogram_{dataset}_{model}_run{run_number}.pdf\", benchmarking_folder_path)\n",
    "shutil.rmtree(\"./figures/\")\n",
    "\n",
    "cell_type_colors = create_new_color_dict(\n",
    "    adata=adata,\n",
    "    color_palette=\"cell_type_30\",\n",
    "    cat_key=\"cell_type\")\n",
    "\n",
    "tmp = pd.crosstab(adata.obs[\"niche\"], adata.obs[\"cell_type\"], normalize='index')\n",
    "tmp = tmp.reindex(adata.uns[\"dendrogram_niche\"][\"categories_ordered\"][::])\n",
    "ax = tmp.plot.barh(color=cell_type_colors, stacked=True, figsize=(6, 10)).legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "plt.yticks(fontsize=24)\n",
    "plt.xticks(fontsize=24)\n",
    "plt.xlabel(\"Cell Type Proportions\", fontsize=24)\n",
    "plt.savefig(f\"{benchmarking_folder_path}/niche_cell_type_proportions_{model}.svg\", bbox_inches='tight')\n",
    "\n",
    "# Compute cluster centroids for cortical layer niches\n",
    "embeddings = adata.obsm[f\"{model}_latent_run{run_number}\"]\n",
    "cluster_labels = adata.obs[\"niche\"]\n",
    "embeddings_df = pd.DataFrame(embeddings, index=adata.obs_names)\n",
    "embeddings_df['cluster_labels'] = cluster_labels.values\n",
    "centroids = embeddings_df.groupby('cluster_labels').mean()\n",
    "cortical_layers_centroids = centroids[centroids.index.str.contains(\"Cortical\")]\n",
    "\n",
    "# Compute average pairwise distance between centroids\n",
    "pairwise_distances = pdist(cortical_layers_centroids.to_numpy(), metric='euclidean')\n",
    "average_distance = np.mean(pairwise_distances)\n",
    "print(average_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5752ea02-a188-437c-99e9-2c88c670a60e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Supplementary fig. 12d: cell types ###\n",
    "plot_category_in_latent_and_physical_space(\n",
    "        adata=adata,\n",
    "        plot_label=\"Cell Types\",\n",
    "        model_label=None,\n",
    "        cat_key=f\"cell_type\",\n",
    "        groups=None,\n",
    "        sample_key=\"sample\",\n",
    "        samples=[\"sample1\"], # =None for latent UMAP\n",
    "        cat_colors=cell_type_colors,\n",
    "        size=(720000 / len(adata)),\n",
    "        spot_size=30,\n",
    "        save_fig=True,\n",
    "        file_path=f\"{benchmarking_folder_path}/cell_types.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e206d09-de9a-46d5-8f4b-54daafb9902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supplementary fig. 12c: scVI niches ###\n",
    "dataset = \"slideseqv2_mouse_hippocampus\"\n",
    "models = [\"scvi\"]\n",
    "run_number = 2\n",
    "leiden_resolutions = [0.9]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    adata = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_{model}.h5ad\")\n",
    "    model = model.replace(\"_gcnconv\", \"\").replace(\"_gatv2conv\", \"\")\n",
    "    adata.obs[\"sample\"] = \"sample1\"\n",
    "    \n",
    "    print(\"\\nComputing neighbor graph...\")\n",
    "    # Use latent representation for UMAP generation\n",
    "    sc.pp.neighbors(adata,\n",
    "                    use_rep=f\"{model}_latent_run{run_number}\",\n",
    "                    key_added=f\"{model}_latent_run{run_number}\")\n",
    "\n",
    "    print(\"\\nComputing UMAP embedding...\")\n",
    "    sc.tl.umap(adata,\n",
    "               neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "        \n",
    "    print(\"\\nComputing Leiden clustering...\")\n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=leiden_resolutions[i],\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    latent_cluster_colors = {\n",
    "        \"0\": \"#66C5CC\",\n",
    "        \"1\": \"#F6CF71\",\n",
    "        \"2\": \"#87C55F\",\n",
    "        \"3\": \"#8BE0A4\",\n",
    "        \"4\": \"#9D88A2\",\n",
    "        \"5\": \"#F89C74\",\n",
    "        \"6\": \"#D2121E\",\n",
    "        \"7\": \"#D2691E\",\n",
    "        \"8\": \"#D3B484\",\n",
    "        \"9\": \"#9EB9F3\",\n",
    "        \"10\": \"#C38D9E\",\n",
    "        \"11\": \"#DCB0F2\",\n",
    "        \"12\": \"#B497E7\",\n",
    "        \"13\": \"#DAB6C4\",\n",
    "        \"14\": \"#B3B3B3\",\n",
    "        \"15\": \"#FF4D4D\"}\n",
    "    \n",
    "    plot_category_in_latent_and_physical_space(\n",
    "            adata=adata,\n",
    "            plot_label=\"Latent Clusters\",\n",
    "            model_label={model},\n",
    "            cat_key=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "            groups=None,\n",
    "            sample_key=\"sample\",\n",
    "            samples=[\"sample1\"],\n",
    "            cat_colors=latent_cluster_colors,\n",
    "            size=(720000 / len(adata)),\n",
    "            spot_size=30,\n",
    "            save_fig=True,\n",
    "            file_path=f\"{benchmarking_folder_path}/latent_clusters_{model}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a49489-460b-4524-9d0c-7e22d5d74105",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supplementary fig. 12c: expiMap niches ###\n",
    "dataset = \"slideseqv2_mouse_hippocampus\"\n",
    "models = [\"expimap\"]\n",
    "run_number = 2\n",
    "leiden_resolutions = [1.75] # [1.59]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    adata = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_{model}.h5ad\")\n",
    "    model = model.replace(\"_gcnconv\", \"\").replace(\"_gatv2conv\", \"\")\n",
    "    adata.obs[\"sample\"] = \"sample1\"\n",
    "    \n",
    "    print(\"\\nComputing neighbor graph...\")\n",
    "    # Use latent representation for UMAP generation\n",
    "    sc.pp.neighbors(adata,\n",
    "                    use_rep=f\"{model}_latent_run{run_number}\",\n",
    "                    key_added=f\"{model}_latent_run{run_number}\")\n",
    "\n",
    "    print(\"\\nComputing UMAP embedding...\")\n",
    "    sc.tl.umap(adata,\n",
    "               neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "        \n",
    "    print(\"\\nComputing Leiden clustering...\")\n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=leiden_resolutions[i],\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    latent_cluster_colors = {\n",
    "        \"0\": \"#F6CF71\", \n",
    "        \"1\": \"#9D88A2\", \n",
    "        \"2\": \"#66C5CC\",\n",
    "        \"3\": \"#87C55F\",\n",
    "        \"4\": \"#8BE0A4\", #\"#FF4D4D\",\n",
    "        \"5\": \"#F89C74\",\n",
    "        \"6\": \"#C38D9E\", \n",
    "        \"7\": \"#D2691E\",\n",
    "        \"8\": \"#9EB9F3\",\n",
    "        \"9\": \"#D3B484\",\n",
    "        \"10\": \"#9EB9F3\", #\"#D2121E\",\n",
    "        \"11\": \"#D2691E\",\n",
    "        \"12\": \"#DCB0F2\",\n",
    "        \"13\": \"#B3B3B3\",\n",
    "        \"14\": \"#DAB6C4\",\n",
    "        \"15\": \"#B497E7\",}\n",
    "    \n",
    "    plot_category_in_latent_and_physical_space(\n",
    "            adata=adata,\n",
    "            plot_label=\"Latent Clusters\",\n",
    "            model_label={model},\n",
    "            cat_key=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "            groups=None,\n",
    "            sample_key=\"sample\",\n",
    "            samples=[\"sample1\"],\n",
    "            cat_colors=latent_cluster_colors,\n",
    "            size=(720000 / len(adata)),\n",
    "            spot_size=30,\n",
    "            save_fig=True,\n",
    "            file_path=f\"{benchmarking_folder_path}/latent_clusters_{model}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5785c046-b8bf-4f55-b61b-06c2b43c2990",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supplementary fig. 13: 25% subsample NicheCompass niches ###\n",
    "dataset = \"slideseqv2_mouse_hippocampus_subsample_25pct\"\n",
    "models = [\"nichecompass_gatv2conv\"]\n",
    "\n",
    "run_number = 2\n",
    "leiden_resolutions = [0.1]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    adata = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_{model}.h5ad\")\n",
    "    model = model.replace(\"_gcnconv\", \"\").replace(\"_gatv2conv\", \"\")\n",
    "    adata.obs[\"sample\"] = \"sample1\"\n",
    "    \n",
    "    print(\"\\nComputing neighbor graph...\")\n",
    "    # Use latent representation for UMAP generation\n",
    "    sc.pp.neighbors(adata,\n",
    "                    use_rep=f\"{model}_latent_run{run_number}\",\n",
    "                    key_added=f\"{model}_latent_run{run_number}\")\n",
    "\n",
    "    print(\"\\nComputing UMAP embedding...\")\n",
    "    sc.tl.umap(adata,\n",
    "               neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "        \n",
    "    print(\"\\nComputing Leiden clustering...\")\n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=leiden_resolutions[i],\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    latent_cluster_colors = {\n",
    "        \"0\": \"#8BE0A4\",\n",
    "        \"1\": \"#DCB0F2\",\n",
    "        \"2\": \"#66C5CC\",\n",
    "        \"3\": \"#F6CF71\",\n",
    "        \"4\": \"#9D88A2\",\n",
    "        \"5\": \"#D3B484\",\n",
    "        \"6\": \"#C38D9E\"}\n",
    "    \n",
    "    plot_category_in_latent_and_physical_space(\n",
    "            adata=adata,\n",
    "            figsize=(10,20),\n",
    "            plot_label=\"Latent Clusters\",\n",
    "            model_label={model},\n",
    "            cat_key=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "            groups=None,\n",
    "            sample_key=\"sample\",\n",
    "            samples=[\"sample1\"], #samples=None #for latent UMAP #samples=[\"sample1\"] for spatial plot\n",
    "            cat_colors=latent_cluster_colors,\n",
    "            size=(720000 / len(adata)),\n",
    "            spot_size=30,\n",
    "            save_fig=True,\n",
    "            file_path=f\"{benchmarking_folder_path}/latent_clusters_{model}_subsample.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120325bb-f8de-478d-89d0-2a6d6da3e9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supplementary fig. 13: 25% subsample STACI niches ###\n",
    "dataset = \"slideseqv2_mouse_hippocampus_subsample_25pct\"\n",
    "models = [\"staci\"]\n",
    "\n",
    "run_number = 2\n",
    "leiden_resolutions = [0.1]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    adata = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_{model}.h5ad\")\n",
    "    adata.obs[\"sample\"] = \"sample1\"\n",
    "    \n",
    "    print(\"\\nComputing neighbor graph...\")\n",
    "    # Use latent representation for UMAP generation\n",
    "    sc.pp.neighbors(adata,\n",
    "                    use_rep=f\"{model}_latent_run{run_number}\",\n",
    "                    key_added=f\"{model}_latent_run{run_number}\")\n",
    "\n",
    "    print(\"\\nComputing UMAP embedding...\")\n",
    "    sc.tl.umap(adata,\n",
    "               neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "        \n",
    "    print(\"\\nComputing Leiden clustering...\")\n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=leiden_resolutions[i],\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    latent_cluster_colors = {\n",
    "        \"0\": \"#8BE0A4\",\n",
    "        \"1\": \"#66C5CC\",\n",
    "        \"2\": \"#D3B484\",\n",
    "        \"3\": \"#F6CF71\",\n",
    "        \"4\": \"#DCB0F2\",\n",
    "        \"5\": \"#C38D9E\",\n",
    "        \"6\": \"#9D88A2\"}\n",
    "    \n",
    "    plot_category_in_latent_and_physical_space(\n",
    "            adata=adata,\n",
    "            figsize=(10,20),\n",
    "            plot_label=\"Latent Clusters\",\n",
    "            model_label={model},\n",
    "            cat_key=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "            groups=None,\n",
    "            sample_key=\"sample\",\n",
    "            samples=[\"sample1\"], #samples=None #for latent UMAP #samples=[\"sample1\"] for spatial plot\n",
    "            cat_colors=latent_cluster_colors,\n",
    "            size=(720000 / len(adata)),\n",
    "            spot_size=30,\n",
    "            save_fig=True,\n",
    "            file_path=f\"{benchmarking_folder_path}/latent_clusters_{model}_subsample.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2338c1-7eff-40a7-9864-44c09babfd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supplementary fig. 13: 25% subsample GraphST niches ###\n",
    "dataset = \"slideseqv2_mouse_hippocampus_subsample_25pct\"\n",
    "models = [\"graphst\"]\n",
    "\n",
    "run_number = 2\n",
    "leiden_resolutions = [0.15]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    adata = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_{model}.h5ad\")\n",
    "    adata.obs[\"sample\"] = \"sample1\"\n",
    "    \n",
    "    print(\"\\nComputing neighbor graph...\")\n",
    "    # Use latent representation for UMAP generation\n",
    "    sc.pp.neighbors(adata,\n",
    "                    use_rep=f\"{model}_latent_run{run_number}\",\n",
    "                    key_added=f\"{model}_latent_run{run_number}\")\n",
    "\n",
    "    print(\"\\nComputing UMAP embedding...\")\n",
    "    sc.tl.umap(adata,\n",
    "               neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "        \n",
    "    print(\"\\nComputing Leiden clustering...\")\n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=leiden_resolutions[i],\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    latent_cluster_colors = {\n",
    "        \"0\": \"#8BE0A4\",\n",
    "        \"1\": \"#9D88A2\",\n",
    "        \"2\": \"#F6CF71\",\n",
    "        \"3\": \"#DCB0F2\",\n",
    "        \"4\": \"#66C5CC\",\n",
    "        \"5\": \"#D3B484\",\n",
    "        \"6\": \"#C38D9E\"}\n",
    "    \n",
    "    plot_category_in_latent_and_physical_space(\n",
    "            adata=adata,\n",
    "            figsize=(10,20),\n",
    "            plot_label=\"Latent Clusters\",\n",
    "            model_label={model},\n",
    "            cat_key=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "            groups=None,\n",
    "            sample_key=\"sample\",\n",
    "            samples=[\"sample1\"], #samples=None #for latent UMAP #samples=[\"sample1\"] for spatial plot\n",
    "            cat_colors=latent_cluster_colors,\n",
    "            size=(720000 / len(adata)),\n",
    "            spot_size=30,\n",
    "            save_fig=True,\n",
    "            file_path=f\"{benchmarking_folder_path}/latent_clusters_{model}_subsample.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96692547-9e29-4ad0-899d-3c62bbda7e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supplementary fig. 13: 25% subsample CellCharter niches ###\n",
    "dataset = \"slideseqv2_mouse_hippocampus_subsample_25pct\"\n",
    "models = [\"cellcharter\"]\n",
    "\n",
    "run_number = 2\n",
    "leiden_resolutions = [0.3]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    adata = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_{model}.h5ad\")\n",
    "    adata.obs[\"sample\"] = \"sample1\"\n",
    "    \n",
    "    print(\"\\nComputing neighbor graph...\")\n",
    "    # Use latent representation for UMAP generation\n",
    "    sc.pp.neighbors(adata,\n",
    "                    use_rep=f\"{model}_latent_run{run_number}\",\n",
    "                    key_added=f\"{model}_latent_run{run_number}\")\n",
    "\n",
    "    print(\"\\nComputing UMAP embedding...\")\n",
    "    sc.tl.umap(adata,\n",
    "               neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "        \n",
    "    # Use cellcharter clustering\n",
    "    #gmm = Cluster(\n",
    "    #    n_clusters=7, \n",
    "    #    random_state=0,\n",
    "        # If running on GPU\n",
    "        #trainer_params=dict(accelerator='gpu', devices=1)\n",
    "    #)\n",
    "    #gmm.fit(adata, use_rep=f\"{model}_latent_run{run_number}\")\n",
    "    #adata.obs[f\"run{run_number}_spatial_clusters\"] = gmm.predict(adata, use_rep=f\"{model}_latent_run{run_number}\").astype(\"str\")\n",
    "    \n",
    "    print(\"\\nComputing Leiden clustering...\")\n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=leiden_resolutions[i],\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    latent_cluster_colors = {\n",
    "        \"0\": \"#8BE0A4\",\n",
    "        \"1\": \"#F6CF71\",\n",
    "        \"2\": \"#DCB0F2\",\n",
    "        \"3\": \"#9D88A2\",\n",
    "        \"4\": \"#66C5CC\",\n",
    "        \"5\": \"#D3B484\",\n",
    "        \"6\": \"#C38D9E\"}\n",
    "    \n",
    "    plot_category_in_latent_and_physical_space(\n",
    "            adata=adata,\n",
    "            figsize=(10,20),\n",
    "            plot_label=\"Latent Clusters\",\n",
    "            model_label={model},\n",
    "            cat_key=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "            groups=None,\n",
    "            sample_key=\"sample\",\n",
    "            samples=[\"sample1\"],\n",
    "            cat_colors=latent_cluster_colors,\n",
    "            size=(720000 / len(adata)),\n",
    "            spot_size=30,\n",
    "            save_fig=True,\n",
    "            file_path=f\"{benchmarking_folder_path}/latent_clusters_{model}_subsample.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b9d6c9-5e57-4746-ad71-5d4ca4b676af",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supplementary fig. 13: 25% subsample BANKSY niches ###\n",
    "dataset = \"slideseqv2_mouse_hippocampus_subsample_25pct\"\n",
    "models = [\"banksy\"]\n",
    "\n",
    "run_number = 2\n",
    "leiden_resolutions = [0.15]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    adata = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_{model}.h5ad\")\n",
    "    adata.obs[\"sample\"] = \"sample1\"\n",
    "    \n",
    "    print(\"\\nComputing neighbor graph...\")\n",
    "    # Use latent representation for UMAP generation\n",
    "    sc.pp.neighbors(adata,\n",
    "                    use_rep=f\"{model}_latent_run{run_number}\",\n",
    "                    key_added=f\"{model}_latent_run{run_number}\")\n",
    "\n",
    "    print(\"\\nComputing UMAP embedding...\")\n",
    "    sc.tl.umap(adata,\n",
    "               neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "        \n",
    "    print(\"\\nComputing Leiden clustering...\")\n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=leiden_resolutions[i],\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    latent_cluster_colors = {\n",
    "        \"0\": \"#8BE0A4\",\n",
    "        \"1\": \"#F6CF71\",\n",
    "        \"2\": \"#DCB0F2\",\n",
    "        \"3\": \"#66C5CC\",\n",
    "        \"4\": \"#9D88A2\",\n",
    "        \"5\": \"#D3B484\",\n",
    "        \"6\": \"#C38D9E\"}\n",
    "    \n",
    "    plot_category_in_latent_and_physical_space(\n",
    "            adata=adata,\n",
    "            figsize=(10,20),\n",
    "            plot_label=\"Latent Clusters\",\n",
    "            model_label={model},\n",
    "            cat_key=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "            groups=None,\n",
    "            sample_key=\"sample\",\n",
    "            samples=[\"sample1\"], #samples=None #for latent UMAP #samples=[\"sample1\"] for spatial plot\n",
    "            cat_colors=latent_cluster_colors,\n",
    "            size=(720000 / len(adata)),\n",
    "            spot_size=30,\n",
    "            save_fig=True,\n",
    "            file_path=f\"{benchmarking_folder_path}/latent_clusters_{model}_subsample.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cadad4-b3f1-412a-aa75-c4f80f40f4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supplementary fig. 13: 25% subsample DeepLinc niches ###\n",
    "dataset = \"slideseqv2_mouse_hippocampus_subsample_25pct\"\n",
    "models = [\"deeplinc\"]\n",
    "\n",
    "run_number = 2\n",
    "leiden_resolutions = [0.225]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    adata = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_{model}.h5ad\")\n",
    "    adata.obs[\"sample\"] = \"sample1\"\n",
    "    \n",
    "    print(\"\\nComputing neighbor graph...\")\n",
    "    # Use latent representation for UMAP generation\n",
    "    sc.pp.neighbors(adata,\n",
    "                    use_rep=f\"{model}_latent_run{run_number}\",\n",
    "                    key_added=f\"{model}_latent_run{run_number}\")\n",
    "\n",
    "    print(\"\\nComputing UMAP embedding...\")\n",
    "    sc.tl.umap(adata,\n",
    "               neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "        \n",
    "    print(\"\\nComputing Leiden clustering...\")\n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=leiden_resolutions[i],\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    latent_cluster_colors = {\n",
    "        \"0\": \"#8BE0A4\",\n",
    "        \"1\": \"#DCB0F2\",\n",
    "        \"2\": \"#66C5CC\",\n",
    "        \"3\": \"#F6CF71\",\n",
    "        \"4\": \"#9D88A2\",\n",
    "        \"5\": \"#D3B484\",\n",
    "        \"6\": \"#C38D9E\"}\n",
    "    \n",
    "    plot_category_in_latent_and_physical_space(\n",
    "            adata=adata,\n",
    "            figsize=(10,20),\n",
    "            plot_label=\"Latent Clusters\",\n",
    "            model_label={model},\n",
    "            cat_key=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "            groups=None,\n",
    "            sample_key=\"sample\",\n",
    "            samples=[\"sample1\"], #samples=None #for latent UMAP #samples=[\"sample1\"] for spatial plot\n",
    "            cat_colors=latent_cluster_colors,\n",
    "            size=(720000 / len(adata)),\n",
    "            spot_size=30,\n",
    "            save_fig=True,\n",
    "            file_path=f\"{benchmarking_folder_path}/latent_clusters_{model}_subsample.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2feb93-2187-40ad-bc67-6a5f04d2a6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metrics\n",
    "datasets = [\"slideseqv2_mouse_hippocampus\",\n",
    "            \"slideseqv2_mouse_hippocampus_subsample_50pct\",\n",
    "            \"slideseqv2_mouse_hippocampus_subsample_25pct\",\n",
    "            \"slideseqv2_mouse_hippocampus_subsample_10pct\",\n",
    "            \"slideseqv2_mouse_hippocampus_subsample_5pct\",\n",
    "            \"slideseqv2_mouse_hippocampus_subsample_1pct\"\n",
    "           ]\n",
    "models = [\"nichecompass_gcnconv\",\n",
    "          \"nichecompass_gatv2conv\",\n",
    "          \"staci\",\n",
    "          \"deeplinc\",\n",
    "          \"graphst\",\n",
    "          \"cellcharter\",\n",
    "          \"banksy\"\n",
    "         ]\n",
    "\n",
    "summary_df = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    dataset_df = pd.DataFrame()\n",
    "    for model in models:\n",
    "        try:\n",
    "            benchmark_df = pd.read_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\")\n",
    "            #adata = sc.read_h5ad(f\"../../artifacts/single_sample_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "            #training_durations = []\n",
    "            #for run_number in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "            #    training_durations.append(adata.uns[f\"{model.split('_')[0]}_model_training_duration_run{run_number}\"])\n",
    "            #benchmark_df[\"run_time\"] = training_durations\n",
    "            #benchmark_df = benchmark_df[[\"dataset\", \"run_number\", \"run_time\", \"gcs\", \"mlami\", \"cas\", \"clisis\", \"nasw\", \"cnmi\", \"cari\", \"casw\", \"clisi\"]]\n",
    "            #benchmark_df.to_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\", index=False)\n",
    "            benchmark_df[\"model\"] = model\n",
    "            dataset_df = pd.concat([dataset_df, benchmark_df], ignore_index=True)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Did not find file {benchmarking_folder_path}/{dataset}_{model}_metrics.csv. Continuing...\")\n",
    "            missing_run_data = {\n",
    "                \"dataset\": [dataset] * 8,\n",
    "                \"model\": [model] * 8,\n",
    "                \"run_number\": [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "                \"run_time\": [np.nan] * 8\n",
    "            }\n",
    "            missing_run_df = pd.DataFrame(missing_run_data)\n",
    "            dataset_df = pd.concat([dataset_df, missing_run_df], ignore_index=True)\n",
    "            \n",
    "    # Apply min-max scaling to metric columns\n",
    "    for i in range(len(metric_cols_single_sample)):\n",
    "        min_val = dataset_df[metric_cols_single_sample[i]].min()\n",
    "        max_val = dataset_df[metric_cols_single_sample[i]].max()\n",
    "        dataset_df[metric_cols_single_sample[i] + \"_scaled\"] = ((\n",
    "            dataset_df[metric_cols_single_sample[i]] - min_val) / (max_val - min_val))\n",
    "\n",
    "    summary_df = pd.concat([summary_df, dataset_df], ignore_index=True)\n",
    "    continue\n",
    "    \n",
    "cat_0_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[0:2]]\n",
    "cat_1_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[2:4]]\n",
    "cat_2_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[4:6]]\n",
    "    \n",
    "summary_df[category_cols_single_sample[0]] = np.average(summary_df[cat_0_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[0:2],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_single_sample[1]] = np.average(summary_df[cat_1_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[2:4],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_single_sample[2]] = np.average(summary_df[cat_2_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[4:6],\n",
    "                                                        axis=1)\n",
    "summary_df[\"Overall Score\"] = np.average(summary_df[category_cols_single_sample[:3]],\n",
    "                                         weights=category_col_weights_single_sample[:3],\n",
    "                                         axis=1)\n",
    " \n",
    "# Reformat for plot\n",
    "summary_df.replace({\"nichecompass_gatv2conv\": \"NicheCompass\",\n",
    "                    \"nichecompass_gcnconv\": \"NicheCompass Light\",\n",
    "                    \"staci\": \"STACI\",\n",
    "                    \"deeplinc\": \"DeepLinc\",\n",
    "                    \"expimap\": \"expiMap\",\n",
    "                    \"graphst\": \"GraphST\",\n",
    "                    \"cellcharter\": \"CellCharter\",\n",
    "                    \"banksy\": \"BANKSY\"}, inplace=True)\n",
    "\n",
    "# Plot over all loss weights combinations\n",
    "# Prepare metrics table plot\n",
    "group_cols = [\"dataset\", \"model\"]\n",
    "aggregate_df = summary_df.groupby(group_cols).mean(\"Overall Score\").sort_values(\"Overall Score\", ascending=False)[\n",
    "    metric_cols_single_sample + [\"Overall Score\"]].reset_index()\n",
    "\n",
    "unrolled_df = pd.melt(\n",
    "    aggregate_df, \n",
    "    id_vars=group_cols,\n",
    "    value_vars=metric_cols_single_sample + [\"Overall Score\"],\n",
    "    var_name=\"score_type\", \n",
    "    value_name=\"score\")\n",
    "\n",
    "# Create spatial indicator column\n",
    "def is_spatially_aware_model(row):\n",
    "    if row[\"model\"] in [\"NicheCompass GCN\", \"NicheCompass GATv2\", \"DeepLinc\", \"GraphST\", \"SageNet\"]:\n",
    "        return True\n",
    "    return False\n",
    "unrolled_df[\"spatially_aware\"] = unrolled_df.apply(lambda row: is_spatially_aware_model(row), axis=1)\n",
    "unrolled_df = unrolled_df[[\"dataset\", \"spatially_aware\", \"model\", \"score_type\", \"score\"]]\n",
    "\n",
    "# Order datasets\n",
    "unrolled_df[\"dataset\"] = pd.Categorical(unrolled_df[\"dataset\"], categories=datasets, ordered=True)\n",
    "unrolled_df = unrolled_df.sort_values(by=\"dataset\")\n",
    "\n",
    "#print(summary_df[\"model\"].value_counts())\n",
    "#print(summary_df[summary_df.isna().any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40bd054-dc77-45c5-9c12-7ea78f6829a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supplementary fig. 17: single sample runtimes ###\n",
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"DeepLinc\": \"#0E1C4A\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 \"CellCharter\": \"#F46AA2\",\n",
    "                 \"BANKSY\": \"#556B2F\",\n",
    "                 #\"scVI\": \"#FE8B3B\",\n",
    "                 #\"expiMap\": \"#7E0028\",\n",
    "                 }\n",
    "\n",
    "run_time_mean_df = summary_df.groupby([\"dataset\", \"model\"])[[\"run_time\"]].mean().reset_index()\n",
    "run_time_mean_df[\"run_time\"] = run_time_mean_df[\"run_time\"] / 60\n",
    "\n",
    "def create_dataset_share_col(row):\n",
    "    if row[\"dataset\"] == \"slideseqv2_mouse_hippocampus\":\n",
    "        return 100\n",
    "    elif row[\"dataset\"] == \"slideseqv2_mouse_hippocampus_subsample_50pct\":    \n",
    "        return 50\n",
    "    elif row[\"dataset\"] == \"slideseqv2_mouse_hippocampus_subsample_25pct\":    \n",
    "        return 25\n",
    "    elif row[\"dataset\"] == \"slideseqv2_mouse_hippocampus_subsample_10pct\":    \n",
    "        return 10\n",
    "    elif row[\"dataset\"] == \"slideseqv2_mouse_hippocampus_subsample_5pct\":    \n",
    "        return 5\n",
    "    elif row[\"dataset\"] == \"slideseqv2_mouse_hippocampus_subsample_1pct\":    \n",
    "        return 1\n",
    "    \n",
    "run_time_mean_df[\"dataset_share\"] = run_time_mean_df.apply(lambda row: create_dataset_share_col(row), axis=1)\n",
    "    \n",
    "ax = sns.lineplot(data=run_time_mean_df,\n",
    "                  x=\"dataset_share\",\n",
    "                  y=\"run_time\",\n",
    "                  hue=\"model\",\n",
    "                  marker='o',\n",
    "                  palette=model_palette)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.title(\"SlideSeqV2 Mouse Hippocampus\\n(41,786 Cells; 4,000 Genes)\")\n",
    "plt.ylabel(\"Run Time (Minutes)\")\n",
    "plt.xlabel(\"Dataset Size (%)\")\n",
    "custom_y_ticks = [1, 10, 60, 180, 360, 720, 1440]  # Adjust the tick positions as needed\n",
    "plt.yscale(\"log\")\n",
    "plt.yticks(custom_y_ticks, custom_y_ticks)\n",
    "legend = plt.gca().get_legend()\n",
    "for handle in legend.legendHandles:\n",
    "    handle.set_linewidth(4.0)  # Adjust the size as needed\n",
    "handles, labels = legend.legendHandles, [text.get_text() for text in legend.get_texts()]\n",
    "order = [3, 2, 4, 1, 0]\n",
    "ordered_handles = [handles[i] for i in order]\n",
    "ordered_labels = [labels[i] for i in order]\n",
    "plt.legend(ordered_handles, ordered_labels)\n",
    "ax = plt.gca()\n",
    "ax.legend().set_visible(False)\n",
    "plt.savefig(benchmarking_folder_path + \"/benchmarking_runtimes_slideseqv2_mouse_hippocampus.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55de09bf-3e2d-41a2-913e-f8e8d6a4817e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supplementary fig. 15b: single sample metric averages ###\n",
    "plot_metrics_table(\n",
    "    df=unrolled_df,\n",
    "    model_col=\"model\",\n",
    "    model_col_width=1.9,\n",
    "    group_col=\"dataset\",\n",
    "    metric_cols=metric_cols_single_sample, # metric_cols_single_sample, category_cols_single_sample\n",
    "    metric_col_weights=metric_col_weights_single_sample, # metric_col_weights_single_sample, category_col_weights_single_sample\n",
    "    metric_col_titles=[col.replace(\" \", \"\\n\") for col in metric_col_titles_single_sample], # category_col_titles_single_sample\n",
    "    metric_col_width=0.7, # 0.8,\n",
    "    aggregate_col_width=1.,\n",
    "    plot_width=42, # 32,\n",
    "    plot_height=8,\n",
    "    show=True,\n",
    "    save_dir=benchmarking_folder_path,\n",
    "    save_name=f\"benchmarking_metrics_slideseqv2_mouse_hippocampus.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69c3cca-3c7d-4c5e-ac5f-ca9b1af82102",
   "metadata": {},
   "source": [
    "#### 2.1.2 seqFISH Mouse Organogenesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb819481-1e40-4cac-8ee0-413416345239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metrics\n",
    "datasets = [\"seqfish_mouse_organogenesis_embryo2\",\n",
    "            \"seqfish_mouse_organogenesis_subsample_50pct_embryo2\",\n",
    "            \"seqfish_mouse_organogenesis_subsample_25pct_embryo2\",\n",
    "            \"seqfish_mouse_organogenesis_subsample_10pct_embryo2\",\n",
    "            \"seqfish_mouse_organogenesis_subsample_5pct_embryo2\",\n",
    "            \"seqfish_mouse_organogenesis_subsample_1pct_embryo2\"]\n",
    "models = [\"nichecompass_gatv2conv\",\n",
    "          \"nichecompass_gcnconv\",\n",
    "          \"staci\",\n",
    "          \"deeplinc\",\n",
    "          \"graphst\",\n",
    "          \"cellcharter\",\n",
    "          \"banksy\"\n",
    "         ]\n",
    "\n",
    "summary_df = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    dataset_df = pd.DataFrame()\n",
    "    for model in models:\n",
    "        try:\n",
    "            benchmark_df = pd.read_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\")\n",
    "            #adata = sc.read_h5ad(f\"../../artifacts/single_sample_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "            #training_durations = []\n",
    "            #for run_number in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "            #    training_durations.append(adata.uns[f\"{model.split('_')[0]}_model_training_duration_run{run_number}\"])\n",
    "            #benchmark_df[\"run_time\"] = training_durations\n",
    "            #benchmark_df = benchmark_df[[\"dataset\", \"run_number\", \"run_time\", \"gcs\", \"mlami\", \"cas\", \"clisis\", \"nasw\", \"cnmi\", \"cari\", \"casw\", \"clisi\"]]\n",
    "            #benchmark_df.to_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\", index=False)\n",
    "            benchmark_df[\"model\"] = model\n",
    "            dataset_df = pd.concat([dataset_df, benchmark_df], ignore_index=True)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Did not find file {benchmarking_folder_path}/{dataset}_{model}_metrics.csv. Continuing...\")\n",
    "            missing_run_data = {\n",
    "                \"dataset\": [dataset] * 8,\n",
    "                \"model\": [model] * 8,\n",
    "                \"run_number\": [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "                \"run_time\": [np.nan] * 8\n",
    "            }\n",
    "            missing_run_df = pd.DataFrame(missing_run_data)\n",
    "            dataset_df = pd.concat([dataset_df, missing_run_df], ignore_index=True)\n",
    "            \n",
    "    # Apply min-max scaling to metric columns\n",
    "    for i in range(len(metric_cols_single_sample)):\n",
    "        min_val = dataset_df[metric_cols_single_sample[i]].min()\n",
    "        max_val = dataset_df[metric_cols_single_sample[i]].max()\n",
    "        dataset_df[metric_cols_single_sample[i] + \"_scaled\"] = ((\n",
    "            dataset_df[metric_cols_single_sample[i]] - min_val) / (max_val - min_val))\n",
    "\n",
    "    summary_df = pd.concat([summary_df, dataset_df], ignore_index=True)\n",
    "    continue\n",
    "    \n",
    "cat_0_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[0:2]]\n",
    "cat_1_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[2:4]]\n",
    "cat_2_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[4:6]]\n",
    "    \n",
    "summary_df[category_cols_single_sample[0]] = np.average(summary_df[cat_0_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[0:2],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_single_sample[1]] = np.average(summary_df[cat_1_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[2:4],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_single_sample[2]] = np.average(summary_df[cat_2_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[4:6],\n",
    "                                                        axis=1)\n",
    "summary_df[\"Overall Score\"] = np.average(summary_df[category_cols_single_sample[:3]],\n",
    "                                         weights=category_col_weights_single_sample[:3],\n",
    "                                         axis=1)\n",
    " \n",
    "# Reformat for plot\n",
    "summary_df.replace({\"nichecompass_gatv2conv\": \"NicheCompass\",\n",
    "                    \"nichecompass_gcnconv\": \"NicheCompass Light\",\n",
    "                    \"staci\": \"STACI\",\n",
    "                    \"deeplinc\": \"DeepLinc\",\n",
    "                    \"expimap\": \"expiMap\",\n",
    "                    \"graphst\": \"GraphST\",\n",
    "                    \"cellcharter\": \"CellCharter\",\n",
    "                    \"banksy\": \"BANKSY\"}, inplace=True)\n",
    "\n",
    "# Plot over all loss weights combinations\n",
    "# Prepare metrics table plot\n",
    "group_cols = [\"dataset\", \"model\"]\n",
    "aggregate_df = summary_df.groupby(group_cols).mean(\"Overall Score\").sort_values(\"Overall Score\", ascending=False)[\n",
    "    metric_cols_single_sample + [\"Overall Score\"]].reset_index()\n",
    "\n",
    "unrolled_df = pd.melt(\n",
    "    aggregate_df, \n",
    "    id_vars=group_cols,\n",
    "    value_vars=metric_cols_single_sample + [\"Overall Score\"],\n",
    "    var_name=\"score_type\", \n",
    "    value_name=\"score\")\n",
    "\n",
    "# Create spatial indicator column\n",
    "def is_spatially_aware_model(row):\n",
    "    if row[\"model\"] in [\"NicheCompass GCN\", \"NicheCompass GATv2\", \"DeepLinc\", \"GraphST\", \"CellCharter\"]:\n",
    "        return True\n",
    "    return False\n",
    "unrolled_df[\"spatially_aware\"] = unrolled_df.apply(lambda row: is_spatially_aware_model(row), axis=1)\n",
    "unrolled_df = unrolled_df[[\"dataset\", \"spatially_aware\", \"model\", \"score_type\", \"score\"]]\n",
    "\n",
    "# Order datasets\n",
    "unrolled_df[\"dataset\"] = pd.Categorical(unrolled_df[\"dataset\"], categories=datasets, ordered=True)\n",
    "unrolled_df = unrolled_df.sort_values(by=\"dataset\")\n",
    "\n",
    "#print(summary_df[\"model\"].value_counts())\n",
    "#print(summary_df[summary_df.isna().any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1afa8d8-c3da-4e82-a5d3-870e045faab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supplementary fig. 17: single sample runtimes ###\n",
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"DeepLinc\": \"#0E1C4A\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 \"CellCharter\": \"#F46AA2\",\n",
    "                 \"BANKSY\": \"#556B2F\",\n",
    "                 #\"scVI\": \"#FE8B3B\",\n",
    "                 #\"expiMap\": \"#7E0028\",\n",
    "                 }\n",
    "\n",
    "run_time_mean_df = summary_df.groupby([\"dataset\", \"model\"])[[\"run_time\"]].mean().reset_index()\n",
    "run_time_mean_df[\"run_time\"] = run_time_mean_df[\"run_time\"] / 60\n",
    "\n",
    "def create_dataset_share_col(row):\n",
    "    if row[\"dataset\"] == \"seqfish_mouse_organogenesis_embryo2\":\n",
    "        return 100\n",
    "    elif row[\"dataset\"] == \"seqfish_mouse_organogenesis_subsample_50pct_embryo2\":    \n",
    "        return 50\n",
    "    elif row[\"dataset\"] == \"seqfish_mouse_organogenesis_subsample_25pct_embryo2\":    \n",
    "        return 25\n",
    "    elif row[\"dataset\"] == \"seqfish_mouse_organogenesis_subsample_10pct_embryo2\":    \n",
    "        return 10\n",
    "    elif row[\"dataset\"] == \"seqfish_mouse_organogenesis_subsample_5pct_embryo2\":    \n",
    "        return 5\n",
    "    elif row[\"dataset\"] == \"seqfish_mouse_organogenesis_subsample_1pct_embryo2\":    \n",
    "        return 1\n",
    "    \n",
    "run_time_mean_df[\"dataset_share\"] = run_time_mean_df.apply(lambda row: create_dataset_share_col(row), axis=1)\n",
    "    \n",
    "ax = sns.lineplot(data=run_time_mean_df,\n",
    "                  x=\"dataset_share\",\n",
    "                  y=\"run_time\",\n",
    "                  hue=\"model\",\n",
    "                  marker='o',\n",
    "                  palette=model_palette)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "plt.title(\"seqFISH Mouse Organogenesis\\n(14,891 Cells; 351 Genes)\")\n",
    "plt.ylabel(\"Run Time (Minutes)\")\n",
    "plt.xlabel(\"Dataset Size (%)\")\n",
    "custom_y_ticks = [1, 10, 60, 180, 360, 720, 1440]  # Adjust the tick positions as needed\n",
    "plt.yscale(\"log\")\n",
    "plt.yticks(custom_y_ticks, None)\n",
    "legend = plt.gca().get_legend()\n",
    "for handle in legend.legendHandles:\n",
    "    handle.set_linewidth(4.0)  # Adjust the size as needed\n",
    "handles, labels = legend.legendHandles, [text.get_text() for text in legend.get_texts()]\n",
    "order = [3, 2, 4, 1, 0]\n",
    "ordered_handles = [handles[i] for i in order]\n",
    "ordered_labels = [labels[i] for i in order]\n",
    "plt.legend(ordered_handles, ordered_labels)\n",
    "ax = plt.gca()\n",
    "ax.legend().set_visible(False)\n",
    "plt.savefig(benchmarking_folder_path + \"/benchmarking_runtimes_seqfish_mouse_organogenesis.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b78079-ec91-4168-a38f-0ff3530e8d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supplementary fig. 15b: single sample metric averages ###\n",
    "plot_metrics_table(\n",
    "    df=unrolled_df,\n",
    "    model_col=\"model\",\n",
    "    model_col_width=1.9,\n",
    "    group_col=\"dataset\",\n",
    "    metric_cols=metric_cols_single_sample, # metric_cols_single_sample, category_cols_single_sample\n",
    "    metric_col_weights=metric_col_weights_single_sample, # metric_col_weights_single_sample, category_col_weights_single_sample\n",
    "    metric_col_titles=[col.replace(\" \", \"\\n\") for col in metric_col_titles_single_sample], # category_col_titles_single_sample\n",
    "    metric_col_width=0.7, # 0.8,\n",
    "    aggregate_col_width=1.,\n",
    "    plot_width=42, # 32,\n",
    "    plot_height=8,\n",
    "    show=True,\n",
    "    save_dir=benchmarking_folder_path,\n",
    "    save_name=f\"benchmarking_metrics_seqfish_mouse_organogenesis.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6150e3-3aa9-4c55-bb20-2e0efe236ffc",
   "metadata": {},
   "source": [
    "#### 2.1.3 nanoString CosMx SMI Human Non-Small-Cell Lung Cancer (NSCLC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6422aa-660c-4474-9fea-3f9868b34146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metrics\n",
    "datasets = [\"nanostring_cosmx_human_nsclc_batch5\",\n",
    "            \"nanostring_cosmx_human_nsclc_subsample_50pct_batch5\",\n",
    "            \"nanostring_cosmx_human_nsclc_subsample_25pct_batch5\",\n",
    "            \"nanostring_cosmx_human_nsclc_subsample_10pct_batch5\",\n",
    "            \"nanostring_cosmx_human_nsclc_subsample_5pct_batch5\",\n",
    "            \"nanostring_cosmx_human_nsclc_subsample_1pct_batch5\"]\n",
    "models = [\"nichecompass_gcnconv\",\n",
    "          \"nichecompass_gatv2conv\",\n",
    "          \"staci\",\n",
    "          \"deeplinc\",\n",
    "          \"graphst\",\n",
    "          \"cellcharter\",\n",
    "          \"banksy\"\n",
    "         ]\n",
    "\n",
    "summary_df = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    dataset_df = pd.DataFrame()\n",
    "    for model in models:\n",
    "        try:\n",
    "            benchmark_df = pd.read_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\")\n",
    "            #adata = sc.read_h5ad(f\"../../artifacts/single_sample_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "            #training_durations = []\n",
    "            #for run_number in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "            #    training_durations.append(adata.uns[f\"{model.split('_')[0]}_model_training_duration_run{run_number}\"])\n",
    "            #benchmark_df[\"run_time\"] = training_durations\n",
    "            #benchmark_df = benchmark_df[[\"dataset\", \"run_number\", \"run_time\", \"gcs\", \"mlami\", \"cas\", \"clisis\", \"nasw\", \"cnmi\", \"cari\", \"casw\", \"clisi\"]]\n",
    "            #benchmark_df.to_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\", index=False)\n",
    "            benchmark_df[\"model\"] = model\n",
    "            dataset_df = pd.concat([dataset_df, benchmark_df], ignore_index=True)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Did not find file {benchmarking_folder_path}/{dataset}_{model}_metrics.csv. Continuing...\")\n",
    "            missing_run_data = {\n",
    "                \"dataset\": [dataset] * 8,\n",
    "                \"model\": [model] * 8,\n",
    "                \"run_number\": [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "                \"run_time\": [np.nan] * 8\n",
    "            }\n",
    "            missing_run_df = pd.DataFrame(missing_run_data)\n",
    "            dataset_df = pd.concat([dataset_df, missing_run_df], ignore_index=True)\n",
    "            \n",
    "    # Apply min-max scaling to metric columns\n",
    "    for i in range(len(metric_cols_single_sample)):\n",
    "        min_val = dataset_df[metric_cols_single_sample[i]].min()\n",
    "        max_val = dataset_df[metric_cols_single_sample[i]].max()\n",
    "        dataset_df[metric_cols_single_sample[i] + \"_scaled\"] = ((\n",
    "            dataset_df[metric_cols_single_sample[i]] - min_val) / (max_val - min_val))\n",
    "\n",
    "    summary_df = pd.concat([summary_df, dataset_df], ignore_index=True)\n",
    "    continue\n",
    "    \n",
    "cat_0_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[0:2]]\n",
    "cat_1_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[2:4]]\n",
    "cat_2_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[4:6]]\n",
    "    \n",
    "summary_df[category_cols_single_sample[0]] = np.average(summary_df[cat_0_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[0:2],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_single_sample[1]] = np.average(summary_df[cat_1_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[2:4],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_single_sample[2]] = np.average(summary_df[cat_2_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[4:6],\n",
    "                                                        axis=1)\n",
    "summary_df[\"Overall Score\"] = np.average(summary_df[category_cols_single_sample[:3]],\n",
    "                                         weights=category_col_weights_single_sample[:3],\n",
    "                                         axis=1)\n",
    " \n",
    "# Reformat for plot\n",
    "summary_df.replace({\"nichecompass_gatv2conv\": \"NicheCompass\",\n",
    "                    \"nichecompass_gcnconv\": \"NicheCompass Light\",\n",
    "                    \"staci\": \"STACI\",\n",
    "                    \"deeplinc\": \"DeepLinc\",\n",
    "                    \"expimap\": \"expiMap\",\n",
    "                    \"graphst\": \"GraphST\",\n",
    "                    \"cellcharter\": \"CellCharter\",\n",
    "                    \"banksy\": \"BANKSY\"}, inplace=True)\n",
    "\n",
    "# Plot over all loss weights combinations\n",
    "# Prepare metrics table plot\n",
    "group_cols = [\"dataset\", \"model\"]\n",
    "aggregate_df = summary_df.groupby(group_cols).mean(\"Overall Score\").sort_values(\"Overall Score\", ascending=False)[\n",
    "    metric_cols_single_sample + [\"Overall Score\"]].reset_index()\n",
    "\n",
    "unrolled_df = pd.melt(\n",
    "    aggregate_df, \n",
    "    id_vars=group_cols,\n",
    "    value_vars=metric_cols_single_sample + [\"Overall Score\"],\n",
    "    var_name=\"score_type\", \n",
    "    value_name=\"score\")\n",
    "\n",
    "# Create spatial indicator column\n",
    "def is_spatially_aware_model(row):\n",
    "    if row[\"model\"] in [\"NicheCompass GCN\", \"NicheCompass GATv2\", \"DeepLinc\", \"GraphST\", \"CellCharter\"]:\n",
    "        return True\n",
    "    return False\n",
    "unrolled_df[\"spatially_aware\"] = unrolled_df.apply(lambda row: is_spatially_aware_model(row), axis=1)\n",
    "unrolled_df = unrolled_df[[\"dataset\", \"spatially_aware\", \"model\", \"score_type\", \"score\"]]\n",
    "\n",
    "# Order datasets\n",
    "unrolled_df[\"dataset\"] = pd.Categorical(unrolled_df[\"dataset\"], categories=datasets, ordered=True)\n",
    "unrolled_df = unrolled_df.sort_values(by=\"dataset\")\n",
    "\n",
    "#print(summary_df[\"model\"].value_counts())\n",
    "#print(summary_df[summary_df.isna().any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7539ec7-8687-44b6-8aec-11f594a5c1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supplementary fig. 17: single sample runtimes ###\n",
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"DeepLinc\": \"#0E1C4A\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 \"CellCharter\": \"#F46AA2\",\n",
    "                 \"BANKSY\": \"#556B2F\",\n",
    "                 #\"scVI\": \"#FE8B3B\",\n",
    "                 #\"expiMap\": \"#7E0028\",\n",
    "                 }\n",
    "\n",
    "run_time_mean_df = summary_df.groupby([\"dataset\", \"model\"])[[\"run_time\"]].mean().reset_index()\n",
    "run_time_mean_df[\"run_time\"] = run_time_mean_df[\"run_time\"] / 60\n",
    "\n",
    "def create_dataset_share_col(row):\n",
    "    if row[\"dataset\"] == \"nanostring_cosmx_human_nsclc_batch5\":\n",
    "        return 100\n",
    "    elif row[\"dataset\"] == \"nanostring_cosmx_human_nsclc_subsample_50pct_batch5\":    \n",
    "        return 50\n",
    "    elif row[\"dataset\"] == \"nanostring_cosmx_human_nsclc_subsample_25pct_batch5\":    \n",
    "        return 25\n",
    "    elif row[\"dataset\"] == \"nanostring_cosmx_human_nsclc_subsample_10pct_batch5\":    \n",
    "        return 10\n",
    "    elif row[\"dataset\"] == \"nanostring_cosmx_human_nsclc_subsample_5pct_batch5\":    \n",
    "        return 5\n",
    "    elif row[\"dataset\"] == \"nanostring_cosmx_human_nsclc_subsample_1pct_batch5\":    \n",
    "        return 1\n",
    "    \n",
    "run_time_mean_df[\"dataset_share\"] = run_time_mean_df.apply(lambda row: create_dataset_share_col(row), axis=1)\n",
    "    \n",
    "ax = sns.lineplot(data=run_time_mean_df,\n",
    "                  x=\"dataset_share\",\n",
    "                  y=\"run_time\",\n",
    "                  hue=\"model\",\n",
    "                  marker='o',\n",
    "                  palette=model_palette)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "plt.title(\"nanoString CosMx Human NSCLC\\n(77,391 Cells; 883 Genes)\")\n",
    "plt.ylabel(\"Run Time (Minutes)\")\n",
    "plt.xlabel(\"Dataset Size (%)\")\n",
    "custom_y_ticks = [1, 10, 60, 180, 360, 720, 1440]  # Adjust the tick positions as needed\n",
    "plt.yscale(\"log\")\n",
    "plt.yticks(custom_y_ticks, None)\n",
    "legend = plt.gca().get_legend()\n",
    "for handle in legend.legendHandles:\n",
    "    handle.set_linewidth(4.0)  # Adjust the size as needed\n",
    "handles, labels = legend.legendHandles, [text.get_text() for text in legend.get_texts()]\n",
    "order = [4, 5, 0, 3, 1, 2, 6]\n",
    "ordered_handles = [handles[i] for i in order]\n",
    "ordered_labels = [labels[i] for i in order]\n",
    "lgd = plt.legend(ordered_handles, ordered_labels, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax = plt.gca()\n",
    "#ax.legend().set_visible(False)\n",
    "plt.savefig(benchmarking_folder_path + \"/benchmarking_runtimes_nanostring_cosmx_human_nsclc.svg\", bbox_inches=\"tight\", bbox_extra_artists=[lgd])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3872fa-6a37-4871-83ac-3400e6ca25f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supplementary fig. 15b: single sample metric averages ###\n",
    "plot_metrics_table(\n",
    "    df=unrolled_df,\n",
    "    model_col=\"model\",\n",
    "    model_col_width=1.9,\n",
    "    group_col=\"dataset\",\n",
    "    metric_cols=metric_cols_single_sample, # metric_cols_single_sample, category_cols_single_sample\n",
    "    metric_col_weights=metric_col_weights_single_sample, # metric_col_weights_single_sample, category_col_weights_single_sample\n",
    "    metric_col_titles=[col.replace(\" \", \"\\n\") for col in metric_col_titles_single_sample],\n",
    "    metric_col_width=0.7, # 0.8,\n",
    "    aggregate_col_width=1.,\n",
    "    plot_width=42, # 32,\n",
    "    plot_height=8,\n",
    "    show=True,\n",
    "    save_dir=benchmarking_folder_path,\n",
    "    save_name=f\"benchmarking_metrics_nanostring_cosmx_human_nsclc.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e7829f-acdc-40df-a608-14b05afbd55d",
   "metadata": {},
   "source": [
    "#### 2.1.4 Vizgen MERFISH Mouse Liver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db20e1a2-841b-4202-b1eb-7752b4a8d252",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"vizgen_merfish_mouse_liver\",\n",
    "            \"vizgen_merfish_mouse_liver_subsample_50pct\",\n",
    "            \"vizgen_merfish_mouse_liver_subsample_25pct\",\n",
    "            \"vizgen_merfish_mouse_liver_subsample_10pct\",\n",
    "            \"vizgen_merfish_mouse_liver_subsample_5pct\",\n",
    "            \"vizgen_merfish_mouse_liver_subsample_1pct\"]\n",
    "models = [\"nichecompass_gcnconv\",\n",
    "          \"nichecompass_gatv2conv\",\n",
    "          \"staci\",\n",
    "          \"deeplinc\",\n",
    "          \"graphst\",\n",
    "          \"cellcharter\",\n",
    "          \"banksy\"\n",
    "         ]\n",
    "\n",
    "summary_df = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    dataset_df = pd.DataFrame()\n",
    "    for model in models:\n",
    "        try:\n",
    "            benchmark_df = pd.read_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\")\n",
    "            #adata = sc.read_h5ad(f\"../../artifacts/single_sample_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "            #training_durations = []\n",
    "            #for run_number in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "            #    training_durations.append(adata.uns[f\"{model.split('_')[0]}_model_training_duration_run{run_number}\"])\n",
    "            #benchmark_df[\"run_time\"] = training_durations\n",
    "            #benchmark_df = benchmark_df[[\"dataset\", \"run_number\", \"run_time\", \"gcs\", \"mlami\", \"cas\", \"clisis\", \"nasw\", \"cnmi\", \"cari\", \"casw\", \"clisi\"]]\n",
    "            #benchmark_df.to_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\", index=False)\n",
    "            benchmark_df[\"model\"] = model\n",
    "            dataset_df = pd.concat([dataset_df, benchmark_df], ignore_index=True)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Did not find file {benchmarking_folder_path}/{dataset}_{model}_metrics.csv. Continuing...\")\n",
    "            missing_run_data = {\n",
    "                \"dataset\": [dataset] * 8,\n",
    "                \"model\": [model] * 8,\n",
    "                \"run_number\": [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "                \"run_time\": [np.nan] * 8\n",
    "            }\n",
    "            missing_run_df = pd.DataFrame(missing_run_data)\n",
    "            dataset_df = pd.concat([dataset_df, missing_run_df], ignore_index=True)\n",
    "            \n",
    "    # Apply min-max scaling to metric columns\n",
    "    for i in range(len(metric_cols_single_sample)):\n",
    "        min_val = dataset_df[metric_cols_single_sample[i]].min()\n",
    "        max_val = dataset_df[metric_cols_single_sample[i]].max()\n",
    "        dataset_df[metric_cols_single_sample[i] + \"_scaled\"] = ((\n",
    "            dataset_df[metric_cols_single_sample[i]] - min_val) / (max_val - min_val))\n",
    "\n",
    "    summary_df = pd.concat([summary_df, dataset_df], ignore_index=True)\n",
    "    continue\n",
    "    \n",
    "cat_0_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[0:2]]\n",
    "cat_1_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[2:4]]\n",
    "cat_2_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[4:6]]\n",
    "    \n",
    "summary_df[category_cols_single_sample[0]] = np.average(summary_df[cat_0_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[0:2],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_single_sample[1]] = np.average(summary_df[cat_1_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[2:4],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_single_sample[2]] = np.average(summary_df[cat_2_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[4:6],\n",
    "                                                        axis=1)\n",
    "summary_df[\"Overall Score\"] = np.average(summary_df[category_cols_single_sample[:3]],\n",
    "                                         weights=category_col_weights_single_sample[:3],\n",
    "                                         axis=1)\n",
    " \n",
    "# Reformat for plot\n",
    "summary_df.replace({\"nichecompass_gatv2conv\": \"NicheCompass\",\n",
    "                    \"nichecompass_gcnconv\": \"NicheCompass Light\",\n",
    "                    \"staci\": \"STACI\",\n",
    "                    \"deeplinc\": \"DeepLinc\",\n",
    "                    \"expimap\": \"expiMap\",\n",
    "                    \"graphst\": \"GraphST\",\n",
    "                    \"cellcharter\": \"CellCharter\",\n",
    "                    \"banksy\": \"BANKSY\"}, inplace=True)\n",
    "\n",
    "# Plot over all loss weights combinations\n",
    "# Prepare metrics table plot\n",
    "group_cols = [\"dataset\", \"model\"]\n",
    "aggregate_df = summary_df.groupby(group_cols).mean(\"Overall Score\").sort_values(\"Overall Score\", ascending=False)[\n",
    "    metric_cols_single_sample + [\"Overall Score\"]].reset_index()\n",
    "\n",
    "unrolled_df = pd.melt(\n",
    "    aggregate_df, \n",
    "    id_vars=group_cols,\n",
    "    value_vars=metric_cols_single_sample + [\"Overall Score\"],\n",
    "    var_name=\"score_type\", \n",
    "    value_name=\"score\")\n",
    "\n",
    "# Create spatial indicator column\n",
    "def is_spatially_aware_model(row):\n",
    "    if row[\"model\"] in [\"NicheCompass GCN\", \"NicheCompass GATv2\", \"DeepLinc\", \"GraphST\", \"CellCharter\"]:\n",
    "        return True\n",
    "    return False\n",
    "unrolled_df[\"spatially_aware\"] = unrolled_df.apply(lambda row: is_spatially_aware_model(row), axis=1)\n",
    "unrolled_df = unrolled_df[[\"dataset\", \"spatially_aware\", \"model\", \"score_type\", \"score\"]]\n",
    "\n",
    "# Order datasets\n",
    "unrolled_df[\"dataset\"] = pd.Categorical(unrolled_df[\"dataset\"], categories=datasets, ordered=True)\n",
    "unrolled_df = unrolled_df.sort_values(by=\"dataset\")\n",
    "\n",
    "#print(summary_df[\"model\"].value_counts())\n",
    "#print(summary_df[summary_df.isna().any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c60a27-c03e-4975-b0f2-42b780b162f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supplementary fig. 17: single sample runtimes ###\n",
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"DeepLinc\": \"#0E1C4A\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 \"CellCharter\": \"#F46AA2\",\n",
    "                 \"BANKSY\": \"#556B2F\",\n",
    "                 #\"scVI\": \"#FE8B3B\",\n",
    "                 #\"expiMap\": \"#7E0028\",\n",
    "                 }\n",
    "\n",
    "run_time_mean_df = summary_df.groupby([\"dataset\", \"model\"])[[\"run_time\"]].mean().reset_index()\n",
    "run_time_mean_df[\"run_time\"] = run_time_mean_df[\"run_time\"] / 60\n",
    "\n",
    "def create_dataset_share_col(row):\n",
    "    if row[\"dataset\"] == \"vizgen_merfish_mouse_liver\":\n",
    "        return 100\n",
    "    elif row[\"dataset\"] == \"vizgen_merfish_mouse_liver_subsample_50pct\":    \n",
    "        return 50\n",
    "    elif row[\"dataset\"] == \"vizgen_merfish_mouse_liver_subsample_25pct\":    \n",
    "        return 25\n",
    "    elif row[\"dataset\"] == \"vizgen_merfish_mouse_liver_subsample_10pct\":    \n",
    "        return 10\n",
    "    elif row[\"dataset\"] == \"vizgen_merfish_mouse_liver_subsample_5pct\":    \n",
    "        return 5\n",
    "    elif row[\"dataset\"] == \"vizgen_merfish_mouse_liver_subsample_1pct\":    \n",
    "        return 1\n",
    "    \n",
    "run_time_mean_df[\"dataset_share\"] = run_time_mean_df.apply(lambda row: create_dataset_share_col(row), axis=1)\n",
    "    \n",
    "ax = sns.lineplot(data=run_time_mean_df,\n",
    "                  x=\"dataset_share\",\n",
    "                  y=\"run_time\",\n",
    "                  hue=\"model\",\n",
    "                  marker='o',\n",
    "                  palette=model_palette)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "plt.title(\"MERFISH Mouse Liver\\n(367,335 Cells; 347 Genes)\")\n",
    "plt.ylabel(\"Run Time (Minutes)\")\n",
    "plt.xlabel(\"Dataset Size (%)\")\n",
    "custom_y_ticks = [1, 10, 60, 180, 360, 720, 1440]  # Adjust the tick positions as needed\n",
    "plt.yscale(\"log\")\n",
    "plt.yticks(custom_y_ticks, None)\n",
    "legend = plt.gca().get_legend()\n",
    "for handle in legend.legendHandles:\n",
    "    handle.set_linewidth(4.0)  # Adjust the size as needed\n",
    "handles, labels = legend.legendHandles, [text.get_text() for text in legend.get_texts()]\n",
    "order = [3, 2, 4, 1, 0]\n",
    "ordered_handles = [handles[i] for i in order]\n",
    "ordered_labels = [labels[i] for i in order]\n",
    "plt.legend(ordered_handles, ordered_labels)\n",
    "ax = plt.gca()\n",
    "ax.legend().set_visible(False)\n",
    "plt.savefig(benchmarking_folder_path + \"/benchmarking_runtimes_vizgen_merfish_mouse_liver.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a04483-34f3-4147-9282-041bfe9a21bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supplementary fig. 15b: single sample metric averages ###\n",
    "plot_metrics_table(\n",
    "    df=unrolled_df,\n",
    "    model_col=\"model\",\n",
    "    model_col_width=1.9,\n",
    "    group_col=\"dataset\",\n",
    "    metric_cols=metric_cols_single_sample, # metric_cols_single_sample, category_cols_single_sample\n",
    "    metric_col_weights=metric_col_weights_single_sample, # metric_col_weights_single_sample, category_col_weights_single_sample\n",
    "    metric_col_titles=[col.replace(\" \", \"\\n\") for col in metric_col_titles_single_sample], # category_col_titles_single_sample\n",
    "    metric_col_width=0.7, # 0.8,\n",
    "    aggregate_col_width=1.,\n",
    "    plot_width=42, # 32,\n",
    "    plot_height=8,\n",
    "    show=True,\n",
    "    save_dir=benchmarking_folder_path,\n",
    "    save_name=f\"benchmarking_metrics_vizgen_merfish_mouse_liver.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894d488a-bd39-4948-8288-8fb26ea35dc5",
   "metadata": {},
   "source": [
    "#### 2.1.5 All Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3583ccc4-f0e9-4894-b3ea-5f2de4fc2f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define params for plot formatting\n",
    "fig_width_10_ticks = 8.2\n",
    "fig_width_9_ticks = 7.8\n",
    "fig_width_8_ticks = 7.4\n",
    "fig_width_7_ticks = 7.0\n",
    "fig_width_6_ticks = 6.6\n",
    "fig_width_5_ticks = 6.2\n",
    "fig_width_2_ticks = 5.1\n",
    "fig_width_3_ticks = 5.5\n",
    "fig_width_4_ticks = 5.85\n",
    "fig_height = 5\n",
    "fontsize = 14\n",
    "row_fontsize = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1f66e5-16cb-41fe-aaff-b89b976ff101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metrics\n",
    "datasets = [\"slideseqv2_mouse_hippocampus\",\n",
    "            \"seqfish_mouse_organogenesis_embryo2\",\n",
    "            \"vizgen_merfish_mouse_liver\",\n",
    "            \"nanostring_cosmx_human_nsclc_batch5\",\n",
    "           ]\n",
    "models = [\"nichecompass_gatv2conv\",\n",
    "          \"nichecompass_gcnconv\",\n",
    "          \"staci\",\n",
    "          \"deeplinc\",\n",
    "          \"graphst\",\n",
    "          \"cellcharter\",\n",
    "          \"banksy\",\n",
    "         ]\n",
    "\n",
    "summary_df = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    dataset_df = pd.DataFrame()\n",
    "    for model in models:\n",
    "        try:\n",
    "            benchmark_df = pd.read_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\")\n",
    "            #adata = sc.read_h5ad(f\"../../artifacts/single_sample_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "            #training_durations = []\n",
    "            #for run_number in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "            #    training_durations.append(adata.uns[f\"{model.split('_')[0]}_model_training_duration_run{run_number}\"])\n",
    "            #benchmark_df[\"run_time\"] = training_durations\n",
    "            #benchmark_df = benchmark_df[[\"dataset\", \"run_number\", \"run_time\", \"gcs\", \"mlami\", \"cas\", \"clisis\", \"nasw\", \"cnmi\", \"cari\", \"casw\", \"clisi\"]]\n",
    "            #benchmark_df.to_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\", index=False)\n",
    "            benchmark_df[\"model\"] = model\n",
    "            dataset_df = pd.concat([dataset_df, benchmark_df], ignore_index=True)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Did not find file {benchmarking_folder_path}/{dataset}_{model}_metrics.csv. Continuing...\")\n",
    "            missing_run_data = {\n",
    "                \"dataset\": [dataset] * 8,\n",
    "                \"model\": [model] * 8,\n",
    "                \"run_number\": [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "                \"run_time\": [np.nan] * 8\n",
    "            }\n",
    "            missing_run_df = pd.DataFrame(missing_run_data)\n",
    "            dataset_df = pd.concat([dataset_df, missing_run_df], ignore_index=True)\n",
    "            \n",
    "    # Apply min-max scaling to metric columns\n",
    "    for i in range(len(metric_cols_single_sample)):\n",
    "        min_val = dataset_df[metric_cols_single_sample[i]].min()\n",
    "        max_val = dataset_df[metric_cols_single_sample[i]].max()\n",
    "        dataset_df[metric_cols_single_sample[i] + \"_scaled\"] = ((\n",
    "            dataset_df[metric_cols_single_sample[i]] - min_val) / (max_val - min_val))\n",
    "\n",
    "    summary_df = pd.concat([summary_df, dataset_df], ignore_index=True)\n",
    "    continue\n",
    "\n",
    "cat_0_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[0:2]]\n",
    "cat_1_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[2:4]]\n",
    "cat_2_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[4:6]]\n",
    "    \n",
    "summary_df[category_cols_single_sample[0]] = np.average(summary_df[cat_0_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[0:2],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_single_sample[1]] = np.average(summary_df[cat_1_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[2:4],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_single_sample[2]] = np.average(summary_df[cat_2_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[4:6],\n",
    "                                                        axis=1)\n",
    "summary_df[\"Overall Score\"] = np.average(summary_df[category_cols_single_sample[:3]],\n",
    "                                         weights=category_col_weights_single_sample[:3],\n",
    "                                         axis=1)\n",
    "\n",
    "# Reformat for plot\n",
    "summary_df.replace({\"nichecompass_gatv2conv\": \"NicheCompass\",\n",
    "                    \"nichecompass_gcnconv\": \"NicheCompass Light\",\n",
    "                    \"staci\": \"STACI\",\n",
    "                    \"deeplinc\": \"DeepLinc\",\n",
    "                    \"expimap\": \"expiMap\",\n",
    "                    \"graphst\": \"GraphST\",\n",
    "                    \"cellcharter\": \"CellCharter\",\n",
    "                    \"banksy\": \"BANKSY\"}, inplace=True)\n",
    "\n",
    "# Plot over all loss weights combinations\n",
    "# Prepare metrics table plot\n",
    "group_cols = [\"dataset\", \"model\"]\n",
    "aggregate_df = summary_df.groupby(group_cols).mean(\"Overall Score\").sort_values(\"Overall Score\", ascending=False)[\n",
    "    metric_cols_single_sample + [\"Overall Score\"]].reset_index()\n",
    "\n",
    "unrolled_df = pd.melt(\n",
    "    aggregate_df, \n",
    "    id_vars=group_cols,\n",
    "    value_vars=metric_cols_single_sample + [\"Overall Score\"],\n",
    "    var_name=\"score_type\", \n",
    "    value_name=\"score\")\n",
    "\n",
    "# Create spatial indicator column\n",
    "def is_spatially_aware_model(row):\n",
    "    if row[\"model\"] in [\"NicheCompass GCN\", \"NicheCompass GATv2\", \"STACI\", \"DeepLinc\", \"GraphST\", \"BANKSY\"]:\n",
    "        return True\n",
    "    return False\n",
    "unrolled_df[\"spatially_aware\"] = unrolled_df.apply(lambda row: is_spatially_aware_model(row), axis=1)\n",
    "unrolled_df = unrolled_df[[\"dataset\", \"spatially_aware\", \"model\", \"score_type\", \"score\"]]\n",
    "\n",
    "# Order datasets\n",
    "unrolled_df[\"dataset\"] = pd.Categorical(unrolled_df[\"dataset\"], categories=datasets, ordered=True)\n",
    "unrolled_df = unrolled_df.sort_values(by=\"dataset\")\n",
    "\n",
    "#print(summary_df[\"model\"].value_counts())\n",
    "#print(summary_df[summary_df.isna().any(axis=1)])\n",
    "\n",
    "summary_df[\"model\"] = summary_df[\"model\"].replace(\"NicheCompass GCN\", \"NicheCompass Light\")\n",
    "summary_df[\"model\"] = summary_df[\"model\"].replace(\"NicheCompass GATv2\", \"NicheCompass\")\n",
    "\n",
    "summary_df[\"dataset\"] = summary_df[\"dataset\"].replace(\n",
    "    {\"slideseqv2_mouse_hippocampus\": \"SlideSeqV2 Mouse Hippocampus\",\n",
    "     \"seqfish_mouse_organogenesis_embryo2\": \"seqFISH Mouse Organogenesis\",\n",
    "     \"nanostring_cosmx_human_nsclc_batch5\": \"nanoString CosMx Human NSCLC\",\n",
    "     \"vizgen_merfish_mouse_liver\": \"MERFISH Mouse Liver\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8673ab75-6490-4d77-bb22-0e14dcfc7821",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Supplementary fig. 15: single sample metrics cas ###\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"DeepLinc\": \"#0E1C4A\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 \"CellCharter\": \"#F46AA2\",\n",
    "                 \"BANKSY\": \"#556B2F\",\n",
    "                 #\"scVI\": \"#FE8B3B\",\n",
    "                 #\"expiMap\": \"#7E0028\",\n",
    "                 }\n",
    "\n",
    "plt.figure(figsize=(fig_width_9_ticks, fig_height))\n",
    "ax = sns.barplot(data=summary_df,\n",
    "                 x=\"cas\",\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette)\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + 1 * i, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(\"CAS\", fontsize=fontsize)\n",
    "plt.yticks(fontsize=row_fontsize)\n",
    "plt.xticks([0., 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8], fontsize=fontsize)\n",
    "plt.xlim(0., 0.9)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_barplot_cas.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be03a347-0043-4431-8493-00387e223420",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supplementary fig. 15: single sample metrics mlami ###\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"DeepLinc\": \"#0E1C4A\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 \"CellCharter\": \"#F46AA2\",\n",
    "                 \"BANKSY\": \"#556B2F\",\n",
    "                 #\"scVI\": \"#FE8B3B\",\n",
    "                 #\"expiMap\": \"#7E0028\",\n",
    "                 }\n",
    "\n",
    "plt.figure(figsize=(fig_width_9_ticks, fig_height))\n",
    "ax = sns.barplot(data=summary_df,\n",
    "                 x=\"mlami\",\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette)\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + 1 * i, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(\"MLAMI\", fontsize=fontsize)\n",
    "plt.yticks(fontsize=row_fontsize)\n",
    "plt.xticks([0., 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8], fontsize=fontsize)\n",
    "plt.xlim(0., 0.9)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_barplot_mlami.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd6204a-627a-440f-80e0-928b1b22edff",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supplementary fig. 15: single sample metrics clisis ###\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"DeepLinc\": \"#0E1C4A\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 \"CellCharter\": \"#F46AA2\",\n",
    "                 \"BANKSY\": \"#556B2F\",\n",
    "                 #\"scVI\": \"#FE8B3B\",\n",
    "                 #\"expiMap\": \"#7E0028\",\n",
    "                 }\n",
    "\n",
    "plt.figure(figsize=(fig_width_4_ticks, fig_height))\n",
    "ax = sns.barplot(data=summary_df,\n",
    "                 x=\"clisis\",\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette)\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + 1 * i, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(\"CLISIS\", fontsize=fontsize)\n",
    "plt.yticks(fontsize=row_fontsize)\n",
    "plt.xticks([0.6, 0.7, 0.8, 0.9], fontsize=fontsize)\n",
    "plt.xlim(0.6, 1.0)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_barplot_clisis.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a3a7cd-628c-4295-894a-055ee565311a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supplementary fig. 15: single sample metrics gcs ###\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"DeepLinc\": \"#0E1C4A\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 \"CellCharter\": \"#F46AA2\",\n",
    "                 \"BANKSY\": \"#556B2F\",\n",
    "                 #\"scVI\": \"#FE8B3B\",\n",
    "                 #\"expiMap\": \"#7E0028\",\n",
    "                 }\n",
    "\n",
    "plt.figure(figsize=(fig_width_3_ticks, fig_height))\n",
    "ax = sns.barplot(data=summary_df,\n",
    "                 x=\"gcs\",\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette)\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + 1 * i, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(\"GCS\", fontsize=fontsize)\n",
    "plt.yticks(fontsize=row_fontsize)\n",
    "plt.xticks([0.7, 0.8, 0.9], fontsize=fontsize)\n",
    "plt.xlim(0.7, 1.0)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_barplot_gcs.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0980900-e2d4-4ac0-91d2-37a75ad04c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df[\"Spatial Consistency Score\"] = (summary_df[\"Global Spatial Consistency Score\"] + summary_df[\"Local Spatial Consistency Score\"])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6761ecd-7851-4a4d-8acb-af31de076619",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fig. 3f: single sample metrics spatial consistency ###\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"DeepLinc\": \"#0E1C4A\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 \"CellCharter\": \"#F46AA2\",\n",
    "                 \"BANKSY\": \"#556B2F\",\n",
    "                 #\"scVI\": \"#FE8B3B\",\n",
    "                 #\"expiMap\": \"#7E0028\",\n",
    "                 }\n",
    "\n",
    "plt.figure(figsize=(fig_width_10_ticks*0.85, fig_height))\n",
    "ax = sns.barplot(data=summary_df,\n",
    "                 x=\"Spatial Consistency Score\",\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette)\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + 1 * i, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(\"Spatial Consistency Score\", fontsize=fontsize)\n",
    "plt.yticks(fontsize=row_fontsize)\n",
    "#plt.xticks([0., 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], fontsize=fontsize)\n",
    "plt.xlim(0., 1.0)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_barplot_spatial_consistency_score.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c562dd-ff23-49cb-9199-5bbb1a9e00ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"SlideSeqV2 Mouse Hippocampus\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"Spatial Consistency Score\"]].mean()\n",
    "metrics_temp_df.loc[\"NicheCompass\"][0] - np.max(metrics_temp_df[~metrics_temp_df.index.isin([\"NicheCompass\", \"NicheCompass Light\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a73de99-1100-4f80-9490-400564eed849",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"seqFISH Mouse Organogenesis\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"Spatial Consistency Score\"]].mean()\n",
    "metrics_temp_df.loc[\"NicheCompass\"][0] - np.max(metrics_temp_df[~metrics_temp_df.index.isin([\"NicheCompass\", \"NicheCompass Light\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a14a93f-97f7-4e22-931f-9a0e3e9c4653",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"MERFISH Mouse Liver\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"Spatial Consistency Score\"]].mean()\n",
    "metrics_temp_df.loc[\"NicheCompass\"][0] - np.max(metrics_temp_df[~metrics_temp_df.index.isin([\"NicheCompass\", \"NicheCompass Light\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823eb969-0b49-4842-9cad-9b914722d21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"nanoString CosMx Human NSCLC\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"Spatial Consistency Score\"]].mean()\n",
    "metrics_temp_df.loc[\"NicheCompass\"][0] - np.max(metrics_temp_df[~metrics_temp_df.index.isin([\"NicheCompass\", \"NicheCompass Light\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db62c0e0-e054-428b-9c85-38a75d6156fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supplementary fig. 15: single sample metrics cnmi ###\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"DeepLinc\": \"#0E1C4A\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 \"CellCharter\": \"#F46AA2\",\n",
    "                 \"BANKSY\": \"#556B2F\",\n",
    "                 #\"scVI\": \"#FE8B3B\",\n",
    "                 #\"expiMap\": \"#7E0028\",\n",
    "                 }\n",
    "\n",
    "plt.figure(figsize=(fig_width_6_ticks, fig_height))\n",
    "ax = sns.barplot(data=summary_df,\n",
    "                 x=\"cnmi\",\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette)\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + 1 * i, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(\"CNMI\", fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "plt.xticks([0., 0.1, 0.2, 0.3, 0.4, 0.5], fontsize=fontsize)\n",
    "plt.xlim(0., 0.6)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_barplot_cnmi.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8315f18c-1b56-48a0-ad41-342e30eb40a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supplementary fig. 15: single sample metrics nasw ###\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"DeepLinc\": \"#0E1C4A\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 \"CellCharter\": \"#F46AA2\",\n",
    "                 \"BANKSY\": \"#556B2F\",\n",
    "                 #\"scVI\": \"#FE8B3B\",\n",
    "                 #\"expiMap\": \"#7E0028\",\n",
    "                 }\n",
    "\n",
    "plt.figure(figsize=(fig_width_2_ticks, fig_height))\n",
    "ax = sns.barplot(data=summary_df,\n",
    "                 x=\"nasw\",\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette)\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + 1 * i, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(\"NASW\", fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "plt.xticks([0.5, 0.6], fontsize=fontsize)\n",
    "plt.xlim(0.5, 0.7)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_barplot_nasw.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e056ef-e52c-4116-9a6e-900f6cee22fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fig. 3f: single sample metrics niche coherence ###\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"DeepLinc\": \"#0E1C4A\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 \"CellCharter\": \"#F46AA2\",\n",
    "                 \"BANKSY\": \"#556B2F\",\n",
    "                 #\"scVI\": \"#FE8B3B\",\n",
    "                 #\"expiMap\": \"#7E0028\",\n",
    "                 }\n",
    "\n",
    "plt.figure(figsize=(fig_width_7_ticks*0.85, 5))\n",
    "ax = sns.barplot(data=summary_df,\n",
    "                 x=\"Niche Coherence Score\",\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette)\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + 1 * i, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(\"Niche Coherence Score\", fontsize=fontsize)\n",
    "plt.yticks(fontsize=row_fontsize)\n",
    "#plt.xticks([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7], fontsize=fontsize)\n",
    "plt.xlim(0.1, 0.9)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_barplot_niche_coherence_score.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9ccfe0-6e68-4e5a-94ad-80e27ba5faf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"SlideSeqV2 Mouse Hippocampus\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"Niche Coherence Score\"]].mean()\n",
    "metrics_temp_df.loc[\"NicheCompass\"][0] - np.max(metrics_temp_df[~metrics_temp_df.index.isin([\"NicheCompass\", \"NicheCompass Light\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68261152-9df8-445a-a8a2-eb45c075a27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"seqFISH Mouse Organogenesis\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"Niche Coherence Score\"]].mean()\n",
    "metrics_temp_df.loc[\"NicheCompass\"][0] - np.max(metrics_temp_df[~metrics_temp_df.index.isin([\"NicheCompass\", \"NicheCompass Light\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d02608-def5-45e5-9360-a54af1080406",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"MERFISH Mouse Liver\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"Niche Coherence Score\"]].mean()\n",
    "metrics_temp_df.loc[\"NicheCompass\"][0] - np.max(metrics_temp_df[~metrics_temp_df.index.isin([\"NicheCompass\", \"NicheCompass Light\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac8e1fc-c24d-44bc-930c-f9373788664d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"nanoString CosMx Human NSCLC\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"Niche Coherence Score\"]].mean()\n",
    "metrics_temp_df.loc[\"NicheCompass\"][0] - np.max(metrics_temp_df[~metrics_temp_df.index.isin([\"NicheCompass\", \"NicheCompass Light\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae744721-2649-4e0b-87e6-e00d28a6d534",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fig. 3f: single sample metrics overall ###\n",
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"DeepLinc\": \"#0E1C4A\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 \"CellCharter\": \"#F46AA2\",\n",
    "                 \"BANKSY\": \"#556B2F\",\n",
    "                 #\"scVI\": \"#FE8B3B\",\n",
    "                 #\"expiMap\": \"#7E0028\",\n",
    "                 }\n",
    "\n",
    "plt.figure(figsize=(fig_width_7_ticks*0.85, fig_height))\n",
    "ax = sns.barplot(data=summary_df,\n",
    "                 x=\"Overall Score\",\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette)\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + 1 * i, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(\"Overall Score\", fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "#plt.xticks([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7], fontsize=fontsize)\n",
    "plt.xlim(0.05, 0.8)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_barplot_overall_score.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81bc2d1-2e26-40d6-99a5-9c510e8fb9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"SlideSeqV2 Mouse Hippocampus\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"Overall Score\"]].mean()\n",
    "metrics_temp_df.loc[\"NicheCompass\"][0] - np.max(metrics_temp_df[~metrics_temp_df.index.isin([\"NicheCompass\", \"NicheCompass Light\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04054b32-46e0-4411-bb88-9c4862f8ea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"seqFISH Mouse Organogenesis\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"Overall Score\"]].mean()\n",
    "metrics_temp_df.loc[\"NicheCompass\"][0] - np.max(metrics_temp_df[~metrics_temp_df.index.isin([\"NicheCompass\", \"NicheCompass Light\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d7d747-820c-4a72-9fcd-598d4867e24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"MERFISH Mouse Liver\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"Overall Score\"]].mean()\n",
    "metrics_temp_df.loc[\"NicheCompass\"][0] - np.max(metrics_temp_df[~metrics_temp_df.index.isin([\"NicheCompass\", \"NicheCompass Light\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f388b353-c753-46c5-b085-69a4ffe5ba0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"nanoString CosMx Human NSCLC\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"Overall Score\"]].mean()\n",
    "metrics_temp_df.loc[\"NicheCompass\"][0] - np.max(metrics_temp_df[~metrics_temp_df.index.isin([\"NicheCompass\", \"NicheCompass Light\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87759e01-86e7-4a47-83fc-b4a85debee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supplementary fig. 17: gene scalability analysis ###\n",
    "size_dict = {}\n",
    "size_dict[\"dataset\"] = [] \n",
    "size_dict[\"n_genes\"] = []\n",
    "size_dict[\"n_gps\"] = []\n",
    "size_dict[\"n_params\"] = []\n",
    "\n",
    "model_label = \"gatv2conv_single_sample_method_benchmarking\"\n",
    "run = \"run1\"\n",
    "\n",
    "for dataset, timestamp in zip(\n",
    "    [\"slideseqv2_mouse_hippocampus\", # 256 edge batch size\n",
    "     \"seqfish_mouse_organogenesis_embryo2\", # 2048 edge batch size\n",
    "     \"vizgen_merfish_mouse_liver\", # 512 edge batch size\n",
    "     \"nanostring_cosmx_human_nsclc_batch5\"], # 512 edge batch size\n",
    "    [\"17082023_104409_1\",\n",
    "     \"16082023_153513_1\",\n",
    "     \"18082023_191958_4\",\n",
    "     \"11092023_224108_2\"]):\n",
    "\n",
    "    model_folder_path = f\"{artifact_folder_path}/{dataset}/models/{model_label}/{timestamp}/{run}\"\n",
    "    model = NicheCompass.load(dir_path=model_folder_path,\n",
    "                              adata=None,\n",
    "                              adata_file_name=f\"{dataset}_{model_label}.h5ad\",\n",
    "                              gp_names_key=\"nichecompass_gp_names\")\n",
    "\n",
    "    size_dict[\"dataset\"].append(dataset)\n",
    "    size_dict[\"n_genes\"].append(len(model.adata.var))\n",
    "    size_dict[\"n_gps\"].append(model.adata.obsm[\"nichecompass_latent\"].shape[1])\n",
    "    size_dict[\"n_params\"].append(sum(p.numel() for p in model.model.parameters()))\n",
    "    \n",
    "size_df = pd.DataFrame(size_dict)\n",
    "size_df.to_csv(f\"{benchmarking_folder_path}/model_sizes.csv\", index=False)\n",
    "size_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed2b7ca-7caf-4901-8141-509f9dd7f571",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_df.columns = [\"Dataset\", \"Number of Genes\", \"Number of GPs\", \"Number of Params\"]\n",
    "\n",
    "size_df[\"Dataset\"].replace({\"slideseqv2_mouse_hippocampus\": \"SlideSeqV2 Mouse Hippocampus\",\n",
    "                            \"seqfish_mouse_organogenesis_embryo2\": \"seqFISH Mouse Organogenesis\",\n",
    "                            \"vizgen_merfish_mouse_liver\": \"MERFISH Mouse Liver\",\n",
    "                            \"nanostring_cosmx_human_nsclc_batch5\": \"Nanostring CosMx Human NSCLC\"}, inplace=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 2))\n",
    "ax.axis('off')\n",
    "ax.axis('tight')\n",
    "table = ax.table(cellText=size_df.values,\n",
    "                 colLabels=size_df.columns,\n",
    "                 cellLoc='center',\n",
    "                 loc='center',\n",
    "                 colColours=[\"lightblue\"] + [\"darkgrey\"]*(len(size_df.columns)-1))\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(14)\n",
    "table.scale(1.8, 2.)\n",
    "plt.savefig(f\"{benchmarking_folder_path}/model_sizes.svg\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769da142-d816-4aa7-a148-2e73959b075a",
   "metadata": {},
   "source": [
    "#### 2.1.6 Simulation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477d0396-b20a-45d5-82ff-03725f94a6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metrics\n",
    "datasets = [\"sim1_1105genes_10000locs_strongincrements\"]\n",
    "models = [\"nichecompass_gatv2conv\",\n",
    "          \"nichecompass_gcnconv\",\n",
    "          \"staci\",\n",
    "          \"deeplinc\",\n",
    "          \"graphst\",\n",
    "          \"cellcharter\",\n",
    "          \"banksy\"\n",
    "         ]\n",
    "\n",
    "summary_df = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    dataset_df = pd.DataFrame()\n",
    "    for model in models:\n",
    "        try:\n",
    "            benchmark_df = pd.read_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\")\n",
    "            #adata = sc.read_h5ad(f\"../../artifacts/single_sample_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "            #training_durations = []\n",
    "            #for run_number in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "            #    training_durations.append(adata.uns[f\"{model.split('_')[0]}_model_training_duration_run{run_number}\"])\n",
    "            #benchmark_df[\"run_time\"] = training_durations\n",
    "            #benchmark_df = benchmark_df[[\"dataset\", \"run_number\", \"run_time\", \"gcs\", \"mlami\", \"cas\", \"clisis\", \"nasw\", \"cnmi\", \"cari\", \"casw\", \"clisi\"]]\n",
    "            #benchmark_df.to_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\", index=False)\n",
    "            benchmark_df[\"model\"] = model\n",
    "            dataset_df = pd.concat([dataset_df, benchmark_df], ignore_index=True)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Did not find file {benchmarking_folder_path}/{dataset}_{model}_metrics.csv. Continuing...\")\n",
    "            missing_run_data = {\n",
    "                \"dataset\": [dataset] * 8,\n",
    "                \"model\": [model] * 8,\n",
    "                \"run_number\": [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "                \"run_time\": [np.nan] * 8\n",
    "            }\n",
    "            missing_run_df = pd.DataFrame(missing_run_data)\n",
    "            dataset_df = pd.concat([dataset_df, missing_run_df], ignore_index=True)\n",
    "            \n",
    "    # Apply min-max scaling to metric columns\n",
    "    for i in range(len(metric_cols_single_sample)):\n",
    "        min_val = dataset_df[metric_cols_single_sample[i]].min()\n",
    "        max_val = dataset_df[metric_cols_single_sample[i]].max()\n",
    "        dataset_df[metric_cols_single_sample[i] + \"_scaled\"] = ((\n",
    "            dataset_df[metric_cols_single_sample[i]] - min_val) / (max_val - min_val))\n",
    "        \n",
    "    for i in range(len(sdm_bench_metric_cols)):\n",
    "        min_val = dataset_df[sdm_bench_metric_cols[i]].min()\n",
    "        max_val = dataset_df[sdm_bench_metric_cols[i]].max()\n",
    "        dataset_df[sdm_bench_metric_cols[i] + \"_scaled\"] = ((\n",
    "            dataset_df[sdm_bench_metric_cols[i]] - min_val) / (max_val - min_val))\n",
    "\n",
    "    summary_df = pd.concat([summary_df, dataset_df], ignore_index=True)\n",
    "    continue\n",
    "    \n",
    "cat_0_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[0:2]]\n",
    "cat_1_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[2:4]]\n",
    "cat_2_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[4:6]]\n",
    "    \n",
    "summary_df[category_cols_single_sample[0]] = np.average(summary_df[cat_0_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[0:2],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_single_sample[1]] = np.average(summary_df[cat_1_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[2:4],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_single_sample[2]] = np.average(summary_df[cat_2_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[4:6],\n",
    "                                                        axis=1)\n",
    "summary_df[\"Overall Score\"] = np.average(summary_df[category_cols_single_sample[:3]],\n",
    "                                         weights=category_col_weights_single_sample[:3],\n",
    "                                         axis=1)\n",
    "summary_df[\"Ground Truth Prediction Score\"] = np.average(summary_df[sdm_bench_metric_cols],\n",
    "                                                         weights=sdm_bench_metric_col_weights,\n",
    "                                                         axis=1)\n",
    " \n",
    "# Reformat for plot\n",
    "summary_df.replace({\"nichecompass_gatv2conv\": \"NicheCompass\",\n",
    "                    \"nichecompass_gcnconv\": \"NicheCompass Light\",\n",
    "                    \"staci\": \"STACI\",\n",
    "                    \"deeplinc\": \"DeepLinc\",\n",
    "                    \"expimap\": \"expiMap\",\n",
    "                    \"graphst\": \"GraphST\",\n",
    "                    \"cellcharter\": \"CellCharter\",\n",
    "                    \"banksy\": \"BANKSY\"}, inplace=True)\n",
    "\n",
    "# Plot over all loss weights combinations\n",
    "# Prepare metrics table plot\n",
    "group_cols = [\"dataset\", \"model\"]\n",
    "aggregate_df = summary_df.groupby(group_cols).mean(\"Overall Score\").sort_values(\"Overall Score\", ascending=False)[\n",
    "    metric_cols_single_sample + [\"Overall Score\"] + sdm_bench_metric_cols + [\"Ground Truth Prediction Score\"]].reset_index()\n",
    "\n",
    "unrolled_df = pd.melt(\n",
    "    aggregate_df, \n",
    "    id_vars=group_cols,\n",
    "    value_vars=metric_cols_single_sample + [\"Overall Score\"] + sdm_bench_metric_cols + [\"Ground Truth Prediction Score\"],\n",
    "    var_name=\"score_type\", \n",
    "    value_name=\"score\")\n",
    "\n",
    "# Create spatial indicator column\n",
    "def is_spatially_aware_model(row):\n",
    "    if row[\"model\"] in [\"NicheCompass GCN\", \"NicheCompass GATv2\", \"DeepLinc\", \"GraphST\", \"CellCharter\"]:\n",
    "        return True\n",
    "    return False\n",
    "unrolled_df[\"spatially_aware\"] = unrolled_df.apply(lambda row: is_spatially_aware_model(row), axis=1)\n",
    "unrolled_df = unrolled_df[[\"dataset\", \"spatially_aware\", \"model\", \"score_type\", \"score\"]]\n",
    "\n",
    "# Order datasets\n",
    "unrolled_df[\"dataset\"] = pd.Categorical(unrolled_df[\"dataset\"], categories=datasets, ordered=True)\n",
    "unrolled_df = unrolled_df.sort_values(by=\"dataset\")\n",
    "\n",
    "#print(summary_df[\"model\"].value_counts())\n",
    "#print(summary_df[summary_df.isna().any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8817c7-7201-459f-a75c-922bc056eef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"sim1_1105genes_10000locs_strongincrements\"\n",
    "\n",
    "# Plot table\n",
    "plot_simple_metrics_table(\n",
    "    df=unrolled_df,\n",
    "    model_col=\"model\",\n",
    "    model_col_width=1.6,\n",
    "    group_col=\"dataset\",\n",
    "    metric_cols=metric_cols_single_sample, # metric_cols_single_sample, category_cols_single_sample\n",
    "    metric_col_weights=metric_col_weights_single_sample, # metric_col_weights_single_sample, category_col_weights_single_sample\n",
    "    metric_col_titles=[col.replace(\" \", \"\\n\") for col in metric_col_titles_single_sample], # category_col_titles_single_sample\n",
    "    metric_col_width=0.5, # 0.8,\n",
    "    aggregate_col_width=1.2,\n",
    "    plot_width=10, # 8.5, # 32,\n",
    "    plot_height=7,# 8,\n",
    "    show=True,\n",
    "    save_dir=benchmarking_folder_path,\n",
    "    save_name=f\"benchmarking_metrics_{dataset}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3177f2f0-63a6-4320-8ec8-a7c0a5d9cd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"sim1_1105genes_10000locs_strongincrements\"\n",
    "\n",
    "# Plot table\n",
    "plot_simple_metrics_table(\n",
    "    df=unrolled_df,\n",
    "    model_col=\"model\",\n",
    "    model_col_width=1.6,\n",
    "    group_col=\"dataset\",\n",
    "    metric_cols=sdm_bench_metric_cols, # metric_cols_single_sample, category_cols_single_sample\n",
    "    metric_col_weights=sdm_bench_metric_col_weights, # metric_col_weights_single_sample, category_col_weights_single_sample\n",
    "    metric_col_titles=sdm_bench_metric_col_titles, # category_col_titles_single_sample\n",
    "    metric_col_width=0.5, # 0.5\n",
    "    aggregate_col_width=1.2,\n",
    "    plot_width=8, # 6.5\n",
    "    plot_height=7,\n",
    "    overall_score_col=\"Ground Truth Prediction Score\",\n",
    "    show=True,\n",
    "    save_dir=benchmarking_folder_path,\n",
    "    save_name=f\"benchmarking_metrics_ground_truth_{dataset}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d7b63-e488-4207-8443-0873b29af482",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"sim1_1105genes_10000locs_strongincrements\"\n",
    "models = [\"nichecompass_gcnconv\"]\n",
    "run_number = 2\n",
    "leiden_resolutions = [0.1]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    adata = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_{model}.h5ad\")\n",
    "    model = model.replace(\"_gcnconv\", \"\").replace(\"_gatv2conv\", \"\")\n",
    "    adata.obs[\"sample\"] = \"sample1\"\n",
    "    \n",
    "    print(\"\\nComputing neighbor graph...\")\n",
    "    # Use latent representation for UMAP generation\n",
    "    sc.pp.neighbors(adata,\n",
    "                    use_rep=f\"{model}_latent_run{run_number}\",\n",
    "                    key_added=f\"{model}_latent_run{run_number}\")\n",
    "\n",
    "    print(\"\\nComputing UMAP embedding...\")\n",
    "    sc.tl.umap(adata,\n",
    "               neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "        \n",
    "    print(\"\\nComputing Leiden clustering...\")\n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=leiden_resolutions[i],\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    niche_annotations = {\n",
    "        \"0\": \"Niche 1\",\n",
    "        \"1\": \"Niche 2\",\n",
    "        \"2\": \"Niche 3\",\n",
    "        \"3\": \"Niche 4\",        \n",
    "        \"4\": \"Niche 5\", \n",
    "        \"5\": \"Niche 6\", \n",
    "        \"6\": \"Niche 7\", \n",
    "        \"7\": \"Niche 8\"}\n",
    "\n",
    "    adata.obs[\"niche\"] = adata.obs[f\"run{run_number}_leiden_{leiden_resolutions[0]}\"].map(niche_annotations)\n",
    "\n",
    "    latent_cluster_colors = create_new_color_dict(\n",
    "        adata=adata,\n",
    "        cat_key=f\"run{run_number}_leiden_{leiden_resolutions[i]}\")\n",
    "    \n",
    "    niche_colors = {niche: latent_cluster_colors[cluster] for cluster, niche in niche_annotations.items()}\n",
    "    \n",
    "    plot_category_in_latent_and_physical_space(\n",
    "            adata=adata,\n",
    "            #figsize=(10, 20), for latent UMAP\n",
    "            plot_label=\"Latent Clusters\",\n",
    "            model_label={model},\n",
    "            cat_key=f\"niche\",\n",
    "            groups=None,\n",
    "            sample_key=\"sample\",\n",
    "            samples=[\"sample1\"], # =None for latent UMAP\n",
    "            cat_colors=niche_colors,\n",
    "            size=(720000 / len(adata)),\n",
    "            spot_size=30,\n",
    "            save_fig=True,\n",
    "            file_path=f\"{benchmarking_folder_path}/latent_clusters_{model}gcnconv_{dataset}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa55eeb3-8a57-45af-a73c-13146abad2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"sim1_1105genes_10000locs_strongincrements\"\n",
    "models = [\"nichecompass_gatv2conv\"]\n",
    "run_number = 2\n",
    "leiden_resolutions = [0.1]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    adata = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_{model}.h5ad\")\n",
    "    model = model.replace(\"_gcnconv\", \"\").replace(\"_gatv2conv\", \"\")\n",
    "    adata.obs[\"sample\"] = \"sample1\"\n",
    "    \n",
    "    print(\"\\nComputing neighbor graph...\")\n",
    "    # Use latent representation for UMAP generation\n",
    "    sc.pp.neighbors(adata,\n",
    "                    use_rep=f\"{model}_latent_run{run_number}\",\n",
    "                    key_added=f\"{model}_latent_run{run_number}\")\n",
    "\n",
    "    print(\"\\nComputing UMAP embedding...\")\n",
    "    sc.tl.umap(adata,\n",
    "               neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "        \n",
    "    print(\"\\nComputing Leiden clustering...\")\n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=leiden_resolutions[i],\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    niche_annotations = {\n",
    "        \"0\": \"Niche 1\",\n",
    "        \"1\": \"Niche 2\",\n",
    "        \"2\": \"Niche 3\",\n",
    "        \"3\": \"Niche 4\",        \n",
    "        \"4\": \"Niche 5\", \n",
    "        \"5\": \"Niche 6\", \n",
    "        \"6\": \"Niche 7\", \n",
    "        \"7\": \"Niche 8\"}\n",
    "\n",
    "    adata.obs[\"niche\"] = adata.obs[f\"run{run_number}_leiden_{leiden_resolutions[0]}\"].map(niche_annotations)\n",
    "\n",
    "    latent_cluster_colors = create_new_color_dict(\n",
    "        adata=adata,\n",
    "        cat_key=f\"run{run_number}_leiden_{leiden_resolutions[i]}\")\n",
    "    \n",
    "    niche_colors = {niche: latent_cluster_colors[cluster] for cluster, niche in niche_annotations.items()}\n",
    "    \n",
    "    plot_category_in_latent_and_physical_space(\n",
    "            adata=adata,\n",
    "            #figsize=(10, 20), for latent UMAP\n",
    "            plot_label=\"Latent Clusters\",\n",
    "            model_label={model},\n",
    "            cat_key=f\"niche\",\n",
    "            groups=None,\n",
    "            sample_key=\"sample\",\n",
    "            samples=[\"sample1\"], # =None for latent UMAP\n",
    "            cat_colors=niche_colors,\n",
    "            size=(720000 / len(adata)),\n",
    "            spot_size=30,\n",
    "            save_fig=True,\n",
    "            file_path=f\"{benchmarking_folder_path}/latent_clusters_{model}gatv2conv_{dataset}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc2d9ef-a972-4e3d-a906-77174227686b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"sim1_1105genes_10000locs_strongincrements\"\n",
    "models = [\"banksy\"]\n",
    "run_number = 2\n",
    "leiden_resolutions = [0.3]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    adata = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_{model}.h5ad\")\n",
    "    model = model.replace(\"_gcnconv\", \"\").replace(\"_gatv2conv\", \"\")\n",
    "    adata.obs[\"sample\"] = \"sample1\"\n",
    "    \n",
    "    print(\"\\nComputing neighbor graph...\")\n",
    "    # Use latent representation for UMAP generation\n",
    "    sc.pp.neighbors(adata,\n",
    "                    use_rep=f\"{model}_latent_run{run_number}\",\n",
    "                    key_added=f\"{model}_latent_run{run_number}\")\n",
    "\n",
    "    print(\"\\nComputing UMAP embedding...\")\n",
    "    sc.tl.umap(adata,\n",
    "               neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "        \n",
    "    print(\"\\nComputing Leiden clustering...\")\n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=leiden_resolutions[i],\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    niche_annotations = {\n",
    "        \"0\": \"Niche 1\",\n",
    "        \"1\": \"Niche 2\",\n",
    "        \"2\": \"Niche 3\",\n",
    "        \"3\": \"Niche 4\",        \n",
    "        \"4\": \"Niche 5\", \n",
    "        \"5\": \"Niche 6\", \n",
    "        \"6\": \"Niche 7\", \n",
    "        \"7\": \"Niche 8\"}\n",
    "\n",
    "    adata.obs[\"niche\"] = adata.obs[f\"run{run_number}_leiden_{leiden_resolutions[0]}\"].map(niche_annotations)\n",
    "\n",
    "    latent_cluster_colors = create_new_color_dict(\n",
    "        adata=adata,\n",
    "        cat_key=f\"run{run_number}_leiden_{leiden_resolutions[i]}\")\n",
    "    \n",
    "    niche_colors = {niche: latent_cluster_colors[cluster] for cluster, niche in niche_annotations.items()}\n",
    "    \n",
    "    plot_category_in_latent_and_physical_space(\n",
    "            adata=adata,\n",
    "            #figsize=(10, 20), for latent UMAP\n",
    "            plot_label=\"Latent Clusters\",\n",
    "            model_label={model},\n",
    "            cat_key=f\"niche\",\n",
    "            groups=None,\n",
    "            sample_key=\"sample\",\n",
    "            samples=[\"sample1\"], # =None for latent UMAP\n",
    "            cat_colors=niche_colors,\n",
    "            size=(720000 / len(adata)),\n",
    "            spot_size=30,\n",
    "            save_fig=True,\n",
    "            file_path=f\"{benchmarking_folder_path}/latent_clusters_{model}_{dataset}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fafa39-5204-461f-b6f1-6d0a34be95ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"sim1_1105genes_10000locs_strongincrements\"\n",
    "models = [\"graphst\"]\n",
    "run_number = 2\n",
    "leiden_resolutions = [0.5]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    adata = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_{model}.h5ad\")\n",
    "    model = model.replace(\"_gcnconv\", \"\").replace(\"_gatv2conv\", \"\")\n",
    "    adata.obs[\"sample\"] = \"sample1\"\n",
    "    \n",
    "    print(\"\\nComputing neighbor graph...\")\n",
    "    # Use latent representation for UMAP generation\n",
    "    sc.pp.neighbors(adata,\n",
    "                    use_rep=f\"{model}_latent_run{run_number}\",\n",
    "                    key_added=f\"{model}_latent_run{run_number}\")\n",
    "\n",
    "    print(\"\\nComputing UMAP embedding...\")\n",
    "    sc.tl.umap(adata,\n",
    "               neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "        \n",
    "    print(\"\\nComputing Leiden clustering...\")\n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=leiden_resolutions[i],\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    niche_annotations = {\n",
    "        \"0\": \"Niche 1\",\n",
    "        \"1\": \"Niche 2\",\n",
    "        \"2\": \"Niche 3\",\n",
    "        \"3\": \"Niche 4\",        \n",
    "        \"4\": \"Niche 5\", \n",
    "        \"5\": \"Niche 6\", \n",
    "        \"6\": \"Niche 7\", \n",
    "        \"7\": \"Niche 8\"}\n",
    "\n",
    "    adata.obs[\"niche\"] = adata.obs[f\"run{run_number}_leiden_{leiden_resolutions[0]}\"].map(niche_annotations)\n",
    "\n",
    "    latent_cluster_colors = create_new_color_dict(\n",
    "        adata=adata,\n",
    "        cat_key=f\"run{run_number}_leiden_{leiden_resolutions[i]}\")\n",
    "    \n",
    "    niche_colors = {niche: latent_cluster_colors[cluster] for cluster, niche in niche_annotations.items()}\n",
    "    \n",
    "    plot_category_in_latent_and_physical_space(\n",
    "            adata=adata,\n",
    "            #figsize=(10, 20), for latent UMAP\n",
    "            plot_label=\"Latent Clusters\",\n",
    "            model_label={model},\n",
    "            cat_key=f\"niche\",\n",
    "            groups=None,\n",
    "            sample_key=\"sample\",\n",
    "            samples=[\"sample1\"], # =None for latent UMAP\n",
    "            cat_colors=niche_colors,\n",
    "            size=(720000 / len(adata)),\n",
    "            spot_size=30,\n",
    "            save_fig=True,\n",
    "            file_path=f\"{benchmarking_folder_path}/latent_clusters_{model}_{dataset}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a705de-255c-4c27-9bee-da9ceafec806",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"sim1_1105genes_10000locs_strongincrements\"\n",
    "models = [\"staci\"]\n",
    "run_number = 2\n",
    "leiden_resolutions = [0.5]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    adata = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_{model}.h5ad\")\n",
    "    model = model.replace(\"_gcnconv\", \"\").replace(\"_gatv2conv\", \"\")\n",
    "    adata.obs[\"sample\"] = \"sample1\"\n",
    "    \n",
    "    print(\"\\nComputing neighbor graph...\")\n",
    "    # Use latent representation for UMAP generation\n",
    "    sc.pp.neighbors(adata,\n",
    "                    use_rep=f\"{model}_latent_run{run_number}\",\n",
    "                    key_added=f\"{model}_latent_run{run_number}\")\n",
    "\n",
    "    print(\"\\nComputing UMAP embedding...\")\n",
    "    sc.tl.umap(adata,\n",
    "               neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "        \n",
    "    print(\"\\nComputing Leiden clustering...\")\n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=leiden_resolutions[i],\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    niche_annotations = {\n",
    "        \"0\": \"Niche 1\",\n",
    "        \"1\": \"Niche 2\",\n",
    "        \"2\": \"Niche 3\",\n",
    "        \"3\": \"Niche 4\",        \n",
    "        \"4\": \"Niche 5\", \n",
    "        \"5\": \"Niche 6\", \n",
    "        \"6\": \"Niche 7\", \n",
    "        \"7\": \"Niche 8\"}\n",
    "\n",
    "    adata.obs[\"niche\"] = adata.obs[f\"run{run_number}_leiden_{leiden_resolutions[0]}\"].map(niche_annotations)\n",
    "\n",
    "    latent_cluster_colors = create_new_color_dict(\n",
    "        adata=adata,\n",
    "        cat_key=f\"run{run_number}_leiden_{leiden_resolutions[i]}\")\n",
    "    \n",
    "    niche_colors = {niche: latent_cluster_colors[cluster] for cluster, niche in niche_annotations.items()}\n",
    "    \n",
    "    plot_category_in_latent_and_physical_space(\n",
    "            adata=adata,\n",
    "            #figsize=(10, 20), for latent UMAP\n",
    "            plot_label=\"Latent Clusters\",\n",
    "            model_label={model},\n",
    "            cat_key=f\"niche\",\n",
    "            groups=None,\n",
    "            sample_key=\"sample\",\n",
    "            samples=[\"sample1\"], # =None for latent UMAP\n",
    "            cat_colors=niche_colors,\n",
    "            size=(720000 / len(adata)),\n",
    "            spot_size=30,\n",
    "            save_fig=True,\n",
    "            file_path=f\"{benchmarking_folder_path}/latent_clusters_{model}_{dataset}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33c0460-658d-4fb9-b7b7-9fa1bd19760e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"sim1_1105genes_10000locs_strongincrements\"\n",
    "models = [\"cellcharter\"]\n",
    "run_number = 2\n",
    "leiden_resolutions = [0.191]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    adata = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_{model}.h5ad\")\n",
    "    model = model.replace(\"_gcnconv\", \"\").replace(\"_gatv2conv\", \"\")\n",
    "    adata.obs[\"sample\"] = \"sample1\"\n",
    "    \n",
    "    print(\"\\nComputing neighbor graph...\")\n",
    "    # Use latent representation for UMAP generation\n",
    "    sc.pp.neighbors(adata,\n",
    "                    use_rep=f\"{model}_latent_run{run_number}\",\n",
    "                    key_added=f\"{model}_latent_run{run_number}\")\n",
    "\n",
    "    print(\"\\nComputing UMAP embedding...\")\n",
    "    sc.tl.umap(adata,\n",
    "               neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "        \n",
    "    print(\"\\nComputing Leiden clustering...\")\n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=leiden_resolutions[i],\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    niche_annotations = {\n",
    "        \"0\": \"Niche 1\",\n",
    "        \"1\": \"Niche 2\",\n",
    "        \"2\": \"Niche 3\",\n",
    "        \"3\": \"Niche 4\",        \n",
    "        \"4\": \"Niche 5\", \n",
    "        \"5\": \"Niche 6\", \n",
    "        \"6\": \"Niche 7\", \n",
    "        \"7\": \"Niche 8\"}\n",
    "\n",
    "    adata.obs[\"niche\"] = adata.obs[f\"run{run_number}_leiden_{leiden_resolutions[0]}\"].map(niche_annotations)\n",
    "\n",
    "    latent_cluster_colors = create_new_color_dict(\n",
    "        adata=adata,\n",
    "        cat_key=f\"run{run_number}_leiden_{leiden_resolutions[i]}\")\n",
    "    \n",
    "    niche_colors = {niche: latent_cluster_colors[cluster] for cluster, niche in niche_annotations.items()}\n",
    "    \n",
    "    plot_category_in_latent_and_physical_space(\n",
    "            adata=adata,\n",
    "            #figsize=(10, 20), for latent UMAP\n",
    "            plot_label=\"Latent Clusters\",\n",
    "            model_label={model},\n",
    "            cat_key=f\"niche\",\n",
    "            groups=None,\n",
    "            sample_key=\"sample\",\n",
    "            samples=[\"sample1\"], # =None for latent UMAP\n",
    "            cat_colors=niche_colors,\n",
    "            size=(720000 / len(adata)),\n",
    "            spot_size=30,\n",
    "            save_fig=True,\n",
    "            file_path=f\"{benchmarking_folder_path}/latent_clusters_{model}_{dataset}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee2dc56-8ee2-41a1-93e3-2bfc75414c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"sim1_1105genes_10000locs_strongincrements\"\n",
    "models = [\"deeplinc\"]\n",
    "run_number = 2\n",
    "leiden_resolutions = [1.5]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    adata = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_{model}.h5ad\")\n",
    "    model = model.replace(\"_gcnconv\", \"\").replace(\"_gatv2conv\", \"\")\n",
    "    adata.obs[\"sample\"] = \"sample1\"\n",
    "    \n",
    "    print(\"\\nComputing neighbor graph...\")\n",
    "    # Use latent representation for UMAP generation\n",
    "    sc.pp.neighbors(adata,\n",
    "                    use_rep=f\"{model}_latent_run{run_number}\",\n",
    "                    key_added=f\"{model}_latent_run{run_number}\")\n",
    "\n",
    "    print(\"\\nComputing UMAP embedding...\")\n",
    "    sc.tl.umap(adata,\n",
    "               neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "        \n",
    "    print(\"\\nComputing Leiden clustering...\")\n",
    "    sc.tl.leiden(adata=adata,\n",
    "                 resolution=leiden_resolutions[i],\n",
    "                 key_added=f\"run{run_number}_leiden_{leiden_resolutions[i]}\",\n",
    "                 neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "    \n",
    "    niche_annotations = {\n",
    "        \"0\": \"Niche 1\",\n",
    "        \"1\": \"Niche 2\",\n",
    "        \"2\": \"Niche 3\",\n",
    "        \"3\": \"Niche 4\",        \n",
    "        \"4\": \"Niche 5\", \n",
    "        \"5\": \"Niche 6\", \n",
    "        \"6\": \"Niche 7\", \n",
    "        \"7\": \"Niche 8\"}\n",
    "\n",
    "    adata.obs[\"niche\"] = adata.obs[f\"run{run_number}_leiden_{leiden_resolutions[0]}\"].map(niche_annotations)\n",
    "\n",
    "    latent_cluster_colors = create_new_color_dict(\n",
    "        adata=adata,\n",
    "        cat_key=f\"run{run_number}_leiden_{leiden_resolutions[i]}\")\n",
    "    \n",
    "    niche_colors = {niche: latent_cluster_colors[cluster] for cluster, niche in niche_annotations.items()}\n",
    "    \n",
    "    plot_category_in_latent_and_physical_space(\n",
    "            adata=adata,\n",
    "            #figsize=(10, 20), for latent UMAP\n",
    "            plot_label=\"Latent Clusters\",\n",
    "            model_label={model},\n",
    "            cat_key=f\"niche\",\n",
    "            groups=None,\n",
    "            sample_key=\"sample\",\n",
    "            samples=[\"sample1\"], # =None for latent UMAP\n",
    "            cat_colors=niche_colors,\n",
    "            size=(720000 / len(adata)),\n",
    "            spot_size=30,\n",
    "            save_fig=True,\n",
    "            file_path=f\"{benchmarking_folder_path}/latent_clusters_{model}_{dataset}.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2a55bb-c6ff-4b62-b3e4-45067914bf44",
   "metadata": {},
   "source": [
    "#### 2.1.7 SDMBench Data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "93cf8b25-37f7-4104-b660-aade099bd2bd",
   "metadata": {},
   "source": [
    "# Load metrics\n",
    "datasets = [\"starmap_mouse_mpfc\"]\n",
    "models = [\"nichecompass_gatv2conv\",\n",
    "          \"nichecompass_gcnconv\",\n",
    "          \"staci\",\n",
    "          #\"deeplinc\",\n",
    "          \"graphst\",\n",
    "          \"cellcharter\",\n",
    "          \"banksy\"\n",
    "         ]\n",
    "\n",
    "summary_df = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    dataset_df = pd.DataFrame()\n",
    "    for model in models:\n",
    "        try:\n",
    "            benchmark_df = pd.read_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\")\n",
    "            #adata = sc.read_h5ad(f\"../../artifacts/single_sample_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "            #training_durations = []\n",
    "            #for run_number in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "            #    training_durations.append(adata.uns[f\"{model.split('_')[0]}_model_training_duration_run{run_number}\"])\n",
    "            #benchmark_df[\"run_time\"] = training_durations\n",
    "            #benchmark_df = benchmark_df[[\"dataset\", \"run_number\", \"run_time\", \"gcs\", \"mlami\", \"cas\", \"clisis\", \"nasw\", \"cnmi\", \"cari\", \"casw\", \"clisi\"]]\n",
    "            #benchmark_df.to_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\", index=False)\n",
    "            benchmark_df[\"model\"] = model\n",
    "            dataset_df = pd.concat([dataset_df, benchmark_df], ignore_index=True)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Did not find file {benchmarking_folder_path}/{dataset}_{model}_metrics.csv. Continuing...\")\n",
    "            missing_run_data = {\n",
    "                \"dataset\": [dataset] * 8,\n",
    "                \"model\": [model] * 8,\n",
    "                \"run_number\": [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "                \"run_time\": [np.nan] * 8\n",
    "            }\n",
    "            missing_run_df = pd.DataFrame(missing_run_data)\n",
    "            dataset_df = pd.concat([dataset_df, missing_run_df], ignore_index=True)\n",
    "            \n",
    "    # Apply min-max scaling to metric columns\n",
    "    for i in range(len(metric_cols_single_sample)):\n",
    "        min_val = dataset_df[metric_cols_single_sample[i]].min()\n",
    "        max_val = dataset_df[metric_cols_single_sample[i]].max()\n",
    "        dataset_df[metric_cols_single_sample[i] + \"_scaled\"] = ((\n",
    "            dataset_df[metric_cols_single_sample[i]] - min_val) / (max_val - min_val))\n",
    "        \n",
    "    for i in range(len(sdm_bench_metric_cols)):\n",
    "        min_val = dataset_df[sdm_bench_metric_cols[i]].min()\n",
    "        max_val = dataset_df[sdm_bench_metric_cols[i]].max()\n",
    "        dataset_df[sdm_bench_metric_cols[i] + \"_scaled\"] = ((\n",
    "            dataset_df[sdm_bench_metric_cols[i]] - min_val) / (max_val - min_val))\n",
    "\n",
    "    summary_df = pd.concat([summary_df, dataset_df], ignore_index=True)\n",
    "    continue\n",
    "    \n",
    "cat_0_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[0:2]]\n",
    "cat_1_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[2:4]]\n",
    "cat_2_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[4:6]]\n",
    "    \n",
    "summary_df[category_cols_single_sample[0]] = np.average(summary_df[cat_0_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[0:2],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_single_sample[1]] = np.average(summary_df[cat_1_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[2:4],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_single_sample[2]] = np.average(summary_df[cat_2_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[4:6],\n",
    "                                                        axis=1)\n",
    "summary_df[\"Overall Score\"] = np.average(summary_df[category_cols_single_sample[:3]],\n",
    "                                         weights=category_col_weights_single_sample[:3],\n",
    "                                         axis=1)\n",
    "summary_df[\"Ground Truth Prediction Score\"] = np.average(summary_df[sdm_bench_metric_cols],\n",
    "                                                         weights=sdm_bench_metric_col_weights,\n",
    "                                                         axis=1)\n",
    " \n",
    "# Reformat for plot\n",
    "summary_df.replace({\"nichecompass_gatv2conv\": \"NicheCompass\",\n",
    "                    \"nichecompass_gcnconv\": \"NicheCompass Light\",\n",
    "                    \"staci\": \"STACI\",\n",
    "                    \"deeplinc\": \"DeepLinc\",\n",
    "                    \"expimap\": \"expiMap\",\n",
    "                    \"graphst\": \"GraphST\",\n",
    "                    \"cellcharter\": \"CellCharter\",\n",
    "                    \"banksy\": \"BANKSY\"}, inplace=True)\n",
    "\n",
    "# Plot over all loss weights combinations\n",
    "# Prepare metrics table plot\n",
    "group_cols = [\"dataset\", \"model\"]\n",
    "aggregate_df = summary_df.groupby(group_cols).mean(\"Overall Score\").sort_values(\"Overall Score\", ascending=False)[\n",
    "    metric_cols_single_sample + [\"Overall Score\"] + sdm_bench_metric_cols + [\"Ground Truth Prediction Score\"]].reset_index()\n",
    "\n",
    "unrolled_df = pd.melt(\n",
    "    aggregate_df, \n",
    "    id_vars=group_cols,\n",
    "    value_vars=metric_cols_single_sample + [\"Overall Score\"] + sdm_bench_metric_cols + [\"Ground Truth Prediction Score\"],\n",
    "    var_name=\"score_type\", \n",
    "    value_name=\"score\")\n",
    "\n",
    "# Create spatial indicator column\n",
    "def is_spatially_aware_model(row):\n",
    "    if row[\"model\"] in [\"NicheCompass GCN\", \"NicheCompass GATv2\", \"DeepLinc\", \"GraphST\", \"CellCharter\"]:\n",
    "        return True\n",
    "    return False\n",
    "unrolled_df[\"spatially_aware\"] = unrolled_df.apply(lambda row: is_spatially_aware_model(row), axis=1)\n",
    "unrolled_df = unrolled_df[[\"dataset\", \"spatially_aware\", \"model\", \"score_type\", \"score\"]]\n",
    "\n",
    "# Order datasets\n",
    "unrolled_df[\"dataset\"] = pd.Categorical(unrolled_df[\"dataset\"], categories=datasets, ordered=True)\n",
    "unrolled_df = unrolled_df.sort_values(by=\"dataset\")\n",
    "\n",
    "#print(summary_df[\"model\"].value_counts())\n",
    "#print(summary_df[summary_df.isna().any(axis=1)])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4ce5816d-0a38-4b41-87f2-dbb1473b41d7",
   "metadata": {},
   "source": [
    "dataset = \"starmap_mouse_mpfc\"\n",
    "\n",
    "# Plot table\n",
    "plot_simple_metrics_table(\n",
    "    df=unrolled_df,\n",
    "    model_col=\"model\",\n",
    "    model_col_width=1.6,\n",
    "    group_col=\"dataset\",\n",
    "    metric_cols=metric_cols_single_sample, # metric_cols_single_sample, category_cols_single_sample\n",
    "    metric_col_weights=metric_col_weights_single_sample, # metric_col_weights_single_sample, category_col_weights_single_sample\n",
    "    metric_col_titles=[col.replace(\" \", \"\\n\") for col in metric_col_titles_single_sample], # category_col_titles_single_sample\n",
    "    metric_col_width=0.5, # 0.8,\n",
    "    aggregate_col_width=1.2,\n",
    "    plot_width=10, # 8.5, # 32,\n",
    "    plot_height=7,# 8,\n",
    "    show=True,\n",
    "    save_dir=benchmarking_folder_path,\n",
    "    save_name=f\"benchmarking_metrics_{dataset}.svg\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d66e256e-3d2c-4f39-8f0b-1db3aa8c09d7",
   "metadata": {},
   "source": [
    "dataset = \"starmap_mouse_mpfc\"\n",
    "\n",
    "# Plot table\n",
    "plot_simple_metrics_table(\n",
    "    df=unrolled_df,\n",
    "    model_col=\"model\",\n",
    "    model_col_width=1.6,\n",
    "    group_col=\"dataset\",\n",
    "    metric_cols=sdm_bench_metric_cols, # metric_cols_single_sample, category_cols_single_sample\n",
    "    metric_col_weights=sdm_bench_metric_col_weights, # metric_col_weights_single_sample, category_col_weights_single_sample\n",
    "    metric_col_titles=sdm_bench_metric_col_titles, # category_col_titles_single_sample\n",
    "    metric_col_width=0.5, # 0.8,\n",
    "    aggregate_col_width=1.2,\n",
    "    plot_width=6.5, # 8.5, # 32,\n",
    "    plot_height=7,# 8,\n",
    "    overall_score_col=\"Ground Truth Prediction Score\",\n",
    "    show=True,\n",
    "    save_dir=benchmarking_folder_path,\n",
    "    save_name=f\"benchmarking_metrics_ground_truth_{dataset}.svg\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1a282363-c61d-4a1b-a4b5-b8a1c13a6fba",
   "metadata": {},
   "source": [
    "dataset = \"starmap_mouse_mpfc\"\n",
    "\n",
    "adata = sc.read_h5ad(f\"{data_folder_path}/{dataset}.h5ad\")\n",
    "\n",
    "# Visualize niche types in UMAP PCA-reduced gene expression space\n",
    "niche_type_colors = create_new_color_dict(\n",
    "        adata=adata,\n",
    "        color_palette=\"default\",\n",
    "        cat_key=\"niche_type\")\n",
    "\n",
    "# Visualize niche types in tissue\n",
    "sc.pl.spatial(adata=adata,\n",
    "              color=\"niche_type\",                \n",
    "              palette=niche_type_colors,\n",
    "              spot_size=100,\n",
    "              show=False)\n",
    "plt.savefig(f\"{artifact_folder_path}/single_sample_method_benchmarking/{dataset}_niches.svg\", format=\"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71952d7b-d5d2-4367-bd65-0b51ded83dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metrics\n",
    "datasets = [\"stereoseq_mouse_embryo\"]\n",
    "models = [\"nichecompass_gatv2conv\",\n",
    "          \"nichecompass_gcnconv\",\n",
    "          #\"staci\",\n",
    "          #\"deeplinc\",\n",
    "          \"graphst\",\n",
    "          \"cellcharter\",\n",
    "          \"banksy\"\n",
    "         ]\n",
    "\n",
    "summary_df = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    dataset_df = pd.DataFrame()\n",
    "    for model in models:\n",
    "        try:\n",
    "            benchmark_df = pd.read_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\")\n",
    "            #adata = sc.read_h5ad(f\"../../artifacts/single_sample_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "            #training_durations = []\n",
    "            #for run_number in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "            #    training_durations.append(adata.uns[f\"{model.split('_')[0]}_model_training_duration_run{run_number}\"])\n",
    "            #benchmark_df[\"run_time\"] = training_durations\n",
    "            #benchmark_df = benchmark_df[[\"dataset\", \"run_number\", \"run_time\", \"gcs\", \"mlami\", \"cas\", \"clisis\", \"nasw\", \"cnmi\", \"cari\", \"casw\", \"clisi\"]]\n",
    "            #benchmark_df.to_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\", index=False)\n",
    "            benchmark_df[\"model\"] = model\n",
    "            dataset_df = pd.concat([dataset_df, benchmark_df], ignore_index=True)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Did not find file {benchmarking_folder_path}/{dataset}_{model}_metrics.csv. Continuing...\")\n",
    "            missing_run_data = {\n",
    "                \"dataset\": [dataset] * 8,\n",
    "                \"model\": [model] * 8,\n",
    "                \"run_number\": [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "                \"run_time\": [np.nan] * 8\n",
    "            }\n",
    "            missing_run_df = pd.DataFrame(missing_run_data)\n",
    "            dataset_df = pd.concat([dataset_df, missing_run_df], ignore_index=True)\n",
    "            \n",
    "    # Apply min-max scaling to metric columns\n",
    "    for i in range(len(metric_cols_single_sample)):\n",
    "        min_val = dataset_df[metric_cols_single_sample[i]].min()\n",
    "        max_val = dataset_df[metric_cols_single_sample[i]].max()\n",
    "        dataset_df[metric_cols_single_sample[i] + \"_scaled\"] = ((\n",
    "            dataset_df[metric_cols_single_sample[i]] - min_val) / (max_val - min_val))\n",
    "        \n",
    "    for i in range(len(sdm_bench_metric_cols)):\n",
    "        min_val = dataset_df[sdm_bench_metric_cols[i]].min()\n",
    "        max_val = dataset_df[sdm_bench_metric_cols[i]].max()\n",
    "        dataset_df[sdm_bench_metric_cols[i] + \"_scaled\"] = ((\n",
    "            dataset_df[sdm_bench_metric_cols[i]] - min_val) / (max_val - min_val))\n",
    "\n",
    "    summary_df = pd.concat([summary_df, dataset_df], ignore_index=True)\n",
    "    continue\n",
    "    \n",
    "cat_0_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[0:2]]\n",
    "cat_1_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[2:4]]\n",
    "cat_2_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_single_sample[4:6]]\n",
    "    \n",
    "summary_df[category_cols_single_sample[0]] = np.average(summary_df[cat_0_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[0:2],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_single_sample[1]] = np.average(summary_df[cat_1_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[2:4],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_single_sample[2]] = np.average(summary_df[cat_2_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_single_sample[4:6],\n",
    "                                                        axis=1)\n",
    "summary_df[\"Overall Score\"] = np.average(summary_df[category_cols_single_sample[:3]],\n",
    "                                         weights=category_col_weights_single_sample[:3],\n",
    "                                         axis=1)\n",
    "summary_df[\"Ground Truth Prediction Score\"] = np.average(summary_df[sdm_bench_metric_cols],\n",
    "                                                         weights=sdm_bench_metric_col_weights,\n",
    "                                                         axis=1)\n",
    " \n",
    "# Reformat for plot\n",
    "summary_df.replace({\"nichecompass_gatv2conv\": \"NicheCompass\",\n",
    "                    \"nichecompass_gcnconv\": \"NicheCompass Light\",\n",
    "                    \"staci\": \"STACI\",\n",
    "                    \"deeplinc\": \"DeepLinc\",\n",
    "                    \"expimap\": \"expiMap\",\n",
    "                    \"graphst\": \"GraphST\",\n",
    "                    \"cellcharter\": \"CellCharter\",\n",
    "                    \"banksy\": \"BANKSY\"}, inplace=True)\n",
    "\n",
    "# Plot over all loss weights combinations\n",
    "# Prepare metrics table plot\n",
    "group_cols = [\"dataset\", \"model\"]\n",
    "aggregate_df = summary_df.groupby(group_cols).mean(\"Overall Score\").sort_values(\"Overall Score\", ascending=False)[\n",
    "    metric_cols_single_sample + [\"Overall Score\"] + sdm_bench_metric_cols + [\"Ground Truth Prediction Score\"]].reset_index()\n",
    "\n",
    "unrolled_df = pd.melt(\n",
    "    aggregate_df, \n",
    "    id_vars=group_cols,\n",
    "    value_vars=metric_cols_single_sample + [\"Overall Score\"] + sdm_bench_metric_cols + [\"Ground Truth Prediction Score\"],\n",
    "    var_name=\"score_type\", \n",
    "    value_name=\"score\")\n",
    "\n",
    "# Create spatial indicator column\n",
    "def is_spatially_aware_model(row):\n",
    "    if row[\"model\"] in [\"NicheCompass GCN\", \"NicheCompass GATv2\", \"DeepLinc\", \"GraphST\", \"CellCharter\"]:\n",
    "        return True\n",
    "    return False\n",
    "unrolled_df[\"spatially_aware\"] = unrolled_df.apply(lambda row: is_spatially_aware_model(row), axis=1)\n",
    "unrolled_df = unrolled_df[[\"dataset\", \"spatially_aware\", \"model\", \"score_type\", \"score\"]]\n",
    "\n",
    "# Order datasets\n",
    "unrolled_df[\"dataset\"] = pd.Categorical(unrolled_df[\"dataset\"], categories=datasets, ordered=True)\n",
    "unrolled_df = unrolled_df.sort_values(by=\"dataset\")\n",
    "\n",
    "#print(summary_df[\"model\"].value_counts())\n",
    "#print(summary_df[summary_df.isna().any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d746985e-ddc5-4ab9-929f-911a758b8fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"stereoseq_mouse_embryo\"\n",
    "\n",
    "# Plot table\n",
    "plot_simple_metrics_table(\n",
    "    df=unrolled_df,\n",
    "    model_col=\"model\",\n",
    "    model_col_width=1.6,\n",
    "    group_col=\"dataset\",\n",
    "    metric_cols=metric_cols_single_sample, # metric_cols_single_sample, category_cols_single_sample\n",
    "    metric_col_weights=metric_col_weights_single_sample, # metric_col_weights_single_sample, category_col_weights_single_sample\n",
    "    metric_col_titles=[col.replace(\" \", \"\\n\") for col in metric_col_titles_single_sample], # category_col_titles_single_sample\n",
    "    metric_col_width=0.5, # 0.8,\n",
    "    aggregate_col_width=1.2,\n",
    "    plot_width=10, # 8.5, # 32,\n",
    "    plot_height=7,# 8,\n",
    "    show=True,\n",
    "    save_dir=benchmarking_folder_path,\n",
    "    save_name=f\"benchmarking_metrics_{dataset}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb30841-fd7f-40c5-a2f8-9626e7d7e29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"stereoseq_mouse_embryo\"\n",
    "\n",
    "# Plot table\n",
    "plot_simple_metrics_table(\n",
    "    df=unrolled_df,\n",
    "    model_col=\"model\",\n",
    "    model_col_width=1.6,\n",
    "    group_col=\"dataset\",\n",
    "    metric_cols=sdm_bench_metric_cols, # metric_cols_single_sample, category_cols_single_sample\n",
    "    metric_col_weights=sdm_bench_metric_col_weights, # metric_col_weights_single_sample, category_col_weights_single_sample\n",
    "    metric_col_titles=sdm_bench_metric_col_titles, # category_col_titles_single_sample\n",
    "    metric_col_width=0.5, # 0.8,\n",
    "    aggregate_col_width=1.2,\n",
    "    plot_width=8, # 8.5, # 32,\n",
    "    plot_height=7,# 8,\n",
    "    overall_score_col=\"Ground Truth Prediction Score\",\n",
    "    show=True,\n",
    "    save_dir=benchmarking_folder_path,\n",
    "    save_name=f\"benchmarking_metrics_ground_truth_{dataset}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3643855-683c-4c22-a159-3d826a9f9bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"stereoseq_mouse_embryo\"\n",
    "\n",
    "adata = sc.read_h5ad(f\"{data_folder_path}/{dataset}.h5ad\")\n",
    "\n",
    "# Visualize niche types in UMAP PCA-reduced gene expression space\n",
    "niche_type_colors = create_new_color_dict(\n",
    "        adata=adata,\n",
    "        color_palette=\"default\",\n",
    "        cat_key=\"niche_type\")\n",
    "\n",
    "# Visualize niche types in tissue\n",
    "sc.pl.spatial(adata=adata,\n",
    "              color=\"niche_type\",                \n",
    "              palette=niche_type_colors,\n",
    "              spot_size=1,\n",
    "              show=False)\n",
    "plt.savefig(f\"{artifact_folder_path}/single_sample_method_benchmarking/{dataset}_niches.svg\", format=\"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9671a4-9789-40ad-bc0a-88db8508bafd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
