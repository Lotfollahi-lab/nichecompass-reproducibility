{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BANKSY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Creator**: Anamika Yadav (anamika310.yadav@gmail.com)\n",
    "- **Date of Creation:** 12.07.2024\n",
    "- **Date of Last Modification:** 22.07.2024 (Sebastian Birk; <sebastian.birk@helmholtz-munich.de>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The Banksy source code is available at https://github.com/prabhakarlab/Banksy (R) and https://github.com/prabhakarlab/Banksy_py (Python).\n",
    "- The corresponding publication is \"Singhal, V. et al. BANKSY unifies cell typing and tissue domain segmentation for scalable spatial omics data analysis. Nat. Genet. (2024) doi:10.1038/s41588-024-01664-3\".\n",
    "- The workflow of this notebook follows the tutorial from https://github.com/prabhakarlab/Banksy_py/blob/main/slideseqv2_analysis.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this notebook in the nichecompass-reproducibility environment, installable from ```('../../../envs/environment.yaml')```. In addition, it is required to clone the Banksy_py repo from GitHub as follows:\n",
    "\n",
    "```cd analysis/benchmarking```\n",
    "\n",
    "```git clone https://github.com/prabhakarlab/Banksy_py.git```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../Banksy_py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Dask dataframe requirements are not installed.\n\nPlease either conda or pip install as follows:\n\n  conda install dask                     # either conda install\n  python -m pip install \"dask[dataframe]\" --upgrade  # or python -m pip install",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/nichecompass-reproducibility/lib/python3.9/site-packages/dask/dataframe/__init__.py:52\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backends, dispatch, methods, rolling\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_testing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m test_dataframe\n",
      "File \u001b[0;32m~/miniconda3/envs/nichecompass-reproducibility/lib/python3.9/site-packages/dask/dataframe/backends.py:14\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CreationDispatch, DaskBackendEntrypoint\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PANDAS_GE_220, is_any_real_numeric_dtype\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataFrame, Index, Scalar, Series, _Frame\n",
      "File \u001b[0;32m~/miniconda3/envs/nichecompass-reproducibility/lib/python3.9/site-packages/dask/dataframe/_compat.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compatibility\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m import_optional_dependency\n\u001b[0;32m----> 9\u001b[0m \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpandas\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/nichecompass-reproducibility/lib/python3.9/site-packages/dask/_compatibility.py:135\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, min_version, errors)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mImportError\u001b[0m: Dask requires version '2.0.0' or newer of 'pandas' (version '1.5.3' currently installed).",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscanpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msc\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msp\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msquidpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msq\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m f1_score\n",
      "File \u001b[0;32m~/miniconda3/envs/nichecompass-reproducibility/lib/python3.9/site-packages/squidpy/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metadata\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msquidpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datasets, gr, im, pl, read, tl\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      8\u001b[0m     md \u001b[38;5;241m=\u001b[39m metadata\u001b[38;5;241m.\u001b[39mmetadata(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/nichecompass-reproducibility/lib/python3.9/site-packages/squidpy/gr/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"The graph module.\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msquidpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_build\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m spatial_neighbors\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msquidpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ligrec\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ligrec\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msquidpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_nhood\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m centrality_scores, interaction_matrix, nhood_enrichment\n",
      "File \u001b[0;32m~/miniconda3/envs/nichecompass-reproducibility/lib/python3.9/site-packages/squidpy/gr/_build.py:25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity, euclidean_distances\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneighbors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NearestNeighbors\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspatialdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SpatialData\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msquidpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_constants\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_constants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CoordType, Transform\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msquidpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_constants\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pkg_constants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Key\n",
      "File \u001b[0;32m~/miniconda3/envs/nichecompass-reproducibility/lib/python3.9/site-packages/spatialdata/__init__.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\n\u001b[1;32m      5\u001b[0m dask\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mset({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataframe.query-planning\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m})\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdd\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Setting `dataframe.query-planning` to False is effective only if run before `dask.dataframe` is initialized. In\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# the case in which the user had initilized `dask.dataframe` before, we would have DASK_EXPER_ENABLED set to `True`.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Here we check that this does not happen.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(dd, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDASK_EXPR_ENABLED\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m dd\u001b[38;5;241m.\u001b[39mDASK_EXPR_ENABLED:\n",
      "File \u001b[0;32m~/miniconda3/envs/nichecompass-reproducibility/lib/python3.9/site-packages/dask/dataframe/__init__.py:122\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    116\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    117\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDask dataframe requirements are not installed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    118\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease either conda or pip install as follows:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    119\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  conda install dask                     # either conda install\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m  python -m pip install \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdask[dataframe]\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m --upgrade  # or python -m pip install\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    121\u001b[0m     )\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _dask_expr_enabled():\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mImportError\u001b[0m: Dask dataframe requirements are not installed.\n\nPlease either conda or pip install as follows:\n\n  conda install dask                     # either conda install\n  python -m pip install \"dask[dataframe]\" --upgrade  # or python -m pip install"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import anndata as ad\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scipy.sparse as sp\n",
    "import squidpy as sq\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from banksy.initialize_banksy import initialize_banksy\n",
    "from banksy_utils.load_data import load_adata, display_adata\n",
    "from banksy_utils.filter_utils import filter_cells, filter_hvg, normalize_total, print_max_min\n",
    "from banksy_utils.umap_pca import pca_umap\n",
    "from banksy.embed_banksy import generate_banksy_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"banksy\"\n",
    "latent_key = f\"{model_name}_latent\"\n",
    "lambda_list = [0.2]  # list of lambda parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Run Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.set_figure_params(figsize=(6, 6))\n",
    "now = datetime.now()\n",
    "current_timestamp = now.strftime(\"%d%m%Y_%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Configure Paths and Directories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_path = \"../../../datasets/st_data/gold/\"\n",
    "benchmarking_folder_path = \"../../../artifacts/single_sample_method_benchmarking\"\n",
    "figure_folder_path = f\"../../../figures\"\n",
    "# figure_folder_path = f\"../figures/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Banksy Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Define Training Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_banksy_models(dataset,\n",
    "                        cell_type_key,\n",
    "                        niche_type_key=None,\n",
    "                        adata_new=None,\n",
    "                        n_start_run=1,\n",
    "                        n_end_run=8,\n",
    "                        n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16],\n",
    "                        gp_inference=False):\n",
    "    # Configure figure folder path\n",
    "    dataset_figure_folder_path = f\"{figure_folder_path}/{dataset}/single_sample_method_benchmarking/\" \\\n",
    "                                 f\"{model_name}/{current_timestamp}\"\n",
    "    os.makedirs(dataset_figure_folder_path, exist_ok=True)\n",
    "\n",
    "    # Create new adata to store results from training runs in storage-efficient way\n",
    "    if adata_new is None:\n",
    "        adata_original = sc.read_h5ad(data_folder_path + f\"{dataset}.h5ad\")\n",
    "        adata_new = sc.AnnData(sp.csr_matrix(\n",
    "            (adata_original.shape[0], adata_original.shape[1]),\n",
    "            dtype=np.float32))\n",
    "        adata_new.var_names = adata_original.var_names\n",
    "        adata_new.obs_names = adata_original.obs_names\n",
    "        adata_new.obs[\"cell_type\"] = adata_original.obs[cell_type_key].values\n",
    "        if niche_type_key in adata_original.obs.columns:\n",
    "            adata_new.obs[\"niche_type\"] = adata_original.obs[niche_type_key].values\n",
    "        adata_new.obsm[\"spatial\"] = adata_original.obsm[\"spatial\"]\n",
    "        del(adata_original)\n",
    "\n",
    "    model_seeds = list(range(10))\n",
    "    for run_number, n_neighbors in zip(np.arange(n_start_run, n_end_run+1), n_neighbor_list):\n",
    "        # n_neighbors is here used for k_geom parameter in banksy method as well as the latent neighbor graph construction used for\n",
    "        # UMAP generation and clustering \n",
    "\n",
    "        # Load data\n",
    "        adata = sc.read_h5ad(data_folder_path + f\"{dataset}.h5ad\")\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Set default model hyperparams\n",
    "        max_m = 1 # use both mean and AFT\n",
    "        nbr_weight_decay = \"scaled_gaussian\" # can also choose \"reciprocal\", \"uniform\" or \"ranked\"\n",
    "        lambda_list = [0.8]\n",
    "        pca_dims = [20]\n",
    "        \n",
    "        # Define spatial coordinates\n",
    "        adata.obs[\"spatial_x\"] = adata.obsm['spatial'][:, 0]\n",
    "        adata.obs[\"spatial_y\"] = adata.obsm['spatial'][:, 1]\n",
    "\n",
    "        banksy_dict = initialize_banksy(\n",
    "            adata,\n",
    "            (\"spatial_x\", \"spatial_y\", \"spatial\"),\n",
    "            n_neighbors,\n",
    "            nbr_weight_decay=nbr_weight_decay,\n",
    "            max_m=max_m,\n",
    "            plt_edge_hist=False,\n",
    "            plt_nbr_weights=False,\n",
    "            plt_agf_angles=False, # takes long time to plot\n",
    "            plt_theta=False)\n",
    "\n",
    "        banksy_dict, banksy_matrix = generate_banksy_matrix(\n",
    "            adata,\n",
    "            banksy_dict,\n",
    "            lambda_list,\n",
    "            max_m)\n",
    "\n",
    "        pca_umap(\n",
    "            banksy_dict,\n",
    "            pca_dims = pca_dims,\n",
    "            add_umap = True,\n",
    "            plt_remaining_var = False)\n",
    "\n",
    "        adata.obsm[latent_key] = banksy_dict[nbr_weight_decay][lambda_list[0]][\"adata\"].obsm[\"reduced_pc_20\"]\n",
    "\n",
    "        # Measure time for model training\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        hours, rem = divmod(elapsed_time, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        print(f\"Duration of model training in run {run_number}: \"\n",
    "              f\"{int(hours)} hours, {int(minutes)} minutes and {int(seconds)} seconds.\")\n",
    "        adata_new.uns[f\"{model_name}_model_training_duration_run{run_number}\"] = (\n",
    "            elapsed_time)\n",
    "\n",
    "        # Store latent representation\n",
    "        adata_new.obsm[latent_key + f\"_run{run_number}\"] = adata.obsm[latent_key]\n",
    "\n",
    "        # Store intermediate adata to disk\n",
    "        if gp_inference:\n",
    "            adata_new.write(f\"{benchmarking_folder_path}/{dataset}_{model_name}_gpinference.h5ad\")\n",
    "        else:\n",
    "            adata_new.write(f\"{benchmarking_folder_path}/{dataset}_{model_name}.h5ad\")  \n",
    "\n",
    "    # Store final adata to disk\n",
    "    if gp_inference:\n",
    "        adata_new.write(f\"{benchmarking_folder_path}/{dataset}_{model_name}_gpinference.h5ad\")\n",
    "    else:\n",
    "        adata_new.write(f\"{benchmarking_folder_path}/{dataset}_{model_name}.h5ad\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Train Models on Benchmarking Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_banksy_models(dataset=\"seqfish_mouse_organogenesis_embryo2\",\n",
    "                    cell_type_key=\"celltype_mapped_refined\",\n",
    "                    adata_new=None,\n",
    "                    n_start_run=1,\n",
    "                    n_end_run=8,\n",
    "                    n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subsample_pct in [50, 25, 10, 5, 1]:\n",
    "    train_banksy_models(dataset=f\"seqfish_mouse_organogenesis_subsample_{subsample_pct}pct_embryo2\",\n",
    "                        cell_type_key=\"celltype_mapped_refined\",\n",
    "                        adata_new=None,\n",
    "                        n_start_run=1,\n",
    "                        n_end_run=8,\n",
    "                        n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_banksy_models(dataset=\"nanostring_cosmx_human_nsclc_batch5\",\n",
    "                    cell_type_key=\"cell_type\",\n",
    "                    adata_new=None,\n",
    "                    n_start_run=1,\n",
    "                    n_end_run=8,\n",
    "                    n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subsample_pct in [50, 25, 10, 5, 1]:\n",
    "    train_banksy_models(dataset=f\"nanostring_cosmx_human_nsclc_subsample_{subsample_pct}pct_batch5\",\n",
    "                        cell_type_key=\"cell_type\",\n",
    "                        adata_new=None,\n",
    "                        n_start_run=1,\n",
    "                        n_end_run=8,\n",
    "                        n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_banksy_models(dataset=\"vizgen_merfish_mouse_liver\",\n",
    "                    cell_type_key=\"Cell_Type\",\n",
    "                    adata_new=None,\n",
    "                    n_start_run=1,\n",
    "                    n_end_run=8,\n",
    "                    n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subsample_pct in [50, 25, 10, 5, 1]:\n",
    "    train_banksy_models(dataset=f\"vizgen_merfish_mouse_liver_subsample_{subsample_pct}pct\",\n",
    "                        cell_type_key=\"Cell_Type\",\n",
    "                        adata_new=None,\n",
    "                        n_start_run=1,\n",
    "                        n_end_run=8,\n",
    "                        n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_banksy_models(dataset=\"slideseqv2_mouse_hippocampus\",\n",
    "                    cell_type_key=\"cell_type\",\n",
    "                    adata_new=None,\n",
    "                    n_start_run=1,\n",
    "                    n_end_run=8,\n",
    "                    n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subsample_pct in [50, 25, 10, 5, 1]:\n",
    "    train_banksy_models(dataset=f\"slideseqv2_mouse_hippocampus_subsample_{subsample_pct}pct\",\n",
    "                        cell_type_key=\"cell_type\",\n",
    "                        adata_new=None,\n",
    "                        n_start_run=1,\n",
    "                        n_end_run=8,\n",
    "                        n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_banksy_models(dataset=\"sim1_1105genes_10000locs_strongincrements\",\n",
    "                    cell_type_key=\"cell_types\",\n",
    "                    niche_type_key=\"niche_types\",\n",
    "                    adata_new=None,\n",
    "                    n_start_run=1,\n",
    "                    n_end_run=8,\n",
    "                    n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_banksy_models(dataset=\"sim1_1105genes_10000locs_strongincrements\",\n",
    "                    cell_type_key=\"cell_types\",\n",
    "                    niche_type_key=\"niche_types\",\n",
    "                    adata_new=None,\n",
    "                    n_start_run=1,\n",
    "                    n_end_run=8,\n",
    "                    n_neighbor_list=[6, 6, 6, 6, 6, 6, 6, 6],\n",
    "                    gp_inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_banksy_models(dataset=\"starmap_mouse_mpfc\",\n",
    "                    cell_type_key=\"cell_type\",\n",
    "                    niche_type_key=\"niche_type\",\n",
    "                    adata_new=None,\n",
    "                    n_start_run=1,\n",
    "                    n_end_run=8,\n",
    "                    n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_banksy_models(dataset=\"stereoseq_mouse_embryo\",\n",
    "                    cell_type_key=\"leiden\",\n",
    "                    niche_type_key=\"niche_type\",\n",
    "                    adata_new=None,\n",
    "                    n_start_run=1,\n",
    "                    n_end_run=8,\n",
    "                    n_neighbor_list=[4, 4, 8, 8, 12, 12, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
