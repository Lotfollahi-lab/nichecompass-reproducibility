{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b1daabf-c8e3-43d4-aa32-9789abcc8619",
   "metadata": {},
   "source": [
    "# Sample Integration Method Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c325d921-2077-42b3-90a8-6f6c7dd928c5",
   "metadata": {},
   "source": [
    "- **Creator**: Sebastian Birk (<sebastian.birk@helmholtz-munich.de>)\n",
    "- **Date of Creation:** 20.01.2023\n",
    "- **Date of Last Modification:** 21.12.2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322fc2f5-5312-458b-8fd3-4773bb3f214d",
   "metadata": {},
   "source": [
    "Run this notebook in the nichecompass-reproducibility environment, installable from ```('../../../envs/environment.yaml')```. Before running this notebook, compute the sample integration method benchmarking metrics by triggering the\n",
    "respective jobs (under **Sample Integration Method Benchmarking** header) in ```('../../slurm_job_submission.ipynb')```.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d464ebf-354f-4f61-8040-c3dcbcc893b9",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5631277-d8d2-4194-a376-280f4f149b7d",
   "metadata": {},
   "source": [
    "### 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5d3297-0290-47c0-846f-705e74cdb3de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbd4925-7505-4d01-bf91-95b54bb8b533",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../../utils\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2de203a-d8f2-473f-8b0b-b5acb634d7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "import warnings\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "\n",
    "import anndata as ad\n",
    "#import cellcharter as cc\n",
    "import matplotlib\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plottable\n",
    "import scanpy as sc\n",
    "import scipy.sparse as sp\n",
    "#import scvi\n",
    "import seaborn as sns\n",
    "import squidpy as sq\n",
    "import torch\n",
    "#from GraphST import GraphST\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.pyplot import rc_context\n",
    "from plottable import ColumnDefinition, Table\n",
    "from plottable.cmap import normed_cmap\n",
    "from plottable.formatters import tickcross\n",
    "from plottable.plots import bar\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from nichecompass.benchmarking import compute_benchmarking_metrics\n",
    "from nichecompass.models import NicheCompass\n",
    "\n",
    "from benchmarking_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f91f345-c297-47cb-8650-c6d9c60a8b7e",
   "metadata": {},
   "source": [
    "### 1.2 Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94479b3-266f-410e-9604-a96b6269f695",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_cols_sample_integration = [\n",
    "    \"cas\", \"mlami\", # global spatial consistency\n",
    "    \"clisis\", \"gcs\", # local spatial consistency\n",
    "    \"nasw\", \"cnmi\", # niche coherence\n",
    "    \"blisi\", \"pcr\" # batch correction\n",
    "]\n",
    "metric_col_weights_sample_integration = [ # separate for each category (later multiplied with category_col_weights)\n",
    "    (1/2), (1/2), # global spatial consistency\n",
    "    (1/2), (1/2), # local spatial consistency\n",
    "    1, 1, # niche coherence\n",
    "    1, 1, # batch correction\n",
    "]\n",
    "metric_col_titles_sample_integration = [\n",
    "    \"CAS\", # \"Cell Type Affinity Similarity\",\n",
    "    \"MLAMI\", # \"Maximum Leiden Adjusted Mutual Info\",\n",
    "    \"CLISIS\", # \"Cell Type Local Inverse Simpson's Index Similarity\",\n",
    "    \"GCS\", # \"Graph Connectivity Similarity\",\n",
    "    \"NASW\", # \"Niche Average Silhouette Width\",\n",
    "    \"CNMI\", # \"Cell Type Normalized Mutual Info\",\n",
    "    \"BLISI\", # \"Batch Local Inverse Simpson's Index\"\n",
    "    \"PCR\" # \"Principal Component Regression\"\n",
    "]\n",
    "metric_cols_single_sample = metric_cols_sample_integration[:-3]\n",
    "metric_col_weights_single_sample = metric_col_weights_sample_integration[:-3]\n",
    "metric_col_titles_single_sample = metric_col_titles_sample_integration[:-3]\n",
    "\n",
    "category_cols_sample_integration = [\n",
    "    \"Global Spatial Consistency Score\",\n",
    "    \"Local Spatial Consistency Score\",\n",
    "    \"Niche Coherence Score\",\n",
    "    \"Batch Correction Score\"]\n",
    "category_col_weights_sample_integration = [\n",
    "    1,\n",
    "    1,\n",
    "    2,\n",
    "    2]\n",
    "category_col_titles_sample_integration = [\n",
    "    \"Global Spatial Consistency Score\",\n",
    "    \"Local Spatial Consistency Score\",\n",
    "    \"Niche Coherence Score\",\n",
    "    \"Batch Correction Score\"]\n",
    "category_col_weights_single_sample = category_col_weights_sample_integration[:-1]\n",
    "category_cols_single_sample = category_cols_sample_integration[:-1]\n",
    "category_col_titles_single_sample = [\n",
    "    \"Global Spatial Consistency Score\",\n",
    "    \"Local Spatial Consistency Score\",\n",
    "    \"Niche Coherence Score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c3b7fa-fa59-43dd-81d2-7e116650915f",
   "metadata": {},
   "source": [
    "### 1.3 Run Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37685c2a-9a44-4de7-a7ca-5f7d23ef62b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sc.set_figure_params(figsize=(6, 6))\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924032d4-24a4-45cf-87e1-0eba197da0c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ignore future warnings and user warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8c0867-04a3-4f95-a806-9d5c2fed3b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.family'] = 'Helvetica'\n",
    "plt.rcParams['font.size'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab22fbaf-aeed-464b-8a20-b640b9e055fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get time of notebook execution for timestamping saved artifacts\n",
    "now = datetime.now()\n",
    "current_timestamp = now.strftime(\"%d%m%Y_%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b886225-6b6d-433c-b117-47b9a8f8091f",
   "metadata": {},
   "source": [
    "### 1.4 Configure Paths and Create Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36675337-808d-40a9-93fc-d6cfa9473f66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_folder_path = \"../../../datasets/st_data/gold\"\n",
    "artifact_folder_path = f\"../../../artifacts\"\n",
    "benchmarking_folder_path = f\"{artifact_folder_path}/sample_integration_method_benchmarking\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c57f4e-804c-4f52-aaaa-0c9013ecf0b9",
   "metadata": {},
   "source": [
    "## 2. Method Benchmarking Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6865fa-b859-428c-afd1-85596aac1cf8",
   "metadata": {},
   "source": [
    "- Run all model notebooks in this directory (```./```) before continuing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1826a2b4-931a-49a5-9ecf-5009499fa9ce",
   "metadata": {},
   "source": [
    "### 2.1 Retrieve NicheCompass Runs & Fix Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f375b54-edbf-46d2-bedf-af326f4b8cfe",
   "metadata": {},
   "source": [
    "#### 2.1.1 seqFISH Mouse Organogenesis"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8c50f6fe-aadc-4732-96f6-764bd3ee89c0",
   "metadata": {},
   "source": [
    "# Store NicheCompass GCN encoder results in benchmarking folder\n",
    "task = \"sample_integration_method_benchmarking\"\n",
    "conv_layer_encoder = \"gcnconv\"\n",
    "datasets = [\n",
    "    \"seqfish_mouse_organogenesis\",\n",
    "    \"seqfish_mouse_organogenesis_subsample_50pct\",\n",
    "    \"seqfish_mouse_organogenesis_subsample_25pct\",\n",
    "    \"seqfish_mouse_organogenesis_subsample_10pct\",\n",
    "    \"seqfish_mouse_organogenesis_subsample_5pct\",\n",
    "    \"seqfish_mouse_organogenesis_subsample_1pct\",\n",
    "]\n",
    "timestamps = [\n",
    "    \"22082023_135318_1\",\n",
    "    \"22082023_143133_1\",\n",
    "    \"22082023_143133_1\",\n",
    "    \"22082023_150526_1\",\n",
    "    \"22082023_151248_1\",\n",
    "    \"22082023_152633_1\",\n",
    "]\n",
    "\n",
    "for dataset, timestamp in zip(datasets, timestamps):\n",
    "    source_path = f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_{task}/{timestamp}/{dataset}_{conv_layer_encoder}_{task}.h5ad\"\n",
    "    destination_path = f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\"\n",
    "    shutil.copy(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8697406f-1ed9-45b3-8a2c-a3c5254ec93a",
   "metadata": {},
   "source": [
    "# Store NicheCompass GATv2 encoder results in benchmarking folder\n",
    "task = \"sample_integration_method_benchmarking\"\n",
    "conv_layer_encoder = \"gatv2conv\"\n",
    "datasets = [\n",
    "    \"seqfish_mouse_organogenesis\",\n",
    "    \"seqfish_mouse_organogenesis_subsample_50pct\",\n",
    "    \"seqfish_mouse_organogenesis_subsample_25pct\",\n",
    "    \"seqfish_mouse_organogenesis_subsample_10pct\",\n",
    "    \"seqfish_mouse_organogenesis_subsample_5pct\",\n",
    "    \"seqfish_mouse_organogenesis_subsample_1pct\",\n",
    "]\n",
    "timestamps = [\n",
    "    \"22082023_184821_1\",\n",
    "    \"26082023_174438_1\",\n",
    "    \"22082023_190828_1\",\n",
    "    \"22082023_170833_1\",\n",
    "    \"22082023_190833_1\",\n",
    "    \"22082023_190826_1\",\n",
    "]\n",
    "\n",
    "for dataset, timestamp in zip(datasets, timestamps):\n",
    "    source_path = f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_{task}/{timestamp}/{dataset}_{conv_layer_encoder}_{task}.h5ad\"\n",
    "    destination_path = f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\"\n",
    "    shutil.copy(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b76263a-62aa-4d86-8dfe-87a176193a24",
   "metadata": {},
   "source": [
    "#### 2.1.2 seqFISH Mouse Organogenesis Imputed"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bb7ddead-e77c-414e-93fe-ef2292b79f27",
   "metadata": {},
   "source": [
    "# Store NicheCompass GCN encoder results in benchmarking folder\n",
    "task = \"sample_integration_method_benchmarking\"\n",
    "conv_layer_encoder = \"gcnconv\"\n",
    "datasets = [\n",
    "    \"seqfish_mouse_organogenesis_imputed\",\n",
    "    \"seqfish_mouse_organogenesis_imputed_subsample_50pct\",\n",
    "    \"seqfish_mouse_organogenesis_imputed_subsample_25pct\",\n",
    "    \"seqfish_mouse_organogenesis_imputed_subsample_10pct\",\n",
    "    \"seqfish_mouse_organogenesis_imputed_subsample_5pct\",\n",
    "    \"seqfish_mouse_organogenesis_imputed_subsample_1pct\",\n",
    "]\n",
    "timestamps = [\n",
    "    \"28082023_170521_2\",\n",
    "    \"28082023_172642_1\",\n",
    "    \"26082023_183656_1\",\n",
    "    \"26082023_183700_1\",\n",
    "    \"28082023_173046_1\",\n",
    "    \"28082023_172747_1\",\n",
    "]\n",
    "\n",
    "for dataset, timestamp in zip(datasets, timestamps):\n",
    "    source_path = f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_{task}/{timestamp}/{dataset}_{conv_layer_encoder}_{task}.h5ad\"\n",
    "    destination_path = f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\"\n",
    "    shutil.copy(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "678e3b7d-3d8f-4261-ab9d-88fc02bd0826",
   "metadata": {},
   "source": [
    "# Store NicheCompass GATv2 encoder results in benchmarking folder\n",
    "task = \"sample_integration_method_benchmarking\"\n",
    "conv_layer_encoder = \"gatv2conv\"\n",
    "datasets = [\n",
    "    \"seqfish_mouse_organogenesis_imputed\",\n",
    "    \"seqfish_mouse_organogenesis_imputed_subsample_50pct\",\n",
    "    \"seqfish_mouse_organogenesis_imputed_subsample_25pct\",\n",
    "    \"seqfish_mouse_organogenesis_imputed_subsample_10pct\",\n",
    "    \"seqfish_mouse_organogenesis_imputed_subsample_5pct\",\n",
    "    \"seqfish_mouse_organogenesis_imputed_subsample_1pct\",\n",
    "]\n",
    "timestamps = [\n",
    "    \"28082023_181323_1\",\n",
    "    \"28082023_114632_1\",\n",
    "    \"26082023_185008_1\",\n",
    "    \"26082023_185205_1\",\n",
    "    \"26082023_185553_1\",\n",
    "    \"26082023_185603_1\",\n",
    "]\n",
    "\n",
    "for dataset, timestamp in zip(datasets, timestamps):\n",
    "    source_path = f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_{task}/{timestamp}/{dataset}_{conv_layer_encoder}_{task}.h5ad\"\n",
    "    destination_path = f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\"\n",
    "    shutil.copy(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dc16a81e-03c5-474d-9342-6ced24174f3c",
   "metadata": {},
   "source": [
    "# Add missing runs for 'seqfish_mouse_organogenesis_imputed'\n",
    "dataset = \"seqfish_mouse_organogenesis_imputed\"\n",
    "conv_layer_encoder = \"gatv2conv\"\n",
    "timestamp = \"28082023_180418_1\"\n",
    "\n",
    "adata1 = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [3, 4]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"28082023_093539_1\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [5]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"28082023_113514_1\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [7]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"28082023_113455_1\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [8]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "adata1.write(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d162f95c-9641-4a8d-adc6-027fab106bc4",
   "metadata": {},
   "source": [
    "# Add missing runs for 'seqfish_mouse_organogenesis_imputed_subsample_50pct'\n",
    "dataset = \"seqfish_mouse_organogenesis_imputed_subsample_50pct\"\n",
    "conv_layer_encoder = \"gatv2conv\"\n",
    "timestamp = \"28082023_093921_1\"\n",
    "\n",
    "adata1 = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [5, 6]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"28082023_113855_1\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [7, 8]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "\n",
    "adata1.write(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399821d6-1312-41e5-bb95-b99a312147f2",
   "metadata": {},
   "source": [
    "#### 2.1.3 nanoString CosMx SMI Human Non-Small-Cell Lung Cancer (NSCLC)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c85e5603-3fc4-418d-9e12-2741fe1f5571",
   "metadata": {},
   "source": [
    "# Store NicheCompass GCN encoder W/O FoV embedding results in benchmarking folder\n",
    "task = \"sample_integration_method_benchmarking\"\n",
    "conv_layer_encoder = \"gcnconv\"\n",
    "datasets = [\n",
    "    #\"nanostring_cosmx_human_nsclc\",\n",
    "    #\"nanostring_cosmx_human_nsclc_subsample_50pct\",\n",
    "    #\"nanostring_cosmx_human_nsclc_subsample_25pct\",\n",
    "    #\"nanostring_cosmx_human_nsclc_subsample_10pct\",\n",
    "    #\"nanostring_cosmx_human_nsclc_subsample_5pct\",\n",
    "    #\"nanostring_cosmx_human_nsclc_subsample_1pct\",\n",
    "]\n",
    "timestamps = [\n",
    "    #\"21082023_162330_1\",\n",
    "    #\"21082023_205148_1\",\n",
    "    #\"22082023_084950_1\",\n",
    "    #\"22082023_093531_1\",\n",
    "    #\"22082023_093728_1\",\n",
    "    #\"22082023_093729_1\",\n",
    "]\n",
    "\n",
    "for dataset, timestamp in zip(datasets, timestamps):\n",
    "    source_path = f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_{task}/{timestamp}/{dataset}_{conv_layer_encoder}_{task}.h5ad\"\n",
    "    destination_path = f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\"\n",
    "    shutil.copy(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d8aed4ff-6379-41f4-bd84-520e5fe2358e",
   "metadata": {},
   "source": [
    "# Add missing runs for 'nanostring_cosmx_human_nsclc'\n",
    "dataset = \"nanostring_cosmx_human_nsclc\"\n",
    "conv_layer_encoder = \"gcnconv\"\n",
    "timestamp = \"21082023_162250_1\"\n",
    "\n",
    "adata1 = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [3, 4]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"22082023_010227_1\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [5]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"21082023_163844_1\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [6]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"21082023_162134_1\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [7]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"21082023_155619_1\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [8]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "adata1.write(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "05fe0051-23f1-4359-813d-eb5b98972c54",
   "metadata": {},
   "source": [
    "# Add missing runs for 'nanostring_cosmx_human_nsclc_subsample_50pct'\n",
    "dataset = \"nanostring_cosmx_human_nsclc_subsample_50pct\"\n",
    "conv_layer_encoder = \"gcnconv\"\n",
    "timestamp = \"21082023_204746_1\"\n",
    "\n",
    "adata1 = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [5, 6]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"22082023_084437_1\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [7]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"22082023_084415_1\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [8]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "    \n",
    "adata1.write(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "39606448-1886-48dc-89e0-602270edd42d",
   "metadata": {},
   "source": [
    "# Store NicheCompass GCN encoder with fov embedding results in benchmarking folder\n",
    "task = \"sample_integration_method_benchmarking\"\n",
    "conv_layer_encoder = \"gcnconv\"\n",
    "datasets = [\n",
    "    \"nanostring_cosmx_human_nsclc\",\n",
    "    \"nanostring_cosmx_human_nsclc_subsample_50pct\",\n",
    "    \"nanostring_cosmx_human_nsclc_subsample_25pct\",\n",
    "    \"nanostring_cosmx_human_nsclc_subsample_10pct\",\n",
    "    \"nanostring_cosmx_human_nsclc_subsample_5pct\",\n",
    "    \"nanostring_cosmx_human_nsclc_subsample_1pct\",\n",
    "]\n",
    "timestamps = [\n",
    "    \"23082023_095435_6\",\n",
    "    \"23082023_101310_1\",\n",
    "    \"23082023_101623_1\",\n",
    "    \"23082023_135406_1\",\n",
    "    \"23082023_125018_1\",\n",
    "    \"23082023_153002_1\",\n",
    "]\n",
    "\n",
    "for dataset, timestamp in zip(datasets, timestamps):\n",
    "    source_path = f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_{task}/{timestamp}/{dataset}_{conv_layer_encoder}_{task}.h5ad\"\n",
    "    destination_path = f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}_fov.h5ad\"\n",
    "    shutil.copy(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "10e278c6-1a28-443e-a1d7-a4dc268a4867",
   "metadata": {},
   "source": [
    "# Add missing runs for 'nanostring_cosmx_human_nsclc'\n",
    "dataset = \"nanostring_cosmx_human_nsclc\"\n",
    "conv_layer_encoder = \"gcnconv\"\n",
    "timestamp = \"23082023_095432_5\"\n",
    "\n",
    "adata1 = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}_fov.h5ad\")\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [3, 4]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"23082023_193617_4\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [5]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"23082023_095348_3\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [6]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"23082023_095317_2\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [7]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"25082023_205342_1\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [8]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "adata1.write(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}_fov.h5ad\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb8819f8-c432-49e7-ba65-09b5fe6d1c65",
   "metadata": {},
   "source": [
    "# Add missing runs for 'nanostring_cosmx_human_nsclc_subsample_50pct'\n",
    "dataset = \"nanostring_cosmx_human_nsclc_subsample_50pct\"\n",
    "conv_layer_encoder = \"gcnconv\"\n",
    "timestamp = \"25082023_132005_4\"\n",
    "\n",
    "adata1 = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}_fov.h5ad\")\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [5]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"23082023_101302_3\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [6]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"23082023_101234_2\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [7]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"25082023_131741_1\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [8]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "adata1.write(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}_fov.h5ad\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f36fb42f-9d44-459b-926a-7ff7962fd2b3",
   "metadata": {},
   "source": [
    "# Store NicheCompass GCN encoder with contrastive loss results in benchmarking folder\n",
    "task = \"sample_integration_method_benchmarking\"\n",
    "conv_layer_encoder = \"gcnconv\"\n",
    "datasets = [\n",
    "    #\"nanostring_cosmx_human_nsclc\",\n",
    "    #\"nanostring_cosmx_human_nsclc_subsample_50pct\",\n",
    "    #\"nanostring_cosmx_human_nsclc_subsample_25pct\",\n",
    "    #\"nanostring_cosmx_human_nsclc_subsample_10pct\",\n",
    "    #\"nanostring_cosmx_human_nsclc_subsample_5pct\",\n",
    "    #\"nanostring_cosmx_human_nsclc_subsample_1pct\",\n",
    "]\n",
    "timestamps = [\n",
    "    #\"02092023_195625_6\",\n",
    "    #\"02092023_215804_5\",\n",
    "    #\"02092023_215804_1\",\n",
    "    #\"02092023_221650_1\",\n",
    "    #\"02092023_222739_1\",\n",
    "    #\"02092023_232258_1\",\n",
    "]\n",
    "\n",
    "for dataset, timestamp in zip(datasets, timestamps):\n",
    "    source_path = f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_{task}/{timestamp}/{dataset}_{conv_layer_encoder}_{task}.h5ad\"\n",
    "    destination_path = f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}_cont.h5ad\"\n",
    "    shutil.copy(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "feb1cc8a-4e45-42ad-b7d6-5fa5cb93ee4a",
   "metadata": {},
   "source": [
    "# Add missing runs for 'nanostring_cosmx_human_nsclc'\n",
    "dataset = \"nanostring_cosmx_human_nsclc\"\n",
    "conv_layer_encoder = \"gcnconv\"\n",
    "timestamp = \"02092023_193219_5\"\n",
    "\n",
    "adata1 = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}_cont.h5ad\")\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [3, 4]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"02092023_192940_4\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [5]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"02092023_192905_3\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [6]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"03092023_114655_2\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [7]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"03092023_114631_1\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [8]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "adata1.write(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}_cont.h5ad\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "079996f7-c028-425f-8b10-56bae6e9b68c",
   "metadata": {},
   "source": [
    "# Add missing runs for 'nanostring_cosmx_human_nsclc_subsample_50pct'\n",
    "dataset = \"nanostring_cosmx_human_nsclc_subsample_50pct\"\n",
    "conv_layer_encoder = \"gcnconv\"\n",
    "timestamp = \"02092023_200431_4\"\n",
    "\n",
    "adata1 = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}_cont.h5ad\")\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [5]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"02092023_200431_3\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [6]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"02092023_195714_2\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [7]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"02092023_195702_1\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [8]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "\n",
    "adata1.write(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}_cont.h5ad\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0a1f9c9a-6431-424a-a437-0d70129cc837",
   "metadata": {},
   "source": [
    "# Store NicheCompass GATv2 W/O FoV embedding results encoder results in benchmarking folder\n",
    "task = \"sample_integration_method_benchmarking\"\n",
    "conv_layer_encoder = \"gatv2conv\"\n",
    "datasets = [\n",
    "    \"nanostring_cosmx_human_nsclc\",\n",
    "    \"nanostring_cosmx_human_nsclc_subsample_50pct\",\n",
    "    \"nanostring_cosmx_human_nsclc_subsample_25pct\",\n",
    "    \"nanostring_cosmx_human_nsclc_subsample_10pct\",\n",
    "    \"nanostring_cosmx_human_nsclc_subsample_5pct\",\n",
    "    \"nanostring_cosmx_human_nsclc_subsample_1pct\",\n",
    "]\n",
    "timestamps = [\n",
    "    \"21082023_190305_1\",\n",
    "    \"21082023_224326_1\",\n",
    "    \"22082023_111356_1\",\n",
    "    \"24082023_153432_1\",\n",
    "    \"22082023_114536_1\",\n",
    "    \"22082023_120631_1\",\n",
    "]\n",
    "\n",
    "for dataset, timestamp in zip(datasets, timestamps):\n",
    "    source_path = f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_{task}/{timestamp}/{dataset}_{conv_layer_encoder}_{task}.h5ad\"\n",
    "    destination_path = f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\"\n",
    "    shutil.copy(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "85ce1a35-7ebd-4017-940f-ac9a03802caa",
   "metadata": {},
   "source": [
    "# Add missing runs for 'nanostring_cosmx_human_nsclc'\n",
    "dataset = \"nanostring_cosmx_human_nsclc\"\n",
    "conv_layer_encoder = \"gatv2conv\"\n",
    "timestamp = \"23082023_210226_5\"\n",
    "\n",
    "adata1 = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [3]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"25082023_125946_1\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [4]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"22082023_084011_1\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [5, 6]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"25082023_125941_1\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [7]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"21082023_155707_1\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [8]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "adata1.write(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4ea805f5-c14b-4333-89d6-ce24ac8143c4",
   "metadata": {},
   "source": [
    "# Add missing runs for 'nanostring_cosmx_human_nsclc_subsample_50pct'\n",
    "dataset = \"nanostring_cosmx_human_nsclc_subsample_50pct\"\n",
    "conv_layer_encoder = \"gatv2conv\"\n",
    "timestamp = \"23082023_153223_1\"\n",
    "\n",
    "adata1 = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [5]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"26082023_181316_1\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [6]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"22082023_102158_1\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [7]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"22082023_094944_1\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [8]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "adata1.write(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d85aedb6-cd22-46be-903a-cfedf3a8341d",
   "metadata": {},
   "source": [
    "# Add missing runs for 'nanostring_cosmx_human_nsclc_subsample_10pct'\n",
    "dataset = \"nanostring_cosmx_human_nsclc_subsample_10pct\"\n",
    "conv_layer_encoder = \"gatv2conv\"\n",
    "timestamp = \"22082023_001247_1\"\n",
    "\n",
    "adata1 = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [5, 6, 7, 8]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "adata1.write(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "502e6d65-16cb-4477-9762-7166732e0c4b",
   "metadata": {},
   "source": [
    "# Store NicheCompass GATv2 encoder with fov embedding results in benchmarking folder\n",
    "task = \"sample_integration_method_benchmarking\"\n",
    "conv_layer_encoder = \"gatv2conv\"\n",
    "datasets = [\n",
    "    #\"nanostring_cosmx_human_nsclc\",\n",
    "    #\"nanostring_cosmx_human_nsclc_subsample_50pct\",\n",
    "    #\"nanostring_cosmx_human_nsclc_subsample_25pct\",\n",
    "    #\"nanostring_cosmx_human_nsclc_subsample_10pct\",\n",
    "    #\"nanostring_cosmx_human_nsclc_subsample_5pct\",\n",
    "    #\"nanostring_cosmx_human_nsclc_subsample_1pct\",\n",
    "]\n",
    "timestamps = [\n",
    "    #\"23082023_210907_6\",\n",
    "    #\"23082023_230006_5\",\n",
    "    #\"26082023_144745_1\",\n",
    "    #\"26082023_191240_1\",\n",
    "    #\"26082023_145405_1\",\n",
    "    #\"24082023_153225_1\",\n",
    "]\n",
    "\n",
    "for dataset, timestamp in zip(datasets, timestamps):\n",
    "    source_path = f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_{task}/{timestamp}/{dataset}_{conv_layer_encoder}_{task}.h5ad\"\n",
    "    destination_path = f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}_fov.h5ad\"\n",
    "    shutil.copy(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6db6f49a-02b3-4cba-b70a-4d7b4ad871b8",
   "metadata": {},
   "source": [
    "# Add missing runs for 'nanostring_cosmx_human_nsclc'\n",
    "dataset = \"nanostring_cosmx_human_nsclc\"\n",
    "conv_layer_encoder = \"gatv2conv\"\n",
    "timestamp = \"23082023_210226_5\"\n",
    "\n",
    "adata1 = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}_fov.h5ad\")\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [3, 4]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"23082023_205331_4\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [5]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"23082023_205333_3\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [6]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"25082023_205342_2\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [7]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"23082023_205101_1\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [8]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "adata1.write(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}_fov.h5ad\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c0ea3cf6-d5d5-49a6-831e-c764564a69bb",
   "metadata": {},
   "source": [
    "# Add missing runs for 'nanostring_cosmx_human_nsclc_subsample_50pct'\n",
    "dataset = \"nanostring_cosmx_human_nsclc_subsample_50pct\"\n",
    "conv_layer_encoder = \"gatv2conv\"\n",
    "timestamp = \"23082023_224509_4\"\n",
    "\n",
    "adata1 = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}_fov.h5ad\")\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [5]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"23082023_214330_3\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [6]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"26082023_180952_2\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [7]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"23082023_213804_1\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [8]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "adata1.write(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}_fov.h5ad\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3f13bd00-940b-4d2e-8dd2-b8e3bf8b0ced",
   "metadata": {},
   "source": [
    "# Add missing runs for 'nanostring_cosmx_human_nsclc_subsample_25pct'\n",
    "dataset = \"nanostring_cosmx_human_nsclc_subsample_25pct\"\n",
    "conv_layer_encoder = \"gatv2conv\"\n",
    "timestamp = \"28082023_152329_1\"\n",
    "\n",
    "adata1 = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}_fov.h5ad\")\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [3]: # still running\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"24082023_153217_1\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [4, 5, 6, 7, 8]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "adata1.write(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}_fov.h5ad\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6395d98e-555f-4392-aa42-a76e23b83445",
   "metadata": {},
   "source": [
    "# Store NicheCompass GATv2 encoder with contrastive loss results in benchmarking folder\n",
    "task = \"sample_integration_method_benchmarking\"\n",
    "conv_layer_encoder = \"gatv2conv\"\n",
    "datasets = [\n",
    "    #\"nanostring_cosmx_human_nsclc\",\n",
    "    #\"nanostring_cosmx_human_nsclc_subsample_50pct\",\n",
    "    \"nanostring_cosmx_human_nsclc_subsample_25pct\",\n",
    "    #\"nanostring_cosmx_human_nsclc_subsample_10pct\",\n",
    "    #\"nanostring_cosmx_human_nsclc_subsample_5pct\",\n",
    "    #\"nanostring_cosmx_human_nsclc_subsample_1pct\",\n",
    "]\n",
    "timestamps = [\n",
    "    #\"30082023_174502_6\",\n",
    "    #\"30082023_183405_5\",\n",
    "    \"04092023_094021_2\",\n",
    "    #\"02092023_171351_1\",\n",
    "    #\"03092023_120506_1\",\n",
    "    #\"30082023_192351_1\",\n",
    "]\n",
    "\n",
    "for dataset, timestamp in zip(datasets, timestamps):\n",
    "    source_path = f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_{task}/{timestamp}/{dataset}_{conv_layer_encoder}_{task}.h5ad\"\n",
    "    destination_path = f\"{artifact_folder_path}/{task}/{dataset}_nichecompass_{conv_layer_encoder}_cont.h5ad\"\n",
    "    shutil.copy(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a1390c3b-8870-45cc-976e-bb0cbe6f3908",
   "metadata": {},
   "source": [
    "# Add missing runs for 'nanostring_cosmx_human_nsclc'\n",
    "dataset = \"nanostring_cosmx_human_nsclc\"\n",
    "conv_layer_encoder = \"gatv2conv\"\n",
    "timestamp = \"01092023_095132_5\"\n",
    "\n",
    "adata1 = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}_cont.h5ad\")\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [3]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"30082023_173911_5\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [4]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"30082023_173911_4\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [5]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"30082023_173911_3\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [6]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"30082023_173911_2\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [7]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"30082023_173911_1\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [8]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "adata1.write(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}_cont.h5ad\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4bf381d0-293d-4fad-97f7-e58112195e1e",
   "metadata": {},
   "source": [
    "# Add missing runs for 'nanostring_cosmx_human_nsclc_subsample_50pct'\n",
    "dataset = \"nanostring_cosmx_human_nsclc_subsample_50pct\"\n",
    "conv_layer_encoder = \"gatv2conv\"\n",
    "timestamp = \"30082023_182210_4\"\n",
    "\n",
    "adata1 = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}_cont.h5ad\")\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [5]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"30082023_175654_3\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [6]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"03092023_114810_2\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [7]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"03092023_114744_1\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [8]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "adata1.write(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}_cont.h5ad\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "858922f2-4cb0-4ea1-b18d-08d5641c7f75",
   "metadata": {},
   "source": [
    "# Add missing runs for 'nanostring_cosmx_human_nsclc_subsample_25pct'\n",
    "dataset = \"nanostring_cosmx_human_nsclc_subsample_25pct\"\n",
    "conv_layer_encoder = \"gatv2conv\"\n",
    "timestamp = \"04092023_094005_1\"\n",
    "\n",
    "adata1 = sc.read_h5ad(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}_cont.h5ad\")\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [3, 4]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"04092023_094225_4\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [5]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"04092023_094213_3\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [6]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "del(adata2)\n",
    "gc.collect()\n",
    "\n",
    "timestamp = \"03092023_115037_1\"\n",
    "adata2 = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/results/{conv_layer_encoder}_sample_integration_method_benchmarking/{timestamp}/{dataset}_{conv_layer_encoder}_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "for run_number in [7, 8]:\n",
    "    adata1.uns[f\"nichecompass_latent_run{run_number}_umap\"] = adata2.uns[f\"nichecompass_latent_run{run_number}_umap\"]\n",
    "    adata1.uns[f\"nichecompass_model_training_duration_run{run_number}\"] = adata2.uns[f\"nichecompass_model_training_duration_run{run_number}\"]\n",
    "    adata1.obsm[f\"nichecompass_latent_run{run_number}\"] = adata2.obsm[f\"nichecompass_latent_run{run_number}\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"]\n",
    "    adata1.obsp[f\"nichecompass_latent_run{run_number}_distances\"] = adata2.obsp[f\"nichecompass_latent_run{run_number}_distances\"]\n",
    "    \n",
    "adata1.write(f\"{benchmarking_folder_path}/{dataset}_nichecompass_{conv_layer_encoder}_cont.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2740c5e1-3f22-4a33-9269-e973a8820732",
   "metadata": {},
   "source": [
    "##### 2.1.3.2 Fix Observation Uniqueness"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8a286276-91b3-4050-8542-2d52b211bd55",
   "metadata": {},
   "source": [
    "conv_layer_encoder = \"gatv2conv_fov\"\n",
    "dataset = \"nanostring_cosmx_human_nsclc_subsample_25pct\"\n",
    "\n",
    "adata = sc.read_h5ad(f\"{artifact_folder_path}/sample_integration_method_benchmarking/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")\n",
    "adata.obs_names_make_unique()\n",
    "adata.write(f\"{artifact_folder_path}/sample_integration_method_benchmarking/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1b85d4ad-1cdc-4d5e-941d-201db3d9def9",
   "metadata": {},
   "source": [
    "# Fix observation uniqueness\n",
    "for model in [\"staci\",\n",
    "              \"graphst\",\n",
    "              \"cellcharter\",\n",
    "              \"banksy\",\n",
    "             ]:\n",
    "    for dataset in [\"nanostring_cosmx_human_nsclc\",\n",
    "                    \"nanostring_cosmx_human_nsclc_subsample_50pct\",\n",
    "                    \"nanostring_cosmx_human_nsclc_subsample_25pct\",\n",
    "                    \"nanostring_cosmx_human_nsclc_subsample_10pct\",\n",
    "                    \"nanostring_cosmx_human_nsclc_subsample_5pct\",\n",
    "                    \"nanostring_cosmx_human_nsclc_subsample_1pct\"\n",
    "                   ]:\n",
    "        adata = sc.read_h5ad(f\"{artifact_folder_path}/sample_integration_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "        adata.obs_names_make_unique()\n",
    "        adata.write(f\"{artifact_folder_path}/sample_integration_method_benchmarking/{dataset}_{model}.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5436f33a-0360-480f-a60b-2cfe1f616b6c",
   "metadata": {},
   "source": [
    "##### 2.1.3.3 Metrics Computation Split Due to Memory Constraints"
   ]
  },
  {
   "cell_type": "raw",
   "id": "02b87ac7-6b10-43bc-b97c-3046c721bd37",
   "metadata": {},
   "source": [
    "# Only keep 1 run for metrics computation due to memory constraints\n",
    "conv_layer_encoder = \"gatv2conv_fov\" # \"gcnconv\", \"gcnconv\", \"gcnconv_cont\", \"gatv2conv_fov\"\n",
    "dataset = \"nanostring_cosmx_human_nsclc_subsample_25pct\" # \"nanostring_cosmx_human_nsclc_subsample_50pct\", # nanostring_cosmx_human_nsclc\n",
    "\n",
    "for part in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "    adata = sc.read_h5ad(f\"{artifact_folder_path}/sample_integration_method_benchmarking/{dataset}_nichecompass_{conv_layer_encoder}.h5ad\")\n",
    "    for run_number in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "        if run_number != part:\n",
    "            del(adata.uns[f\"nichecompass_latent_run{run_number}_umap\"])\n",
    "            del(adata.uns[f\"nichecompass_model_training_duration_run{run_number}\"])\n",
    "            del(adata.obsp[f\"nichecompass_latent_run{run_number}_connectivities\"])\n",
    "            del(adata.obsp[f\"nichecompass_latent_run{run_number}_distances\"])\n",
    "            del(adata.obsm[f\"nichecompass_latent_run{run_number}\"])\n",
    "    adata.write(f\"{artifact_folder_path}/sample_integration_method_benchmarking/{dataset}_nichecompass_{conv_layer_encoder}_part{part}.h5ad\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7151a420-cf7c-4448-a84d-3090bb3a8dfe",
   "metadata": {},
   "source": [
    "conv_layer_encoder = \"gatv2conv_cont\" # \"gcnconv\", \"gcnconv_cont\", \"gatv2conv_fov\", \"gatv2conv_cont\"\n",
    "dataset = \"nanostring_cosmx_human_nsclc_subsample_25pct\"\n",
    "\n",
    "df = pd.read_csv(f\"{artifact_folder_path}/sample_integration_method_benchmarking/{dataset}_nichecompass_{conv_layer_encoder}_part1_metrics.csv\")\n",
    "for run_number in [2, 3, 4, 5, 6, 7, 8]:\n",
    "    df2 = pd.read_csv(f\"{artifact_folder_path}/sample_integration_method_benchmarking/{dataset}_nichecompass_{conv_layer_encoder}_part{run_number}_metrics.csv\")\n",
    "    df = pd.concat([df, df2], ignore_index=True)\n",
    "df.to_csv(f\"{artifact_folder_path}/sample_integration_method_benchmarking/{dataset}_nichecompass_{conv_layer_encoder}_metrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455db312-8765-46ef-a81e-afcd91b788ec",
   "metadata": {},
   "source": [
    "### 2.2 Create Benchmarking Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93372b2c-cd53-4f2f-9c5f-67e07efa16f8",
   "metadata": {},
   "source": [
    "#### 2.2.1 nanoString CosMx SMI Human Non-Small-Cell Lung Cancer (NSCLC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ff2ad5-c04f-420c-ad0d-b1dcf3a1e383",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.color_palette(\"colorblind\").as_hex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fc24c4-1de9-469f-88f4-5ca697570c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sns.color_palette(\"colorblind\").as_hex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0171efc-d724-4906-9e6d-7d7dafae1cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fig. 3e: 10 pct subsample comparison NicheCompass with FoV embedding ###\n",
    "dataset = \"nanostring_cosmx_human_nsclc_subsample_10pct\"\n",
    "run_number = 2\n",
    "model = \"nichecompass_gatv2conv\"\n",
    "latent_leiden_resolution = 0.21\n",
    "timestamp = \"26082023_191240_1\"\n",
    "adata = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/models/gatv2conv_sample_integration_method_benchmarking/{timestamp}/run{run_number}/{dataset}_gatv2conv_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "print(\"\\nComputing UMAP embedding...\")\n",
    "sc.tl.umap(adata,\n",
    "           neighbors_key=f\"nichecompass_latent\")\n",
    "\n",
    "print(\"\\nComputing Leiden clustering...\")\n",
    "sc.tl.leiden(adata=adata,\n",
    "             resolution=latent_leiden_resolution,\n",
    "             key_added=f\"latent_leiden_{latent_leiden_resolution}\",\n",
    "             neighbors_key=f\"nichecompass_latent\")\n",
    "\n",
    "niche_annotation_dict = {\n",
    "    \"0\": \"Endothelial/Stroma\",\n",
    "    \"1\": \"Tumor 1\",\n",
    "    \"2\": \"Lymphoid Structures\",\n",
    "    \"3\": \"Epithelial/Stroma\",\n",
    "    \"4\": \"Neutrophil/Myeloid/Stroma\",\n",
    "    \"5\": \"Plasmablast/Stroma\",\n",
    "    \"6\": \"Tumor-Stroma Boundary\",\n",
    "    \"7\": \"Tumor 2\"}\n",
    "\n",
    "latent_cluster_colors = create_new_color_dict(\n",
    "    adata=adata,\n",
    "    cat_key=f\"latent_leiden_{latent_leiden_resolution}\")\n",
    "\n",
    "adata.obs[\"niche\"] = adata.obs[f\"latent_leiden_{latent_leiden_resolution}\"].map(niche_annotation_dict)\n",
    "niche_colors = {niche: latent_cluster_colors[cluster] for cluster, niche in niche_annotation_dict.items()}\n",
    "\n",
    "plot_category_in_latent_and_physical_space(\n",
    "        adata=adata,\n",
    "        plot_label=\"Niches\",\n",
    "        model_label={model},\n",
    "        cat_key=\"niche\",\n",
    "        groups=None,\n",
    "        sample_key=\"batch\",\n",
    "        samples=adata.obs[\"batch\"].unique().tolist(),\n",
    "        cat_colors=niche_colors,\n",
    "        size=(720000 / len(adata)),\n",
    "        spot_size=200,\n",
    "        save_fig=True,\n",
    "        file_path=f\"{benchmarking_folder_path}/{dataset}_niches_{model}.svg\")\n",
    "\n",
    "cell_type_colors = create_new_color_dict(\n",
    "    adata=adata,\n",
    "    color_palette=\"cell_type_20\",\n",
    "    cat_key=\"cell_type\")\n",
    "\n",
    "#adata_temp = adata[adata.obs[\"niche\"].isin([\"Endothelial/Stroma\",\n",
    "#                                            \"Plasmablast/Stroma\",\n",
    "#                                            \"Tumor-Stroma Boundary\"])]\n",
    "adata_temp = adata\n",
    "\n",
    "tmp = pd.crosstab(adata_temp.obs[\"niche\"], adata_temp.obs[\"cell_type\"], normalize='index')\n",
    "tmp.rename(index={\"Tumor-Stroma Boundary\": \"Tumor-Stroma\\nBoundary\"},\n",
    "           inplace=True)\n",
    "ax = tmp.plot.barh(color=cell_type_colors, stacked=True, figsize=(3, 6)).legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel(\"Cell Type Proportions\", fontsize=16)\n",
    "plt.savefig(f\"{benchmarking_folder_path}/{model}_{dataset}_niche_cell_type_proportions.svg\", bbox_inches='tight')\n",
    "\n",
    "adata.obs[\"batch\"] = adata.obs[\"batch\"].replace({\"lung5_rep1\": \"Replicate 1\",\n",
    "                                                 \"lung5_rep2\": \"Replicate 2\",\n",
    "                                                 \"lung5_rep3\": \"Replicate 3\"})\n",
    "\n",
    "batch_colors = {\"Replicate 1\": sns.color_palette(\"colorblind\").as_hex()[0],\n",
    "                \"Replicate 2\": sns.color_palette(\"colorblind\").as_hex()[3],\n",
    "                \"Replicate 3\": sns.color_palette(\"colorblind\").as_hex()[8]}\n",
    "\n",
    "plot_category_in_latent_and_physical_space(\n",
    "        adata=adata,\n",
    "        plot_label=\"Batches\",\n",
    "        model_label={model},\n",
    "        cat_key=\"batch\",\n",
    "        groups=None,\n",
    "        sample_key=\"batch\",\n",
    "        samples=adata.obs[\"batch\"].unique().tolist(),\n",
    "        cat_colors=batch_colors,\n",
    "        size=(720000 / len(adata)),\n",
    "        spot_size=200,\n",
    "        save_fig=True,\n",
    "        file_path=f\"{benchmarking_folder_path}/{dataset}_batches_{model}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32520e3b-41aa-4776-b8d3-e90259cfe50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fig. 3e: 10 pct subsample comparison GraphST with prior alignment through PASTE algorithm ###\n",
    "model = \"graphst_paste\"\n",
    "latent_leiden_resolution = 0.4\n",
    "adata = sc.read_h5ad(f\"{artifact_folder_path}/sample_integration_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "\n",
    "print(\"\\nComputing UMAP embedding...\")\n",
    "sc.tl.umap(adata,\n",
    "           neighbors_key=f\"graphst_latent_run{run_number}\")\n",
    "\n",
    "print(\"\\nComputing Leiden clustering...\")\n",
    "sc.tl.leiden(adata=adata,\n",
    "             resolution=latent_leiden_resolution,\n",
    "             key_added=f\"latent_leiden_{latent_leiden_resolution}\",\n",
    "             neighbors_key=f\"graphst_latent_run{run_number}\")\n",
    "\n",
    "latent_cluster_colors = {\n",
    "    \"0\": \"#66C5CC\",\n",
    "    \"1\": \"#9EB9F3\",\n",
    "    \"2\": \"#C9DB74\",\n",
    "    \"3\": \"#DCB0F2\",\n",
    "    \"4\": \"#8B008B\",\n",
    "    \"5\": \"#FE88B1\",\n",
    "    \"6\": \"#F6CF71\",\n",
    "    \"7\": \"#F89C74\"}\n",
    "\n",
    "niche_annotation_dict = {\n",
    "    \"0\": \"Endothelial/Stroma (Replicate 1 & 3)\",\n",
    "    \"1\": \"Tumor 1\",\n",
    "    \"2\": \"Lymphoid Structures\",\n",
    "    \"3\": \"Neutrophil/Myeloid/Stroma\",\n",
    "    \"4\": \"Endothelial/Stroma (Replicate 2)\",\n",
    "    \"5\": \"Tumor-Stroma Boundary\",\n",
    "    \"6\": \"Epithelial/Stroma\",\n",
    "    \"7\": \"Tumor 2\"}\n",
    "\n",
    "adata.obs[\"niche\"] = adata.obs[f\"latent_leiden_{latent_leiden_resolution}\"].map(niche_annotation_dict)\n",
    "niche_colors = {niche: latent_cluster_colors[cluster] for cluster, niche in niche_annotation_dict.items()}\n",
    "\n",
    "plot_category_in_latent_and_physical_space(\n",
    "        adata=adata,\n",
    "        plot_label=\"Niches\",\n",
    "        model_label={model},\n",
    "        cat_key=f\"niche\",\n",
    "        groups=None,\n",
    "        sample_key=\"batch\",\n",
    "        samples=adata.obs[\"batch\"].unique().tolist(),\n",
    "        cat_colors=niche_colors,\n",
    "        size=(720000 / len(adata)),\n",
    "        spot_size=200,\n",
    "        save_fig=True,\n",
    "        file_path=f\"{benchmarking_folder_path}/{dataset}_niches_{model}.svg\")\n",
    "\n",
    "cell_type_colors = create_new_color_dict(\n",
    "    adata=adata,\n",
    "    color_palette=\"cell_type_20\",\n",
    "    cat_key=\"cell_type\")\n",
    "\n",
    "#adata_temp = adata[adata.obs[\"niche\"].isin([\"Endothelial/Stroma (Replicate 2)\",\n",
    "#                                            \"Endothelial/Stroma (Replicate 1 & 3)\",\n",
    "#                                            \"Tumor-Stroma Boundary\"])]\n",
    "adata_temp = adata\n",
    "\n",
    "tmp = pd.crosstab(adata_temp.obs[\"niche\"], adata_temp.obs[\"cell_type\"], normalize='index')\n",
    "tmp.rename(index={\"Endothelial/Stroma (Replicate 2)\": \"Endothelial/Stroma\\n(Replicate 2)\",\n",
    "                  \"Endothelial/Stroma (Replicate 1 & 3)\": \"Endothelial/Stroma\\n(Replicate 1 & 3)\",\n",
    "                  \"Tumor-Stroma Boundary\": \"Tumor-Stroma\\nBoundary\"},\n",
    "           inplace=True)\n",
    "ax = tmp.plot.barh(color=cell_type_colors, stacked=True, figsize=(3, 6)).legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel(\"Cell Type Proportions\", fontsize=16)\n",
    "plt.savefig(f\"{benchmarking_folder_path}/{model}_{dataset}_niche_cell_type_proportions.svg\", bbox_inches='tight')\n",
    "\n",
    "adata.obs[\"batch\"] = adata.obs[\"batch\"].replace({\"lung5_rep1\": \"Replicate 1\",\n",
    "                                                 \"lung5_rep2\": \"Replicate 2\",\n",
    "                                                 \"lung5_rep3\": \"Replicate 3\"})\n",
    "\n",
    "batch_colors = {\"Replicate 1\": sns.color_palette(\"colorblind\").as_hex()[0],\n",
    "                \"Replicate 2\": sns.color_palette(\"colorblind\").as_hex()[3],\n",
    "                \"Replicate 3\": sns.color_palette(\"colorblind\").as_hex()[8]}\n",
    "\n",
    "plot_category_in_latent_and_physical_space(\n",
    "        adata=adata,\n",
    "        plot_label=\"Batches\",\n",
    "        model_label={model},\n",
    "        cat_key=\"batch\",\n",
    "        groups=None,\n",
    "        sample_key=\"batch\",\n",
    "        samples=adata.obs[\"batch\"].unique().tolist(),\n",
    "        cat_colors=batch_colors,\n",
    "        size=(720000 / len(adata)),\n",
    "        spot_size=200,\n",
    "        save_fig=True,\n",
    "        file_path=f\"{benchmarking_folder_path}/{dataset}_batches_{model}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e8d0ed-7cc3-44b0-afe0-b3c2674549f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fig. 3e: 10 pct subsample comparison STACI ###\n",
    "model = \"staci\"\n",
    "run_number = 1\n",
    "latent_leiden_resolution = 0.19 # 0.18\n",
    "adata = sc.read_h5ad(f\"{artifact_folder_path}/sample_integration_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "\n",
    "sc.pp.neighbors(adata,\n",
    "                use_rep=f\"staci_latent_run{run_number}\",\n",
    "                key_added=f\"staci_latent_run{run_number}\")\n",
    "\n",
    "print(\"\\nComputing UMAP embedding...\")\n",
    "sc.tl.umap(adata,\n",
    "           neighbors_key=f\"staci_latent_run{run_number}\")\n",
    "\n",
    "print(\"\\nComputing Leiden clustering...\")\n",
    "sc.tl.leiden(adata=adata,\n",
    "             resolution=latent_leiden_resolution,\n",
    "             key_added=f\"latent_leiden_{latent_leiden_resolution}\",\n",
    "             neighbors_key=f\"staci_latent_run{run_number}\")\n",
    "\n",
    "latent_cluster_colors = {\n",
    "    \"0\": \"#9EB9F3\",\n",
    "    \"1\": \"#F6CF71\",\n",
    "    \"2\": \"#C9DB74\",\n",
    "    \"3\": \"#66C5CC\",\n",
    "    \"4\": \"#87C55F\",\n",
    "    \"5\": \"#DCB0F2\",\n",
    "    \"6\": \"#8B008B\",\n",
    "    \"7\": \"#F89C74\"}\n",
    "\n",
    "niche_annotation_dict = {\n",
    "    \"0\": \"Tumor 1\",\n",
    "    \"1\": \"Epithelial/Stroma\",\n",
    "    \"2\": \"Lymphoid Structures\",\n",
    "    \"3\": \"Endothelial/Stroma (Replicate 1 & 3)\",\n",
    "    \"4\": \"Plasmablast/Stroma\",\n",
    "    \"5\": \"Neutrophil/Myeloid/Stroma\",\n",
    "    \"6\": \"Endothelial/Stroma (Replicate 2)\",\n",
    "    \"7\": \"Tumor 2\"}\n",
    "\n",
    "adata.obs[\"niche\"] = adata.obs[f\"latent_leiden_{latent_leiden_resolution}\"].map(niche_annotation_dict)\n",
    "niche_colors = {niche: latent_cluster_colors[cluster] for cluster, niche in niche_annotation_dict.items()}\n",
    "\n",
    "plot_category_in_latent_and_physical_space(\n",
    "        adata=adata,\n",
    "        plot_label=\"Niches\",\n",
    "        model_label={model},\n",
    "        cat_key=f\"niche\",\n",
    "        groups=None,\n",
    "        sample_key=\"batch\",\n",
    "        samples=adata.obs[\"batch\"].unique().tolist(),\n",
    "        cat_colors=niche_colors,\n",
    "        size=(720000 / len(adata)),\n",
    "        spot_size=200,\n",
    "        save_fig=True,\n",
    "        file_path=f\"{benchmarking_folder_path}/{dataset}_niches_{model}.svg\")\n",
    "\n",
    "cell_type_colors = create_new_color_dict(\n",
    "    adata=adata,\n",
    "    color_palette=\"cell_type_20\",\n",
    "    cat_key=\"cell_type\")\n",
    "\n",
    "#adata_temp = adata[adata.obs[\"niche\"].isin([\"Endothelial/Stroma (Replicate 2)\",\n",
    "#                                            \"Endothelial/Stroma (Replicate 1 & 3)\",\n",
    "#                                            \"Plasmablast/Stroma\"])]\n",
    "adata_temp = adata\n",
    "\n",
    "tmp = pd.crosstab(adata_temp.obs[\"niche\"], adata_temp.obs[\"cell_type\"], normalize='index')\n",
    "tmp.rename(index={\"Endothelial/Stroma (Replicate 1 & 3)\": \"Endothelial/Stroma\\n(Replicate 1 & 3)\",\n",
    "                  \"Endothelial/Stroma (Replicate 2)\": \"Endothelial/Stroma\\n(Replicate 2)\"}, inplace=True)\n",
    "ax = tmp.plot.barh(color=cell_type_colors, stacked=True, figsize=(3, 6)).legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel(\"Cell Type Proportions\", fontsize=16)\n",
    "plt.savefig(f\"{benchmarking_folder_path}/{model}_{dataset}_niche_cell_type_proportions.svg\", bbox_inches='tight')\n",
    "\n",
    "adata.obs[\"batch\"] = adata.obs[\"batch\"].replace({\"lung5_rep1\": \"Replicate 1\",\n",
    "                                                 \"lung5_rep2\": \"Replicate 2\",\n",
    "                                                 \"lung5_rep3\": \"Replicate 3\"})\n",
    "\n",
    "batch_colors = {\"Replicate 1\": sns.color_palette(\"colorblind\").as_hex()[0],\n",
    "                \"Replicate 2\": sns.color_palette(\"colorblind\").as_hex()[3],\n",
    "                \"Replicate 3\": sns.color_palette(\"colorblind\").as_hex()[8]}\n",
    "\n",
    "plot_category_in_latent_and_physical_space(\n",
    "        adata=adata,\n",
    "        plot_label=\"Batches\",\n",
    "        model_label={model},\n",
    "        cat_key=\"batch\",\n",
    "        groups=None,\n",
    "        sample_key=\"batch\",\n",
    "        samples=adata.obs[\"batch\"].unique().tolist(),\n",
    "        cat_colors=batch_colors,\n",
    "        size=(720000 / len(adata)),\n",
    "        spot_size=200,\n",
    "        save_fig=True,\n",
    "        file_path=f\"{benchmarking_folder_path}/{dataset}_batches_{model}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d8040d-d660-4693-ad42-daab484125f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fig. 3e: 10 pct subsample comparison CellCharter ###\n",
    "model = \"cellcharter\"\n",
    "run_number = 1\n",
    "latent_leiden_resolution = 0.21\n",
    "adata = sc.read_h5ad(f\"{artifact_folder_path}/sample_integration_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "\n",
    "print(\"\\nComputing UMAP embedding...\")\n",
    "sc.tl.umap(adata,\n",
    "           neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "\n",
    "print(\"\\nComputing Leiden clustering...\")\n",
    "sc.tl.leiden(adata=adata,\n",
    "             resolution=latent_leiden_resolution,\n",
    "             key_added=f\"latent_leiden_{latent_leiden_resolution}\",\n",
    "             neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "\n",
    "#print(\"\\nComputing CellCharter clustering...\")\n",
    "# Use cellcharter clustering\n",
    "#gmm = cc.tl.Cluster(\n",
    "#    n_clusters=8, \n",
    "#    random_state=1,\n",
    "#    # If running on GPU\n",
    "#    #trainer_params=dict(accelerator='gpu', devices=1)\n",
    "#)\n",
    "#gmm.fit(adata, use_rep=f\"{model}_latent_run{run_number}\")\n",
    "#adata.obs[\"spatial_clusters\"] = gmm.predict(adata, use_rep=f\"{model}_latent_run{run_number}\").astype(\"str\")\n",
    "\n",
    "latent_cluster_colors = {\n",
    "    \"0\": \"#66C5CC\",\n",
    "    \"1\": \"#87C55F\",\n",
    "    \"2\": \"#9EB9F3\",\n",
    "    \"3\": \"#DCB0F2\",\n",
    "    \"4\": \"#8B008B\",\n",
    "    \"5\": \"#FE88B1\",\n",
    "    \"6\": \"#FE88B1\",\n",
    "    \"7\": \"#2F4F4F\",\n",
    "    \"8\": \"#FF00FF\"}\n",
    "\n",
    "niche_annotation_dict = {\n",
    "    \"0\": \"Endothelial/Stroma (Replicate 1 & 3)\",\n",
    "    \"1\": \"Plasmablast/Stroma & Lymphoid Structures\",\n",
    "    \"2\": \"Tumor 1\",\n",
    "    \"3\": \"Neutrophil/Myeloid/Stroma\",\n",
    "    \"4\": \"Endothelial/Stroma (Replicate 2)\",\n",
    "    \"5\": \"Tumor 2\",\n",
    "    \"6\": \"Tumor-Stroma Boundary\",\n",
    "    \"7\": \"Tumor 3\",\n",
    "    \"8\": \"Tumor 4\"}\n",
    "\n",
    "adata.obs[\"niche\"] = adata.obs[f\"latent_leiden_{latent_leiden_resolution}\"].map(niche_annotation_dict)\n",
    "niche_colors = {niche: latent_cluster_colors[cluster] for cluster, niche in niche_annotation_dict.items()}\n",
    "\n",
    "plot_category_in_latent_and_physical_space(\n",
    "        adata=adata,\n",
    "        plot_label=\"Niches\",\n",
    "        model_label={model},\n",
    "        cat_key=f\"niche\",\n",
    "        groups=None,\n",
    "        sample_key=\"batch\",\n",
    "        samples=adata.obs[\"batch\"].unique().tolist(),\n",
    "        cat_colors=niche_colors,\n",
    "        size=(720000 / len(adata)),\n",
    "        spot_size=200,\n",
    "        save_fig=True,\n",
    "        file_path=f\"{benchmarking_folder_path}/{dataset}_niches_{model}.svg\")\n",
    "\n",
    "cell_type_colors = create_new_color_dict(\n",
    "    adata=adata,\n",
    "    color_palette=\"cell_type_20\",\n",
    "    cat_key=\"cell_type\")\n",
    "\n",
    "#adata_temp = adata[adata.obs[\"niche\"].isin([\"Endothelial/Stroma (Replicate 2)\",\n",
    "#                                            \"Endothelial/Stroma (Replicate 1 & 3)\",\n",
    "#                                            \"Tumor-Stroma Boundary\",\n",
    "#                                            \"Plasmablast/Stroma\"])]\n",
    "adata_temp = adata\n",
    "\n",
    "tmp = pd.crosstab(adata_temp.obs[\"niche\"], adata_temp.obs[\"cell_type\"], normalize='index')\n",
    "tmp.rename(index={\"Endothelial/Stroma (Replicate 2)\": \"Endothelial/Stroma\\n(Replicate 2)\",\n",
    "                  \"Endothelial/Stroma (Replicate 1 & 3)\": \"Endothelial/Stroma\\n(Replicate 1 & 3)\",\n",
    "                  \"Tumor-Stroma Boundary\": \"Tumor-Stroma\\nBoundary\",\n",
    "                  \"Plasmablast/Stroma & Lymphoid Structures\": \"Plasmablast/Stroma &\\n Lymphoid Structures\"},\n",
    "           inplace=True)\n",
    "ax = tmp.plot.barh(color=cell_type_colors, stacked=True, figsize=(3, 6)).legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel(\"Cell Type Proportions\", fontsize=16)\n",
    "plt.savefig(f\"{benchmarking_folder_path}/{model}_{dataset}_niche_cell_type_proportions.svg\", bbox_inches='tight')\n",
    "\n",
    "adata.obs[\"batch\"] = adata.obs[\"batch\"].replace({\"lung5_rep1\": \"Replicate 1\",\n",
    "                                                 \"lung5_rep2\": \"Replicate 2\",\n",
    "                                                 \"lung5_rep3\": \"Replicate 3\"})\n",
    "\n",
    "batch_colors = {\"Replicate 1\": sns.color_palette(\"colorblind\").as_hex()[0],\n",
    "                \"Replicate 2\": sns.color_palette(\"colorblind\").as_hex()[3],\n",
    "                \"Replicate 3\": sns.color_palette(\"colorblind\").as_hex()[8]}\n",
    "\n",
    "plot_category_in_latent_and_physical_space(\n",
    "        adata=adata,\n",
    "        plot_label=\"Batches\",\n",
    "        model_label={model},\n",
    "        cat_key=\"batch\",\n",
    "        groups=None,\n",
    "        sample_key=\"batch\",\n",
    "        samples=adata.obs[\"batch\"].unique().tolist(),\n",
    "        cat_colors=batch_colors,\n",
    "        size=(720000 / len(adata)),\n",
    "        spot_size=200,\n",
    "        save_fig=True,\n",
    "        file_path=f\"{benchmarking_folder_path}/{dataset}_batches_{model}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4a7849-93ae-40f9-8e7a-c785dc8e3770",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fig. 3e: 10 pct subsample comparison BANKSY ###\n",
    "model = \"banksy\"\n",
    "dataset = \"nanostring_cosmx_human_nsclc_subsample_10pct\"\n",
    "run_number = 1\n",
    "latent_leiden_resolution = 0.48\n",
    "adata = sc.read_h5ad(f\"{artifact_folder_path}/sample_integration_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "\n",
    "sc.pp.neighbors(adata,\n",
    "                use_rep=f\"{model}_latent_run{run_number}\",\n",
    "                key_added=f\"{model}_latent_run{run_number}\")\n",
    "\n",
    "print(\"\\nComputing UMAP embedding...\")\n",
    "sc.tl.umap(adata,\n",
    "           neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "\n",
    "print(\"\\nComputing Leiden clustering...\")\n",
    "sc.tl.leiden(adata=adata,\n",
    "             resolution=latent_leiden_resolution,\n",
    "             key_added=f\"latent_leiden_{latent_leiden_resolution}\",\n",
    "             neighbors_key=f\"{model}_latent_run{run_number}\")\n",
    "\n",
    "latent_cluster_colors = {\n",
    "    \"0\": \"#F6CF71\",\n",
    "    \"1\": \"#9EB9F3\",\n",
    "    \"2\": \"#66C5CC\",\n",
    "    \"3\": \"#DCB0F2\",\n",
    "    \"4\": \"#8B4513\",\n",
    "    \"5\": \"#FE88B1\",\n",
    "    \"6\": \"#F89C74\",\n",
    "    \"7\": \"#FF6347\",\n",
    "    \"8\": \"#2F4F4F\"}\n",
    "\n",
    "niche_annotation_dict = {\n",
    "    \"0\": \"Epithelial/Stroma\",\n",
    "    \"1\": \"Tumor 1\",\n",
    "    \"2\": \"Endothelial/Stroma (Replicate 1 & 3)\",\n",
    "    \"3\": \"Neutrophil/Myeloid/Stroma\",\n",
    "    \"4\": \"Artifact 2\",\n",
    "    \"5\": \"Tumor-Stroma Boundary\", #\"Plasmablast/Stroma\",\n",
    "    \"6\": \"Tumor 2\",\n",
    "    \"7\": \"Artifact 1\",\n",
    "    \"8\": \"Tumor 3\"}\n",
    "\n",
    "adata.obs[\"niche\"] = adata.obs[f\"latent_leiden_{latent_leiden_resolution}\"].map(niche_annotation_dict)\n",
    "niche_colors = {niche: latent_cluster_colors[cluster] for cluster, niche in niche_annotation_dict.items()}\n",
    "\n",
    "plot_category_in_latent_and_physical_space(\n",
    "        adata=adata,\n",
    "        plot_label=\"Niches\",\n",
    "        model_label={model},\n",
    "        cat_key=f\"niche\",\n",
    "        groups=None,\n",
    "        sample_key=\"batch\",\n",
    "        samples=adata.obs[\"batch\"].unique().tolist(),\n",
    "        cat_colors=niche_colors,\n",
    "        size=(720000 / len(adata)),\n",
    "        spot_size=200,\n",
    "        save_fig=True,\n",
    "        file_path=f\"{benchmarking_folder_path}/{dataset}_niches_{model}.svg\")\n",
    "\n",
    "cell_type_colors = create_new_color_dict(\n",
    "    adata=adata,\n",
    "    color_palette=\"cell_type_20\",\n",
    "    cat_key=\"cell_type\")\n",
    "\n",
    "adata_temp = adata\n",
    "\n",
    "tmp = pd.crosstab(adata_temp.obs[\"niche\"], adata_temp.obs[\"cell_type\"], normalize='index')\n",
    "tmp.rename(index={\"Endothelial/Stroma (Replicate 1 & 3)\": \"Endothelial/Stroma\\n(Replicate 1 & 3)\",\n",
    "                  \"Endothelial/Stroma (Replicate 2)\": \"Endothelial/Stroma\\n(Replicate 2)\"}, inplace=True)\n",
    "ax = tmp.plot.barh(color=cell_type_colors, stacked=True, figsize=(3, 6)).legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel(\"Cell Type Proportions\", fontsize=16)\n",
    "plt.savefig(f\"{benchmarking_folder_path}/{model}_{dataset}_niche_cell_type_proportions.svg\", bbox_inches='tight')\n",
    "\n",
    "adata.obs[\"batch\"] = adata.obs[\"batch\"].replace({\"lung5_rep1\": \"Replicate 1\",\n",
    "                                                 \"lung5_rep2\": \"Replicate 2\",\n",
    "                                                 \"lung5_rep3\": \"Replicate 3\"})\n",
    "\n",
    "batch_colors = {\"Replicate 1\": sns.color_palette(\"colorblind\").as_hex()[0],\n",
    "                \"Replicate 2\": sns.color_palette(\"colorblind\").as_hex()[3],\n",
    "                \"Replicate 3\": sns.color_palette(\"colorblind\").as_hex()[8]}\n",
    "\n",
    "plot_category_in_latent_and_physical_space(\n",
    "        adata=adata,\n",
    "        plot_label=\"Batches\",\n",
    "        model_label={model},\n",
    "        cat_key=\"batch\",\n",
    "        groups=None,\n",
    "        sample_key=\"batch\",\n",
    "        samples=adata.obs[\"batch\"].unique().tolist(),\n",
    "        cat_colors=batch_colors,\n",
    "        size=(720000 / len(adata)),\n",
    "        spot_size=200,\n",
    "        save_fig=True,\n",
    "        file_path=f\"{benchmarking_folder_path}/{dataset}_batches_{model}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2ae4c1-01b7-49a7-9ccb-cc6e58d29c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplementary figure: PCR batch effect\n",
    "adata_batch1 = sc.read_h5ad(f\"{data_folder_path}/nanostring_cosmx_human_nsclc_subsample_10pct_batch1.h5ad\")\n",
    "adata_batch2 = sc.read_h5ad(f\"{data_folder_path}/nanostring_cosmx_human_nsclc_subsample_10pct_batch2.h5ad\")\n",
    "adata_batch3 = sc.read_h5ad(f\"{data_folder_path}/nanostring_cosmx_human_nsclc_subsample_10pct_batch3.h5ad\")\n",
    "\n",
    "adata_combined = sc.concat([adata_batch1, adata_batch2, adata_batch3], axis=0)\n",
    "\n",
    "sc.tl.pca(adata_combined)\n",
    "sc.pp.neighbors(adata_combined, n_pcs=20)\n",
    "sc.tl.umap(adata_combined)\n",
    "\n",
    "adata_combined.obs[\"batch\"] = adata_combined.obs[\"batch\"].replace(\n",
    "    {\"lung5_rep1\": \"Replicate 1\",\n",
    "     \"lung5_rep2\": \"Replicate 2\",\n",
    "     \"lung5_rep3\": \"Replicate 3\"})\n",
    "\n",
    "adata_combined.obs[\"fov\"] = adata_combined.obs[\"fov\"].replace(\n",
    "    {\"lung5_rep1_1\": \"Replicate 1 FoV 1\",\n",
    "     \"lung5_rep1_2\": \"Replicate 1 FoV 2\",\n",
    "     \"lung5_rep1_3\": \"Replicate 1 FoV 3\",\n",
    "     \"lung5_rep1_4\": \"Replicate 1 FoV 4\",\n",
    "     \"lung5_rep2_1\": \"Replicate 2 FoV 1\",\n",
    "     \"lung5_rep2_2\": \"Replicate 2 FoV 2\",\n",
    "     \"lung5_rep2_3\": \"Replicate 2 FoV 3\",\n",
    "     \"lung5_rep2_4\": \"Replicate 2 FoV 4\",\n",
    "     \"lung5_rep3_1\": \"Replicate 3 FoV 1\",\n",
    "     \"lung5_rep3_2\": \"Replicate 3 FoV 2\",\n",
    "     \"lung5_rep3_3\": \"Replicate 3 FoV 3\",\n",
    "     \"lung5_rep3_4\": \"Replicate 3 FoV 4\",})\n",
    "\n",
    "batch_colors = {\"Replicate 1\": sns.color_palette(\"colorblind\").as_hex()[0],\n",
    "                \"Replicate 2\": sns.color_palette(\"colorblind\").as_hex()[3],\n",
    "                \"Replicate 3\": sns.color_palette(\"colorblind\").as_hex()[8]}\n",
    "fov_colors = {\"Replicate 1 FoV 1\": sns.color_palette(\"dark\").as_hex()[0],\n",
    "              \"Replicate 1 FoV 2\": sns.color_palette(\"pastel\").as_hex()[0],\n",
    "              \"Replicate 1 FoV 3\": sns.color_palette(\"muted\").as_hex()[0],\n",
    "              \"Replicate 1 FoV 4\": sns.color_palette(\"bright\").as_hex()[0],\n",
    "              \"Replicate 2 FoV 1\": sns.color_palette(\"dark\").as_hex()[3],\n",
    "              \"Replicate 2 FoV 2\": sns.color_palette(\"pastel\").as_hex()[3],\n",
    "              \"Replicate 2 FoV 3\": sns.color_palette(\"muted\").as_hex()[3],\n",
    "              \"Replicate 2 FoV 4\": sns.color_palette(\"bright\").as_hex()[3],\n",
    "              \"Replicate 3 FoV 1\": sns.color_palette(\"dark\").as_hex()[8],\n",
    "              \"Replicate 3 FoV 2\": sns.color_palette(\"pastel\").as_hex()[8],\n",
    "              \"Replicate 3 FoV 3\": sns.color_palette(\"muted\").as_hex()[8],\n",
    "              \"Replicate 3 FoV 4\": sns.color_palette(\"bright\").as_hex()[8]}\n",
    "\n",
    "plot_category_in_latent_and_physical_space(\n",
    "        adata=adata_combined,\n",
    "        plot_label=\"Batches\",\n",
    "        model_label=None,\n",
    "        cat_key=\"batch\",\n",
    "        groups=None,\n",
    "        sample_key=\"batch\",\n",
    "        samples=adata.obs[\"batch\"].unique().tolist(),\n",
    "        cat_colors=batch_colors,\n",
    "        size=(720000 / len(adata)),\n",
    "        spot_size=200,\n",
    "        save_fig=True,\n",
    "        file_path=f\"{benchmarking_folder_path}/{dataset}_pcr_batches.svg\")\n",
    "\n",
    "plot_category_in_latent_and_physical_space(\n",
    "        adata=adata_combined,\n",
    "        plot_label=\"FoV\",\n",
    "        model_label=None,\n",
    "        cat_key=\"fov\",\n",
    "        groups=None,\n",
    "        sample_key=\"batch\",\n",
    "        samples=adata.obs[\"batch\"].unique().tolist(),\n",
    "        cat_colors=fov_colors,\n",
    "        size=(720000 / len(adata)),\n",
    "        spot_size=200,\n",
    "        save_fig=True,\n",
    "        file_path=f\"{benchmarking_folder_path}/{dataset}_pcr_fovs.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4839ca5a-6b2f-4404-a416-1628af784c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supplementary figure: 10 pct subsample comparison GraphST without prior alignment through PASTE algorithm ###\n",
    "run_number = 2\n",
    "\n",
    "model = \"graphst\"\n",
    "latent_leiden_resolution = 0.5\n",
    "adata = sc.read_h5ad(f\"{artifact_folder_path}/sample_integration_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "\n",
    "print(\"\\nComputing UMAP embedding...\")\n",
    "sc.tl.umap(adata,\n",
    "           neighbors_key=f\"graphst_latent_run{run_number}\")\n",
    "\n",
    "print(\"\\nComputing Leiden clustering...\")\n",
    "sc.tl.leiden(adata=adata,\n",
    "             resolution=latent_leiden_resolution,\n",
    "             key_added=f\"latent_leiden_{latent_leiden_resolution}\",\n",
    "             neighbors_key=f\"graphst_latent_run{run_number}\")\n",
    "\n",
    "latent_cluster_colors = {\n",
    "    \"0\": \"#9EB9F3\",\n",
    "    \"1\": \"#C9DB74\",\n",
    "    \"2\": \"#66C5CC\",\n",
    "    \"3\": \"#DCB0F2\",\n",
    "    \"4\": \"#87C55F\",\n",
    "    \"5\": \"#8B008B\",\n",
    "    \"6\": \"#FE88B1\",\n",
    "    \"7\": \"#F6CF71\",\n",
    "    \"8\": \"#F89C74\",\n",
    "    \"9\": \"#2F4F4F\"}\n",
    "\n",
    "niche_annotation_dict = {\n",
    "    \"0\": \"Tumor 1\",\n",
    "    \"1\": \"Lymphoid Structures\",\n",
    "    \"2\": \"Endothelial/Stroma (Replicate 1 & 3)\",\n",
    "    \"3\": \"Neutrophil/Myeloid/Stroma\",\n",
    "    \"4\": \"Plasmablast/Stroma\",\n",
    "    \"5\": \"Endothelial/Stroma (Replicate 2)\",\n",
    "    \"6\": \"Tumor-Stroma Boundary\",\n",
    "    \"7\": \"Epithelial/Stroma\",\n",
    "    \"8\": \"Tumor 2\",\n",
    "    \"9\": \"Tumor 3\"}\n",
    "\n",
    "adata.obs[\"niche\"] = adata.obs[f\"latent_leiden_{latent_leiden_resolution}\"].map(niche_annotation_dict)\n",
    "niche_colors = {niche: latent_cluster_colors[cluster] for cluster, niche in niche_annotation_dict.items()}\n",
    "\n",
    "plot_category_in_latent_and_physical_space(\n",
    "        adata=adata,\n",
    "        plot_label=\"Niches\",\n",
    "        model_label={model},\n",
    "        cat_key=f\"niche\",\n",
    "        groups=None,\n",
    "        sample_key=\"batch\",\n",
    "        samples=adata.obs[\"batch\"].unique().tolist(),\n",
    "        cat_colors=niche_colors,\n",
    "        size=(720000 / len(adata)),\n",
    "        spot_size=200,\n",
    "        save_fig=True,\n",
    "        file_path=f\"{benchmarking_folder_path}/{dataset}_niches_{model}.svg\")\n",
    "\n",
    "cell_type_colors = create_new_color_dict(\n",
    "    adata=adata,\n",
    "    color_palette=\"cell_type_20\",\n",
    "    cat_key=\"cell_type\")\n",
    "\n",
    "adata_temp = adata\n",
    "\n",
    "tmp = pd.crosstab(adata_temp.obs[\"niche\"], adata_temp.obs[\"cell_type\"], normalize='index')\n",
    "tmp.rename(index={\"Endothelial/Stroma (Replicate 1 & 3)\": \"Endothelial/Stroma\\n(Replicate 1 & 3)\",\n",
    "                  \"Endothelial/Stroma (Replicate 2)\": \"Endothelial/Stroma\\n(Replicate 2)\"}, inplace=True)\n",
    "ax = tmp.plot.barh(color=cell_type_colors, stacked=True, figsize=(3, 6)).legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel(\"Cell Type Proportions\", fontsize=16)\n",
    "plt.savefig(f\"{benchmarking_folder_path}/{model}_{dataset}_niche_cell_type_proportions.svg\", bbox_inches='tight')\n",
    "\n",
    "adata.obs[\"batch\"] = adata.obs[\"batch\"].replace({\"lung5_rep1\": \"Replicate 1\",\n",
    "                                                 \"lung5_rep2\": \"Replicate 2\",\n",
    "                                                 \"lung5_rep3\": \"Replicate 3\"})\n",
    "\n",
    "batch_colors = {\"Replicate 1\": sns.color_palette(\"colorblind\").as_hex()[0],\n",
    "                \"Replicate 2\": sns.color_palette(\"colorblind\").as_hex()[3],\n",
    "                \"Replicate 3\": sns.color_palette(\"colorblind\").as_hex()[8]}\n",
    "\n",
    "plot_category_in_latent_and_physical_space(\n",
    "        adata=adata,\n",
    "        plot_label=\"Batches\",\n",
    "        model_label={model},\n",
    "        cat_key=\"batch\",\n",
    "        groups=None,\n",
    "        sample_key=\"batch\",\n",
    "        samples=adata.obs[\"batch\"].unique().tolist(),\n",
    "        cat_colors=batch_colors,\n",
    "        size=(720000 / len(adata)),\n",
    "        spot_size=200,\n",
    "        save_fig=True,\n",
    "        file_path=f\"{benchmarking_folder_path}/{dataset}_batches_{model}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcccdef-44fb-4dde-b703-32caf3c5b769",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supplementary figure: 10 pct subsample comparison NicheCompass (no fov embedding) ###\n",
    "model = \"nichecompass_gatv2conv\"\n",
    "timestamp = \"24082023_153432_1\"\n",
    "latent_leiden_resolution = 0.3 # 0.21\n",
    "adata = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/models/gatv2conv_sample_integration_method_benchmarking/{timestamp}/run{run_number}/{dataset}_gatv2conv_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "print(\"\\nComputing UMAP embedding...\")\n",
    "sc.tl.umap(adata,\n",
    "           neighbors_key=f\"nichecompass_latent\")\n",
    "\n",
    "print(\"\\nComputing Leiden clustering...\")\n",
    "sc.tl.leiden(adata=adata,\n",
    "             resolution=latent_leiden_resolution,\n",
    "             key_added=f\"latent_leiden_{latent_leiden_resolution}\",\n",
    "             neighbors_key=f\"nichecompass_latent\")\n",
    "\n",
    "latent_cluster_colors = {\n",
    "    \"0\": \"#9EB9F3\",\n",
    "    \"1\": \"#FE88B1\",\n",
    "    \"2\": \"#66C5CC\",\n",
    "    \"3\": \"#C9DB74\", \n",
    "    \"4\": \"#DCB0F2\",\n",
    "    \"5\": \"#87C55F\",\n",
    "    \"6\": \"#8B008B\",\n",
    "    \"7\": \"#F6CF71\",\n",
    "    \"8\": \"#F89C74\",\n",
    "    \"9\": \"#2F4F4F\"}\n",
    "\n",
    "niche_annotation_dict = {\n",
    "    \"0\": \"Tumor 1\",\n",
    "    \"1\": \"Tumor-Stroma Boundary\",\n",
    "    \"2\": \"Endothelial/Stroma (Replicate 1 & 3)\",\n",
    "    \"3\": \"Lymphoid Structures\",\n",
    "    \"4\": \"Neutrophil/Myeloid/Stroma\",\n",
    "    \"5\": \"Plasmablast/Stroma\",\n",
    "    \"6\": \"Endothelial/Stroma (Replicate 2)\",\n",
    "    \"7\": \"Epithelial/Stroma\",\n",
    "    \"8\": \"Tumor 2\",\n",
    "    \"9\": \"Tumor 3\"}\n",
    "\n",
    "adata.obs[\"niche\"] = adata.obs[f\"latent_leiden_{latent_leiden_resolution}\"].map(niche_annotation_dict)\n",
    "niche_colors = {niche: latent_cluster_colors[cluster] for cluster, niche in niche_annotation_dict.items()}\n",
    "\n",
    "plot_category_in_latent_and_physical_space(\n",
    "        adata=adata,\n",
    "        plot_label=\"Niches\",\n",
    "        model_label={model},\n",
    "        cat_key=f\"niche\",\n",
    "        groups=None,\n",
    "        sample_key=\"batch\",\n",
    "        samples=adata.obs[\"batch\"].unique().tolist(),\n",
    "        cat_colors=niche_colors,\n",
    "        size=(720000 / len(adata)),\n",
    "        spot_size=200,\n",
    "        save_fig=True,\n",
    "        file_path=f\"{benchmarking_folder_path}/{dataset}_niches_{model}.svg\")\n",
    "\n",
    "cell_type_colors = create_new_color_dict(\n",
    "    adata=adata,\n",
    "    color_palette=\"cell_type_20\",\n",
    "    cat_key=\"cell_type\")\n",
    "\n",
    "adata_temp = adata\n",
    "\n",
    "tmp = pd.crosstab(adata_temp.obs[\"niche\"], adata_temp.obs[\"cell_type\"], normalize='index')\n",
    "tmp.rename(index={\"Endothelial/Stroma (Replicate 1 & 3)\": \"Endothelial/Stroma\\n(Replicate 1 & 3)\",\n",
    "                  \"Endothelial/Stroma (Replicate 2)\": \"Endothelial/Stroma\\n(Replicate 2)\"}, inplace=True)\n",
    "ax = tmp.plot.barh(color=cell_type_colors, stacked=True, figsize=(3, 6)).legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel(\"Cell Type Proportions\", fontsize=16)\n",
    "plt.savefig(f\"{benchmarking_folder_path}/{model}_{dataset}_niche_cell_type_proportions.svg\", bbox_inches='tight')\n",
    "\n",
    "adata.obs[\"batch\"] = adata.obs[\"batch\"].replace({\"lung5_rep1\": \"Replicate 1\",\n",
    "                                                 \"lung5_rep2\": \"Replicate 2\",\n",
    "                                                 \"lung5_rep3\": \"Replicate 3\"})\n",
    "\n",
    "batch_colors = {\"Replicate 1\": sns.color_palette(\"colorblind\").as_hex()[0],\n",
    "                \"Replicate 2\": sns.color_palette(\"colorblind\").as_hex()[3],\n",
    "                \"Replicate 3\": sns.color_palette(\"colorblind\").as_hex()[8]}\n",
    "\n",
    "plot_category_in_latent_and_physical_space(\n",
    "        adata=adata,\n",
    "        plot_label=\"Batches\",\n",
    "        model_label={model},\n",
    "        cat_key=\"batch\",\n",
    "        groups=None,\n",
    "        sample_key=\"batch\",\n",
    "        samples=adata.obs[\"batch\"].unique().tolist(),\n",
    "        cat_colors=batch_colors,\n",
    "        size=(720000 / len(adata)),\n",
    "        spot_size=200,\n",
    "        save_fig=True,\n",
    "        file_path=f\"{benchmarking_folder_path}/{dataset}_batches_{model}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f864452-8b45-4b57-84ef-d09ffda3cc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supplementary figure: 10 pct subsample comparison NicheCompass Light ###\n",
    "model = \"nichecompass_gcnconv_fov\"\n",
    "timestamp = \"23082023_135406_1\"\n",
    "latent_leiden_resolution = 0.25\n",
    "adata = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/models/gcnconv_sample_integration_method_benchmarking/{timestamp}/run{run_number}/{dataset}_gcnconv_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "print(\"\\nComputing UMAP embedding...\")\n",
    "sc.tl.umap(adata,\n",
    "           neighbors_key=f\"nichecompass_latent\")\n",
    "\n",
    "print(\"\\nComputing Leiden clustering...\")\n",
    "sc.tl.leiden(adata=adata,\n",
    "             resolution=latent_leiden_resolution,\n",
    "             key_added=f\"latent_leiden_{latent_leiden_resolution}\",\n",
    "             neighbors_key=f\"nichecompass_latent\")\n",
    "\n",
    "latent_cluster_colors = {\n",
    "    \"0\": \"#66C5CC\",\n",
    "    \"1\": \"#9EB9F3\",\n",
    "    \"2\": \"#C9DB74\",\n",
    "    \"3\": \"#87C55F\",\n",
    "    \"4\": \"#DCB0F2\",\n",
    "    \"5\": \"#F6CF71\",\n",
    "    \"6\": \"#FE88B1\",\n",
    "    \"7\": \"#F89C74\"}\n",
    "\n",
    "niche_annotation_dict = {\n",
    "    \"0\": \"Endothelial/Stroma\",\n",
    "    \"1\": \"Tumor 1\",\n",
    "    \"2\": \"Lymphoid Structures\",\n",
    "    \"3\": \"Plasmablast/Stroma\",\n",
    "    \"4\": \"Neutrophil/Myeloid/Stroma\",\n",
    "    \"5\": \"Epithelial/Stroma\",\n",
    "    \"6\": \"Tumor-Stroma Boundary\",\n",
    "    \"7\": \"Tumor 2\"}\n",
    "\n",
    "adata.obs[\"niche\"] = adata.obs[f\"latent_leiden_{latent_leiden_resolution}\"].map(niche_annotation_dict)\n",
    "niche_colors = {niche: latent_cluster_colors[cluster] for cluster, niche in niche_annotation_dict.items()}\n",
    "\n",
    "plot_category_in_latent_and_physical_space(\n",
    "        adata=adata,\n",
    "        plot_label=\"Niches\",\n",
    "        model_label={model},\n",
    "        cat_key=f\"niche\",\n",
    "        groups=None,\n",
    "        sample_key=\"batch\",\n",
    "        samples=adata.obs[\"batch\"].unique().tolist(),\n",
    "        cat_colors=niche_colors,\n",
    "        size=(720000 / len(adata)),\n",
    "        spot_size=200,\n",
    "        save_fig=True,\n",
    "        file_path=f\"{benchmarking_folder_path}/{dataset}_niches_{model}.svg\")\n",
    "\n",
    "cell_type_colors = create_new_color_dict(\n",
    "    adata=adata,\n",
    "    color_palette=\"cell_type_20\",\n",
    "    cat_key=\"cell_type\")\n",
    "\n",
    "adata_temp = adata\n",
    "\n",
    "tmp = pd.crosstab(adata_temp.obs[\"niche\"], adata_temp.obs[\"cell_type\"], normalize='index')\n",
    "tmp.rename(index={\"Endothelial/Stroma (Replicate 1 & 3)\": \"Endothelial/Stroma\\n(Replicate 1 & 3)\",\n",
    "                  \"Endothelial/Stroma (Replicate 2)\": \"Endothelial/Stroma\\n(Replicate 2)\"}, inplace=True)\n",
    "ax = tmp.plot.barh(color=cell_type_colors, stacked=True, figsize=(3, 6)).legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel(\"Cell Type Proportions\", fontsize=16)\n",
    "plt.savefig(f\"{benchmarking_folder_path}/{model}_{dataset}_niche_cell_type_proportions.svg\", bbox_inches='tight')\n",
    "\n",
    "adata.obs[\"batch\"] = adata.obs[\"batch\"].replace({\"lung5_rep1\": \"Replicate 1\",\n",
    "                                                 \"lung5_rep2\": \"Replicate 2\",\n",
    "                                                 \"lung5_rep3\": \"Replicate 3\"})\n",
    "\n",
    "batch_colors = {\"Replicate 1\": sns.color_palette(\"colorblind\").as_hex()[0],\n",
    "                \"Replicate 2\": sns.color_palette(\"colorblind\").as_hex()[3],\n",
    "                \"Replicate 3\": sns.color_palette(\"colorblind\").as_hex()[8]}\n",
    "\n",
    "plot_category_in_latent_and_physical_space(\n",
    "        adata=adata,\n",
    "        plot_label=\"Batches\",\n",
    "        model_label={model},\n",
    "        cat_key=\"batch\",\n",
    "        groups=None,\n",
    "        sample_key=\"batch\",\n",
    "        samples=adata.obs[\"batch\"].unique().tolist(),\n",
    "        cat_colors=batch_colors,\n",
    "        size=(720000 / len(adata)),\n",
    "        spot_size=200,\n",
    "        save_fig=True,\n",
    "        file_path=f\"{benchmarking_folder_path}/{dataset}_batches_{model}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1238ba-9bef-4635-b0af-13489bc59ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supplementary figure: 10 pct subsample comparison NicheCompass Light (no fov embedding) ###\n",
    "model = \"nichecompass_gcnconv\"\n",
    "timestamp = \"22082023_093531_1\"\n",
    "latent_leiden_resolution = 0.21\n",
    "adata = sc.read_h5ad(f\"{artifact_folder_path}/{dataset}/models/gcnconv_sample_integration_method_benchmarking/{timestamp}/run{run_number}/{dataset}_gcnconv_sample_integration_method_benchmarking.h5ad\")\n",
    "\n",
    "print(\"\\nComputing UMAP embedding...\")\n",
    "sc.tl.umap(adata,\n",
    "           neighbors_key=f\"nichecompass_latent\")\n",
    "\n",
    "print(\"\\nComputing Leiden clustering...\")\n",
    "sc.tl.leiden(adata=adata,\n",
    "             resolution=latent_leiden_resolution,\n",
    "             key_added=f\"latent_leiden_{latent_leiden_resolution}\",\n",
    "             neighbors_key=f\"nichecompass_latent\")\n",
    "\n",
    "latent_cluster_colors = {\n",
    "    \"0\": \"#9EB9F3\",\n",
    "    \"1\": \"#C9DB74\",\n",
    "    \"2\": \"#FE88B1\",\n",
    "    \"3\": \"#66C5CC\", \n",
    "    \"4\": \"#DCB0F2\",\n",
    "    \"5\": \"#87C55F\",\n",
    "    \"6\": \"#8B008B\",\n",
    "    \"7\": \"#F89C74\"}\n",
    "\n",
    "niche_annotation_dict = {\n",
    "    \"0\": \"Tumor 1\",\n",
    "    \"1\": \"Lymphoid Structures\",\n",
    "    \"2\": \"Tumor-Stroma Boundary\", \n",
    "    \"3\": \"Endothelial/Stroma (Replicate 1 & 3)\",\n",
    "    \"4\": \"Neutrophil/Myeloid/Stroma\",\n",
    "    \"5\": \"Plasmablast/Stroma\",\n",
    "    \"6\": \"Endothelial/Stroma (Replicate 2)\",\n",
    "    \"7\": \"Tumor 2\",}\n",
    "\n",
    "adata.obs[\"niche\"] = adata.obs[f\"latent_leiden_{latent_leiden_resolution}\"].map(niche_annotation_dict)\n",
    "niche_colors = {niche: latent_cluster_colors[cluster] for cluster, niche in niche_annotation_dict.items()}\n",
    "\n",
    "plot_category_in_latent_and_physical_space(\n",
    "        adata=adata,\n",
    "        plot_label=\"Niches\",\n",
    "        model_label={model},\n",
    "        cat_key=f\"niche\",\n",
    "        groups=None,\n",
    "        sample_key=\"batch\",\n",
    "        samples=adata.obs[\"batch\"].unique().tolist(),\n",
    "        cat_colors=niche_colors,\n",
    "        size=(720000 / len(adata)),\n",
    "        spot_size=200,\n",
    "        save_fig=True,\n",
    "        file_path=f\"{benchmarking_folder_path}/{dataset}_niches_{model}.svg\")\n",
    "\n",
    "cell_type_colors = create_new_color_dict(\n",
    "    adata=adata,\n",
    "    color_palette=\"cell_type_20\",\n",
    "    cat_key=\"cell_type\")\n",
    "\n",
    "adata_temp = adata\n",
    "\n",
    "tmp = pd.crosstab(adata_temp.obs[\"niche\"], adata_temp.obs[\"cell_type\"], normalize='index')\n",
    "tmp.rename(index={\"Endothelial/Stroma (Replicate 1 & 3)\": \"Endothelial/Stroma\\n(Replicate 1 & 3)\",\n",
    "                  \"Endothelial/Stroma (Replicate 2)\": \"Endothelial/Stroma\\n(Replicate 2)\"}, inplace=True)\n",
    "ax = tmp.plot.barh(color=cell_type_colors, stacked=True, figsize=(3, 6)).legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel(\"Cell Type Proportions\", fontsize=16)\n",
    "plt.savefig(f\"{benchmarking_folder_path}/{model}_{dataset}_niche_cell_type_proportions.svg\", bbox_inches='tight')\n",
    "\n",
    "adata.obs[\"batch\"] = adata.obs[\"batch\"].replace({\"lung5_rep1\": \"Replicate 1\",\n",
    "                                                 \"lung5_rep2\": \"Replicate 2\",\n",
    "                                                 \"lung5_rep3\": \"Replicate 3\"})\n",
    "\n",
    "batch_colors = {\"Replicate 1\": sns.color_palette(\"colorblind\").as_hex()[0],\n",
    "                \"Replicate 2\": sns.color_palette(\"colorblind\").as_hex()[3],\n",
    "                \"Replicate 3\": sns.color_palette(\"colorblind\").as_hex()[8]}\n",
    "\n",
    "plot_category_in_latent_and_physical_space(\n",
    "        adata=adata,\n",
    "        plot_label=\"Batches\",\n",
    "        model_label={model},\n",
    "        cat_key=\"batch\",\n",
    "        groups=None,\n",
    "        sample_key=\"batch\",\n",
    "        samples=adata.obs[\"batch\"].unique().tolist(),\n",
    "        cat_colors=batch_colors,\n",
    "        size=(720000 / len(adata)),\n",
    "        spot_size=200,\n",
    "        save_fig=True,\n",
    "        file_path=f\"{benchmarking_folder_path}/{dataset}_batches_{model}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90277d35-4042-404f-8bc1-656d8b2eedfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fig. 3e: 10 pct subsample comparison metrics (not included) ###\n",
    "datasets = [\"nanostring_cosmx_human_nsclc_subsample_10pct\"]\n",
    "models = [\"nichecompass_gatv2conv_fov\",\n",
    "          \"staci\",\n",
    "          \"graphst_paste\",\n",
    "          \"cellcharter\",\n",
    "          \"banksy\"]\n",
    "\n",
    "summary_df = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    dataset_df = pd.DataFrame()\n",
    "    for model in models:\n",
    "        try:\n",
    "            benchmark_df = pd.read_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\")\n",
    "            #adata = sc.read_h5ad(f\"../../artifacts/single_sample_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "            #training_durations = []\n",
    "            #for run_number in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "            #    training_durations.append(adata.uns[f\"{model.split('_')[0]}_model_training_duration_run{run_number}\"])\n",
    "            #benchmark_df[\"run_time\"] = training_durations\n",
    "            #benchmark_df = benchmark_df[[\"dataset\", \"run_number\", \"run_time\", \"gcs\", \"mlami\", \"cas\", \"clisis\", \"nasw\", \"cnmi\", \"cari\", \"casw\", \"clisi\"]]\n",
    "            #benchmark_df.to_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\", index=False)\n",
    "            benchmark_df[\"model\"] = model\n",
    "            dataset_df = pd.concat([dataset_df, benchmark_df], ignore_index=True)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Did not find file {benchmarking_folder_path}/{dataset}_{model}_metrics.csv. Continuing...\")\n",
    "            missing_run_data = {\n",
    "                \"dataset\": [dataset] * 8,\n",
    "                \"model\": [model] * 8,\n",
    "                \"run_number\": [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "                \"run_time\": [np.nan] * 8\n",
    "            }\n",
    "            missing_run_df = pd.DataFrame(missing_run_data)\n",
    "            dataset_df = pd.concat([dataset_df, missing_run_df], ignore_index=True)\n",
    "            \n",
    "    # Apply min-max scaling to metric columns\n",
    "    for i in range(len(metric_cols_sample_integration)):\n",
    "        min_val = dataset_df[metric_cols_sample_integration[i]].min()\n",
    "        max_val = dataset_df[metric_cols_sample_integration[i]].max()\n",
    "        dataset_df[metric_cols_sample_integration[i] + \"_scaled\"] = ((\n",
    "            dataset_df[metric_cols_sample_integration[i]] - min_val) / (max_val - min_val))\n",
    "\n",
    "    summary_df = pd.concat([summary_df, dataset_df], ignore_index=True)\n",
    "    continue\n",
    "    \n",
    "summary_df['pcr'] = summary_df['pcr'].fillna(0)\n",
    "summary_df['pcr_scaled'] = summary_df['pcr_scaled'].fillna(0)\n",
    "            \n",
    "cat_0_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_sample_integration[0:2]]\n",
    "cat_1_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_sample_integration[2:4]]\n",
    "cat_2_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_sample_integration[4:6]]\n",
    "cat_3_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_sample_integration[6:8]]\n",
    "    \n",
    "summary_df[category_cols_sample_integration[0]] = np.average(summary_df[cat_0_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_sample_integration[0:2],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_sample_integration[1]] = np.average(summary_df[cat_1_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_sample_integration[2:4],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_sample_integration[2]] = np.average(summary_df[cat_2_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_sample_integration[4:6],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_sample_integration[3]] = np.average(summary_df[cat_3_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_sample_integration[6:8],\n",
    "                                                        axis=1)\n",
    "summary_df[\"Overall Score\"] = np.average(summary_df[category_cols_sample_integration[:4]],\n",
    "                                         weights=category_col_weights_sample_integration[:4],\n",
    "                                         axis=1)\n",
    " \n",
    "# Reformat for plot\n",
    "summary_df.replace({\"nichecompass_gatv2conv_fov\": \"NicheCompass\",\n",
    "                    \"staci\": \"STACI\",\n",
    "                    \"graphst_paste\": \"GraphST\",\n",
    "                    \"cellcharter\": \"CellCharter\",\n",
    "                    \"banksy\": \"BANKSY\"}, inplace=True)\n",
    "\n",
    "summary_df = summary_df[(summary_df[\"run_number\"] == 2) & (summary_df[\"model\"] != \"STACI\") |\n",
    "                        (summary_df[\"run_number\"] == 1) & (summary_df[\"model\"] == \"STACI\")]\n",
    "\n",
    "# Plot over all loss weights combinations\n",
    "# Prepare metrics table plot\n",
    "group_cols = [\"dataset\", \"model\"]\n",
    "aggregate_df = summary_df.groupby(group_cols).mean(\"Overall Score\").sort_values(\"Overall Score\", ascending=False)[\n",
    "    metric_cols_sample_integration + [\"Overall Score\"]].reset_index()\n",
    "\n",
    "unrolled_df = pd.melt(aggregate_df, \n",
    "   id_vars=group_cols,\n",
    "   value_vars=metric_cols_sample_integration + [\"Overall Score\"], # metric_cols_sample_integration, category_cols_sample_integration\n",
    "   var_name=\"score_type\", \n",
    "   value_name=\"score\")\n",
    "\n",
    "# Create spatial indicator column\n",
    "def is_spatially_aware_model(row):\n",
    "    if row[\"model\"] in [\"NicheCompass\", \"NicheCompass Light\", \"GraphST\", \"GraphST (No Prior Alignment)\", \"CellCharter\"]:\n",
    "        return True\n",
    "    return False\n",
    "unrolled_df[\"spatially_aware\"] = unrolled_df.apply(lambda row: is_spatially_aware_model(row), axis=1)\n",
    "unrolled_df = unrolled_df[[\"dataset\", \"spatially_aware\", \"model\", \"score_type\", \"score\"]]\n",
    "\n",
    "# Order datasets\n",
    "unrolled_df[\"dataset\"] = pd.Categorical(unrolled_df[\"dataset\"], categories=datasets, ordered=True)\n",
    "unrolled_df = unrolled_df.sort_values(by=\"dataset\")\n",
    "\n",
    "#print(summary_df[\"model\"].value_counts())\n",
    "#print(summary_df[summary_df.isna().any(axis=1)])\n",
    "\n",
    "summary_df[\"model\"] = summary_df[\"model\"].replace(\"NicheCompass GCN\", \"NicheCompass Light\")\n",
    "summary_df[\"model\"] = summary_df[\"model\"].replace(\"NicheCompass GATv2\", \"NicheCompass\")\n",
    "\n",
    "summary_df[\"dataset\"] = summary_df[\"dataset\"].replace(\n",
    "    {\"nanostring_cosmx_human_nsclc_subsample_10pct\": \"nanoString CosMx Human NSCLC\"})\n",
    "\n",
    "# Plot table\n",
    "plot_simple_metrics_table(\n",
    "    df=unrolled_df,\n",
    "    model_col=\"model\",\n",
    "    model_col_width=2.1,\n",
    "    group_col=\"dataset\",\n",
    "    metric_cols=metric_cols_sample_integration, # metric_cols_sample_integration, category_cols_sample_integration\n",
    "    metric_col_weights=metric_col_weights_sample_integration, # metric_col_weights_sample_integration, category_col_weights_sample_integration\n",
    "    metric_col_titles=[col.replace(\" \", \"\\n\") for col in metric_col_titles_sample_integration], # category_col_titles_sample_integration\n",
    "    metric_col_width=1.1, # 0.8,\n",
    "    plot_width=11, # 32,\n",
    "    plot_height=5,\n",
    "    show=True,\n",
    "    save_dir=benchmarking_folder_path,\n",
    "    save_name=f\"benchmarking_metrics_nanostring_cosmx_human_nsclc_subsample_10pct_run2.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24175d99-fac0-436a-a1d9-a8f79197b93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supplementary fig. 14: 10 pct subsample comparison NC vs STACI vs GraphST variations vs CellCharter vs BANKSY ###\n",
    "datasets = [\"nanostring_cosmx_human_nsclc_subsample_10pct\"]\n",
    "models = [\"nichecompass_gatv2conv_fov\",\n",
    "          \"nichecompass_gatv2conv\",\n",
    "          \"nichecompass_gcnconv_fov\",\n",
    "          \"nichecompass_gcnconv\",\n",
    "          \"staci\",\n",
    "          \"graphst_paste\",\n",
    "          \"graphst\",\n",
    "          \"cellcharter\",\n",
    "          \"banksy\"]\n",
    "\n",
    "summary_df = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    dataset_df = pd.DataFrame()\n",
    "    for model in models:\n",
    "        try:\n",
    "            benchmark_df = pd.read_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\")\n",
    "            #adata = sc.read_h5ad(f\"../../artifacts/single_sample_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "            #training_durations = []\n",
    "            #for run_number in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "            #    training_durations.append(adata.uns[f\"{model.split('_')[0]}_model_training_duration_run{run_number}\"])\n",
    "            #benchmark_df[\"run_time\"] = training_durations\n",
    "            #benchmark_df = benchmark_df[[\"dataset\", \"run_number\", \"run_time\", \"gcs\", \"mlami\", \"cas\", \"clisis\", \"nasw\", \"cnmi\", \"cari\", \"casw\", \"clisi\"]]\n",
    "            #benchmark_df.to_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\", index=False)\n",
    "            benchmark_df[\"model\"] = model\n",
    "            dataset_df = pd.concat([dataset_df, benchmark_df], ignore_index=True)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Did not find file {benchmarking_folder_path}/{dataset}_{model}_metrics.csv. Continuing...\")\n",
    "            missing_run_data = {\n",
    "                \"dataset\": [dataset] * 8,\n",
    "                \"model\": [model] * 8,\n",
    "                \"run_number\": [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "                \"run_time\": [np.nan] * 8\n",
    "            }\n",
    "            missing_run_df = pd.DataFrame(missing_run_data)\n",
    "            dataset_df = pd.concat([dataset_df, missing_run_df], ignore_index=True)\n",
    "            \n",
    "    # Apply min-max scaling to metric columns\n",
    "    for i in range(len(metric_cols_sample_integration)):\n",
    "        min_val = dataset_df[metric_cols_sample_integration[i]].min()\n",
    "        max_val = dataset_df[metric_cols_sample_integration[i]].max()\n",
    "        dataset_df[metric_cols_sample_integration[i] + \"_scaled\"] = ((\n",
    "            dataset_df[metric_cols_sample_integration[i]] - min_val) / (max_val - min_val))\n",
    "\n",
    "    summary_df = pd.concat([summary_df, dataset_df], ignore_index=True)\n",
    "    continue\n",
    "    \n",
    "summary_df['pcr'] = summary_df['pcr'].fillna(0)\n",
    "summary_df['pcr_scaled'] = summary_df['pcr_scaled'].fillna(0)\n",
    "            \n",
    "cat_0_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_sample_integration[0:2]]\n",
    "cat_1_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_sample_integration[2:4]]\n",
    "cat_2_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_sample_integration[4:6]]\n",
    "cat_3_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_sample_integration[6:8]]\n",
    "    \n",
    "summary_df[category_cols_sample_integration[0]] = np.average(summary_df[cat_0_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_sample_integration[0:2],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_sample_integration[1]] = np.average(summary_df[cat_1_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_sample_integration[2:4],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_sample_integration[2]] = np.average(summary_df[cat_2_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_sample_integration[4:6],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_sample_integration[3]] = np.average(summary_df[cat_3_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_sample_integration[6:8],\n",
    "                                                        axis=1)\n",
    "summary_df[\"Overall Score\"] = np.average(summary_df[category_cols_sample_integration[:4]],\n",
    "                                         weights=category_col_weights_sample_integration[:4],\n",
    "                                         axis=1)\n",
    " \n",
    "# Reformat for plot\n",
    "summary_df.replace({\"nichecompass_gatv2conv_fov\": \"NicheCompass\",\n",
    "                    \"nichecompass_gatv2conv\": \"NicheCompass (No FoV Embedding)\",\n",
    "                    \"nichecompass_gcnconv_fov\": \"NicheCompass Light\",\n",
    "                    \"nichecompass_gcnconv\": \"NicheCompass Light (No FoV Embedding)\",\n",
    "                    \"staci\": \"STACI\",\n",
    "                    \"graphst_paste\": \"GraphST\",\n",
    "                    \"graphst\": \"GraphST (No Prior Alignment)\",\n",
    "                    \"cellcharter\": \"CellCharter\",\n",
    "                    \"banksy\": \"BANKSY\"}, inplace=True)\n",
    "\n",
    "summary_df = summary_df[(summary_df[\"run_number\"] == 2) & (summary_df[\"model\"] != \"STACI\") |\n",
    "                        (summary_df[\"run_number\"] == 1) & (summary_df[\"model\"] == \"STACI\")]\n",
    "\n",
    "summary_df['pcr'] = summary_df['pcr'].fillna(0)\n",
    "\n",
    "# Plot over all loss weights combinations\n",
    "# Prepare metrics table plot\n",
    "group_cols = [\"dataset\", \"model\"]\n",
    "aggregate_df = summary_df.groupby(group_cols).mean(\"Overall Score\").sort_values(\"Overall Score\", ascending=False)[\n",
    "    metric_cols_sample_integration + [\"Overall Score\"]].reset_index()\n",
    "\n",
    "unrolled_df = pd.melt(aggregate_df, \n",
    "   id_vars=group_cols,\n",
    "   value_vars=metric_cols_sample_integration + [\"Overall Score\"], # metric_cols_sample_integration, category_cols_sample_integration\n",
    "   var_name=\"score_type\", \n",
    "   value_name=\"score\")\n",
    "\n",
    "# Create spatial indicator column\n",
    "def is_spatially_aware_model(row):\n",
    "    if row[\"model\"] in [\"NicheCompass\",\n",
    "                        \"NicheCompass (No FoV Embedding)\",\n",
    "                        \"NicheCompass Light\",\n",
    "                        \"NicheCompass Light (No FoV Embedding)\",\n",
    "                        \"GraphST\",\n",
    "                        \"GraphST (No Prior Alignment)\",\n",
    "                        \"CellCharter\"]:\n",
    "        return True\n",
    "    return False\n",
    "unrolled_df[\"spatially_aware\"] = unrolled_df.apply(lambda row: is_spatially_aware_model(row), axis=1)\n",
    "unrolled_df = unrolled_df[[\"dataset\", \"spatially_aware\", \"model\", \"score_type\", \"score\"]]\n",
    "\n",
    "# Order datasets\n",
    "unrolled_df[\"dataset\"] = pd.Categorical(unrolled_df[\"dataset\"], categories=datasets, ordered=True)\n",
    "unrolled_df = unrolled_df.sort_values(by=\"dataset\")\n",
    "\n",
    "#print(summary_df[\"model\"].value_counts())\n",
    "#print(summary_df[summary_df.isna().any(axis=1)])\n",
    "\n",
    "summary_df[\"model\"] = summary_df[\"model\"].replace(\"NicheCompass GCN\", \"NicheCompass Light\")\n",
    "summary_df[\"model\"] = summary_df[\"model\"].replace(\"NicheCompass GATv2\", \"NicheCompass\")\n",
    "\n",
    "summary_df[\"dataset\"] = summary_df[\"dataset\"].replace(\n",
    "    {\"nanostring_cosmx_human_nsclc_subsample_10pct\": \"nanoString CosMx Human NSCLC\"})\n",
    "\n",
    "# Plot table\n",
    "plot_simple_metrics_table(\n",
    "    df=unrolled_df,\n",
    "    model_col=\"model\",\n",
    "    model_col_width=5.5,\n",
    "    group_col=\"dataset\",\n",
    "    metric_cols=metric_cols_sample_integration, # metric_cols_sample_integration, category_cols_sample_integration\n",
    "    metric_col_weights=metric_col_weights_sample_integration, # metric_col_weights_sample_integration, category_col_weights_sample_integration\n",
    "    metric_col_titles=[col.replace(\" \", \"\\n\") for col in metric_col_titles_sample_integration], # category_col_titles_sample_integration\n",
    "    metric_col_width=1.1, # 0.8,\n",
    "    plot_width=14, # 32,\n",
    "    plot_height=8,\n",
    "    show=True,\n",
    "    save_dir=benchmarking_folder_path,\n",
    "    save_name=f\"benchmarking_metrics_nanostring_cosmx_human_nsclc_subsample_10pct_run2_supplement.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7419aa0c-ecc1-4f89-97b6-c40c4b8d842e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metrics\n",
    "datasets = [\"nanostring_cosmx_human_nsclc\",\n",
    "            \"nanostring_cosmx_human_nsclc_subsample_50pct\",\n",
    "            \"nanostring_cosmx_human_nsclc_subsample_25pct\",\n",
    "            \"nanostring_cosmx_human_nsclc_subsample_10pct\",\n",
    "            \"nanostring_cosmx_human_nsclc_subsample_5pct\",\n",
    "            \"nanostring_cosmx_human_nsclc_subsample_1pct\"]\n",
    "models = [\"nichecompass_gatv2conv\",\n",
    "          \"nichecompass_gcnconv\",\n",
    "          \"staci\",\n",
    "          \"graphst_paste\",\n",
    "          \"graphst\",\n",
    "          \"cellcharter\",\n",
    "          \"banksy\"]\n",
    "\n",
    "summary_df = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    dataset_df = pd.DataFrame()\n",
    "    for model in models:\n",
    "        try:\n",
    "            benchmark_df = pd.read_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\")\n",
    "            #adata = sc.read_h5ad(f\"../../artifacts/single_sample_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "            #training_durations = []\n",
    "            #for run_number in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "            #    training_durations.append(adata.uns[f\"{model.split('_')[0]}_model_training_duration_run{run_number}\"])\n",
    "            #benchmark_df[\"run_time\"] = training_durations\n",
    "            #benchmark_df = benchmark_df[[\"dataset\", \"run_number\", \"run_time\", \"gcs\", \"mlami\", \"cas\", \"clisis\", \"nasw\", \"cnmi\", \"cari\", \"casw\", \"clisi\"]]\n",
    "            #benchmark_df.to_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\", index=False)\n",
    "            benchmark_df[\"model\"] = model\n",
    "            dataset_df = pd.concat([dataset_df, benchmark_df], ignore_index=True)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Did not find file {benchmarking_folder_path}/{dataset}_{model}_metrics.csv. Continuing...\")\n",
    "            missing_run_data = {\n",
    "                \"dataset\": [dataset] * 8,\n",
    "                \"model\": [model] * 8,\n",
    "                \"run_number\": [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "                \"run_time\": [np.nan] * 8\n",
    "            }\n",
    "            missing_run_df = pd.DataFrame(missing_run_data)\n",
    "            dataset_df = dataset_df = pd.concat([dataset_df, missing_run_df], ignore_index=True)\n",
    "            \n",
    "    # Apply min-max scaling to metric columns\n",
    "    for i in range(len(metric_cols_sample_integration)):\n",
    "        min_val = dataset_df[metric_cols_sample_integration[i]].min()\n",
    "        max_val = dataset_df[metric_cols_sample_integration[i]].max()\n",
    "        dataset_df[metric_cols_sample_integration[i] + \"_scaled\"] = ((\n",
    "            dataset_df[metric_cols_sample_integration[i]] - min_val) / (max_val - min_val))\n",
    "\n",
    "    summary_df = pd.concat([summary_df, dataset_df], ignore_index=True)\n",
    "    continue\n",
    "\n",
    "summary_df['pcr'] = summary_df['pcr'].fillna(0)\n",
    "summary_df['pcr_scaled'] = summary_df['pcr_scaled'].fillna(0)\n",
    "    \n",
    "cat_0_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_sample_integration[0:2]]\n",
    "cat_1_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_sample_integration[2:4]]\n",
    "cat_2_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_sample_integration[4:6]]\n",
    "cat_3_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_sample_integration[6:8]]\n",
    "    \n",
    "summary_df[category_cols_sample_integration[0]] = np.average(summary_df[cat_0_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_sample_integration[0:2],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_sample_integration[1]] = np.average(summary_df[cat_1_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_sample_integration[2:4],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_sample_integration[2]] = np.average(summary_df[cat_2_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_sample_integration[4:6],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_sample_integration[3]] = np.average(summary_df[cat_3_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_sample_integration[6:8],\n",
    "                                                        axis=1)\n",
    "summary_df[\"Overall Score\"] = np.average(summary_df[category_cols_sample_integration[:4]],\n",
    "                                         weights=category_col_weights_sample_integration[:4],\n",
    "                                         axis=1)\n",
    " \n",
    "# Reformat for plot\n",
    "summary_df.replace({\"nichecompass_gatv2conv\": \"NicheCompass\",\n",
    "                    \"nichecompass_gcnconv\": \"NicheCompass Light\",\n",
    "                    \"staci\": \"STACI\",\n",
    "                    \"graphst_paste\": \"GraphST\",\n",
    "                    \"graphst\": \"GraphST (No Prior Alignment)\",\n",
    "                    \"cellcharter\": \"CellCharter\",\n",
    "                    \"banksy\": \"BANKSY\"}, inplace=True)\n",
    "\n",
    "# Plot over all loss weights combinations\n",
    "# Prepare metrics table plot\n",
    "group_cols = [\"dataset\", \"model\"]\n",
    "aggregate_df = summary_df.groupby(group_cols).mean(\"Overall Score\").sort_values(\"Overall Score\", ascending=False)[\n",
    "    metric_cols_sample_integration + [\"Overall Score\"]].reset_index()\n",
    "\n",
    "unrolled_df = pd.melt(aggregate_df, \n",
    "   id_vars=group_cols,\n",
    "   value_vars=metric_cols_sample_integration + [\"Overall Score\"], # metric_cols_sample_integration, category_cols_sample_integration\n",
    "   var_name=\"score_type\", \n",
    "   value_name=\"score\")\n",
    "\n",
    "# Create spatial indicator column\n",
    "def is_spatially_aware_model(row):\n",
    "    if row[\"model\"] in [\"NicheCompass\", \"NicheCompass Light\", \"GraphST\", \"GraphST (No Prior Alignment)\", \"CellCharter\", \"BANKSY\"]:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "unrolled_df[\"spatially_aware\"] = unrolled_df.apply(lambda row: is_spatially_aware_model(row), axis=1)\n",
    "unrolled_df = unrolled_df[[\"dataset\", \"spatially_aware\", \"model\", \"score_type\", \"score\"]]\n",
    "\n",
    "# Order datasets\n",
    "unrolled_df[\"dataset\"] = pd.Categorical(unrolled_df[\"dataset\"], categories=datasets, ordered=True)\n",
    "unrolled_df = unrolled_df.sort_values(by=\"dataset\")\n",
    "\n",
    "#print(summary_df[\"model\"].value_counts())\n",
    "#print(summary_df[summary_df.isna().any(axis=1)])\n",
    "\n",
    "summary_df[\"model\"] = summary_df[\"model\"].replace(\"NicheCompass GCN\", \"NicheCompass Light\")\n",
    "summary_df[\"model\"] = summary_df[\"model\"].replace(\"NicheCompass GATv2\", \"NicheCompass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44def9f4-2b2d-4177-8ef6-bb4d8d58d6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supplementary figure: scalability ###\n",
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 \"GraphST (No Prior Alignment)\": \"#b5bd61\",\n",
    "                 \"CellCharter\": \"#F46AA2\",\n",
    "                 \"BANKSY\": \"#556B2F\"}\n",
    "\n",
    "run_time_mean_df = summary_df.groupby([\"dataset\", \"model\"])[[\"run_time\"]].mean().reset_index()\n",
    "run_time_mean_df[\"run_time\"] = run_time_mean_df[\"run_time\"] / 60\n",
    "\n",
    "def create_dataset_share_col(row):\n",
    "    if row[\"dataset\"] == \"nanostring_cosmx_human_nsclc\":\n",
    "        return 100\n",
    "    elif row[\"dataset\"] == \"nanostring_cosmx_human_nsclc_subsample_50pct\":    \n",
    "        return 50\n",
    "    elif row[\"dataset\"] == \"nanostring_cosmx_human_nsclc_subsample_25pct\":    \n",
    "        return 25\n",
    "    elif row[\"dataset\"] == \"nanostring_cosmx_human_nsclc_subsample_10pct\":    \n",
    "        return 10\n",
    "    elif row[\"dataset\"] == \"nanostring_cosmx_human_nsclc_subsample_5pct\":    \n",
    "        return 5\n",
    "    elif row[\"dataset\"] == \"nanostring_cosmx_human_nsclc_subsample_1pct\":    \n",
    "        return 1\n",
    "    \n",
    "run_time_mean_df[\"dataset_share\"] = run_time_mean_df.apply(lambda row: create_dataset_share_col(row), axis=1)\n",
    "\n",
    "with sns.axes_style(\"ticks\"):\n",
    "    ax = sns.lineplot(data=run_time_mean_df,\n",
    "                      x=\"dataset_share\",\n",
    "                      y=\"run_time\",\n",
    "                      hue=\"model\",\n",
    "                      marker='o',\n",
    "                      palette=model_palette)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    plt.title(\"nanoString CosMx Human NSCLC\\n(232,671 Cells; 960 Genes)\")\n",
    "    plt.ylabel(\"Run Time (Minutes)\")\n",
    "    plt.xlabel(\"Dataset Size (%)\")\n",
    "    custom_y_ticks = [1, 10, 60, 180, 360, 720, 1440]  # Adjust the tick positions as needed\n",
    "    plt.yscale(\"log\")\n",
    "    plt.yticks(custom_y_ticks, custom_y_ticks)\n",
    "    legend = plt.gca().get_legend()\n",
    "    for handle in legend.legendHandles:\n",
    "        handle.set_linewidth(4.0)  # Adjust the size as needed\n",
    "    handles, labels = legend.legendHandles, [text.get_text() for text in legend.get_texts()]\n",
    "    order = [1, 2, 0]\n",
    "    ordered_handles = [handles[i] for i in order]\n",
    "    ordered_labels = [labels[i] for i in order]\n",
    "    plt.legend(ordered_handles, ordered_labels)\n",
    "    ax = plt.gca()\n",
    "    ax.legend().set_visible(False)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(benchmarking_folder_path + \"/benchmarking_runtimes_nanostring_cosmx_human_nsclc.svg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b2447e-015d-4ec1-aeef-435cb307bcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supplementary fig. 16b: sample integration metric averages ###\n",
    "# Define the custom sort order\n",
    "custom_order = [\"NicheCompass\", \"NicheCompass Light\", \"BANKSY\", \"CellCharter\", \"STACI\", \"GraphST\", \"GraphST (No Prior Alignment)\"]\n",
    "\n",
    "# Convert the 'category' column to a categorical data type with the custom order\n",
    "unrolled_df['model'] = pd.Categorical(unrolled_df['model'], categories=custom_order, ordered=True)\n",
    "\n",
    "# Sort the DataFrame based on the 'category' column\n",
    "unrolled_df = unrolled_df.sort_values(['dataset', 'model'])\n",
    "\n",
    "plot_metrics_table(\n",
    "    df=unrolled_df,\n",
    "    model_col=\"model\",\n",
    "    model_col_width=3,\n",
    "    group_col=\"dataset\",\n",
    "    metric_cols=metric_cols_sample_integration, # metric_cols_sample_integration, category_cols_sample_integration\n",
    "    metric_col_weights=metric_col_weights_sample_integration, # metric_col_weights_sample_integration, category_col_weights_sample_integration\n",
    "    metric_col_titles=[col.replace(\" \", \"\\n\") for col in metric_col_titles_sample_integration], # category_col_titles_sample_integration\n",
    "    metric_col_width=0.5, # 0.8,\n",
    "    aggregate_col_width=0.8,\n",
    "    plot_width=43.5, # 32,\n",
    "    plot_height=6,\n",
    "    show=True,\n",
    "    save_dir=benchmarking_folder_path,\n",
    "    save_name=f\"benchmarking_metrics_nanostring_cosmx_human_nsclc.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5152ed58-b8ed-4ef7-9933-07ab65607937",
   "metadata": {},
   "source": [
    "#### 2.1.2 seqFISH Mouse Organogenesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5293104-06d8-483c-a7fb-34eedc9d2b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metrics\n",
    "datasets = [\"seqfish_mouse_organogenesis\",\n",
    "            \"seqfish_mouse_organogenesis_subsample_50pct\",\n",
    "            \"seqfish_mouse_organogenesis_subsample_25pct\",\n",
    "            \"seqfish_mouse_organogenesis_subsample_10pct\",\n",
    "            \"seqfish_mouse_organogenesis_subsample_5pct\",\n",
    "            \"seqfish_mouse_organogenesis_subsample_1pct\"]\n",
    "models = [\"nichecompass_gatv2conv\",\n",
    "          \"nichecompass_gcnconv\",\n",
    "          \"staci\",\n",
    "          \"graphst_paste\",\n",
    "          \"graphst\",\n",
    "          \"cellcharter\",\n",
    "          \"banksy\"]\n",
    "\n",
    "summary_df = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    dataset_df = pd.DataFrame()\n",
    "    for model in models:\n",
    "        try:\n",
    "            benchmark_df = pd.read_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\")\n",
    "            #adata = sc.read_h5ad(f\"../../artifacts/single_sample_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "            #training_durations = []\n",
    "            #for run_number in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "            #    training_durations.append(adata.uns[f\"{model.split('_')[0]}_model_training_duration_run{run_number}\"])\n",
    "            #benchmark_df[\"run_time\"] = training_durations\n",
    "            #benchmark_df = benchmark_df[[\"dataset\", \"run_number\", \"run_time\", \"gcs\", \"mlami\", \"cas\", \"clisis\", \"nasw\", \"cnmi\", \"cari\", \"casw\", \"clisi\"]]\n",
    "            #benchmark_df.to_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\", index=False)\n",
    "            benchmark_df[\"model\"] = model\n",
    "            dataset_df = pd.concat([dataset_df, benchmark_df], ignore_index=True)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Did not find file {benchmarking_folder_path}/{dataset}_{model}_metrics.csv. Continuing...\")\n",
    "            missing_run_data = {\n",
    "                \"dataset\": [dataset] * 8,\n",
    "                \"model\": [model] * 8,\n",
    "                \"run_number\": [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "                \"run_time\": [np.nan] * 8\n",
    "            }\n",
    "            missing_run_df = pd.DataFrame(missing_run_data)\n",
    "            dataset_df = pd.concat([dataset_df, missing_run_df], ignore_index=True)\n",
    "            \n",
    "    # Apply min-max scaling to metric columns\n",
    "    for i in range(len(metric_cols_sample_integration)):\n",
    "        min_val = dataset_df[metric_cols_sample_integration[i]].min()\n",
    "        max_val = dataset_df[metric_cols_sample_integration[i]].max()\n",
    "        dataset_df[metric_cols_sample_integration[i] + \"_scaled\"] = ((\n",
    "            dataset_df[metric_cols_sample_integration[i]] - min_val) / (max_val - min_val))\n",
    "\n",
    "    summary_df = pd.concat([summary_df, dataset_df], ignore_index=True)\n",
    "    continue\n",
    "    \n",
    "summary_df['pcr'] = summary_df['pcr'].fillna(0)\n",
    "summary_df['pcr_scaled'] = summary_df['pcr_scaled'].fillna(0)\n",
    "            \n",
    "cat_0_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_sample_integration[0:2]]\n",
    "cat_1_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_sample_integration[2:4]]\n",
    "cat_2_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_sample_integration[4:6]]\n",
    "cat_3_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_sample_integration[6:8]]\n",
    "    \n",
    "summary_df[category_cols_sample_integration[0]] = np.average(summary_df[cat_0_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_sample_integration[0:2],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_sample_integration[1]] = np.average(summary_df[cat_1_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_sample_integration[2:4],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_sample_integration[2]] = np.average(summary_df[cat_2_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_sample_integration[4:6],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_sample_integration[3]] = np.average(summary_df[cat_3_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_sample_integration[6:8],\n",
    "                                                        axis=1)\n",
    "summary_df[\"Overall Score\"] = np.average(summary_df[category_cols_sample_integration[:4]],\n",
    "                                         weights=category_col_weights_sample_integration[:4],\n",
    "                                         axis=1)\n",
    " \n",
    "# Reformat for plot\n",
    "summary_df.replace({\"nichecompass_gatv2conv\": \"NicheCompass\",\n",
    "                    \"nichecompass_gcnconv\": \"NicheCompass Light\",\n",
    "                    \"staci\": \"STACI\",\n",
    "                    \"graphst_paste\": \"GraphST\",\n",
    "                    \"graphst\": \"GraphST (No Prior Alignment)\",\n",
    "                    \"cellcharter\": \"CellCharter\",\n",
    "                    \"banksy\": \"BANKSY\"}, inplace=True)\n",
    "\n",
    "# Plot over all loss weights combinations\n",
    "# Prepare metrics table plot\n",
    "group_cols = [\"dataset\", \"model\"]\n",
    "aggregate_df = summary_df.groupby(group_cols).mean(\"Overall Score\").sort_values(\"Overall Score\", ascending=False)[\n",
    "    metric_cols_sample_integration + [\"Overall Score\"]].reset_index()\n",
    "\n",
    "unrolled_df = pd.melt(aggregate_df, \n",
    "   id_vars=group_cols,\n",
    "   value_vars=metric_cols_sample_integration + [\"Overall Score\"], # metric_cols_sample_integration, category_cols_sample_integration\n",
    "   var_name=\"score_type\", \n",
    "   value_name=\"score\")\n",
    "\n",
    "# Create spatial indicator column\n",
    "def is_spatially_aware_model(row):\n",
    "    if row[\"model\"] in [\"NicheCompass\", \"NicheCompass Light\", \"GraphST\", \"GraphST (No Prior Alignment)\", \"BANKSY\"]:\n",
    "        return True\n",
    "    return False\n",
    "unrolled_df[\"spatially_aware\"] = unrolled_df.apply(lambda row: is_spatially_aware_model(row), axis=1)\n",
    "unrolled_df = unrolled_df[[\"dataset\", \"spatially_aware\", \"model\", \"score_type\", \"score\"]]\n",
    "\n",
    "# Order datasets\n",
    "unrolled_df[\"dataset\"] = pd.Categorical(unrolled_df[\"dataset\"], categories=datasets, ordered=True)\n",
    "unrolled_df = unrolled_df.sort_values(by=\"dataset\")\n",
    "\n",
    "#print(summary_df[\"model\"].value_counts())\n",
    "#print(summary_df[summary_df.isna().any(axis=1)])\n",
    "\n",
    "summary_df[\"model\"] = summary_df[\"model\"].replace(\"NicheCompass GCN\", \"NicheCompass Light\")\n",
    "summary_df[\"model\"] = summary_df[\"model\"].replace(\"NicheCompass GATv2\", \"NicheCompass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155b01fd-3785-4a67-9c6f-557392f0d6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supplementary fig. 17: sample integration runtimes ###\n",
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 \"GraphST (No Prior Alignment)\": \"#b5bd61\",\n",
    "                 \"CellCharter\": \"#F46AA2\",\n",
    "                 \"BANKSY\": \"#556B2F\"}\n",
    "\n",
    "run_time_mean_df = summary_df.groupby([\"dataset\", \"model\"])[[\"run_time\"]].mean().reset_index()\n",
    "run_time_mean_df[\"run_time\"] = run_time_mean_df[\"run_time\"] / 60\n",
    "\n",
    "def create_dataset_share_col(row):\n",
    "    if row[\"dataset\"] == \"seqfish_mouse_organogenesis\":\n",
    "        return 100\n",
    "    elif row[\"dataset\"] == \"seqfish_mouse_organogenesis_subsample_50pct\":    \n",
    "        return 50\n",
    "    elif row[\"dataset\"] == \"seqfish_mouse_organogenesis_subsample_25pct\":    \n",
    "        return 25\n",
    "    elif row[\"dataset\"] == \"seqfish_mouse_organogenesis_subsample_10pct\":    \n",
    "        return 10\n",
    "    elif row[\"dataset\"] == \"seqfish_mouse_organogenesis_subsample_5pct\":    \n",
    "        return 5\n",
    "    elif row[\"dataset\"] == \"seqfish_mouse_organogenesis_subsample_1pct\":    \n",
    "        return 1\n",
    "    \n",
    "run_time_mean_df[\"dataset_share\"] = run_time_mean_df.apply(lambda row: create_dataset_share_col(row), axis=1)\n",
    "\n",
    "with sns.axes_style(\"ticks\"):\n",
    "    ax = sns.lineplot(data=run_time_mean_df,\n",
    "                      x=\"dataset_share\",\n",
    "                      y=\"run_time\",\n",
    "                      hue=\"model\",\n",
    "                      marker='o',\n",
    "                      palette=model_palette)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    plt.title(\"seqFISH Mouse Organogenesis\\n(57,536 Cells; 351 Genes)\")\n",
    "    plt.ylabel(\"Run Time (Minutes)\")\n",
    "    plt.xlabel(\"Dataset Size (%)\")\n",
    "    custom_y_ticks = [1, 10, 60, 180, 360, 720, 1440]  # Adjust the tick positions as needed\n",
    "    plt.yscale(\"log\")\n",
    "    plt.yticks(custom_y_ticks, custom_y_ticks)\n",
    "    legend = plt.gca().get_legend()\n",
    "    for handle in legend.legendHandles:\n",
    "        handle.set_linewidth(4.0)  # Adjust the size as needed\n",
    "    handles, labels = legend.legendHandles, [text.get_text() for text in legend.get_texts()]\n",
    "    order = [1, 2, 0]\n",
    "    ordered_handles = [handles[i] for i in order]\n",
    "    ordered_labels = [labels[i] for i in order]\n",
    "    plt.legend(ordered_handles, ordered_labels)\n",
    "    ax = plt.gca()\n",
    "    ax.legend().set_visible(False)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(benchmarking_folder_path + \"/benchmarking_runtimes_seqfish_mouse_organogenesis.svg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61714b40-c7b7-4827-b5fa-d101961b4f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supplementary fig. 16b: sample integration metric averages ###\n",
    "plot_metrics_table(\n",
    "    df=unrolled_df,\n",
    "    model_col=\"model\",\n",
    "    model_col_width=3,\n",
    "    group_col=\"dataset\",\n",
    "    metric_cols=metric_cols_sample_integration, # metric_cols_sample_integration, category_cols_sample_integration\n",
    "    metric_col_weights=metric_col_weights_sample_integration, # metric_col_weights_sample_integration, category_col_weights_sample_integration\n",
    "    metric_col_titles=[col.replace(\" \", \"\\n\") for col in metric_col_titles_sample_integration], # category_col_titles_sample_integration\n",
    "    metric_col_width=0.5, # 0.8,\n",
    "    aggregate_col_width=0.8,\n",
    "    plot_width=43.5, # 32,\n",
    "    plot_height=6,\n",
    "    show=True,\n",
    "    save_dir=benchmarking_folder_path,\n",
    "    save_name=f\"benchmarking_metrics_seqfish_mouse_organogenesis.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e65c11-d87a-44ce-ba69-d91ae5211926",
   "metadata": {},
   "source": [
    "#### 2.1.3 seqFISH Mouse Organogenesis Imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52393cad-57a6-4929-a1a0-155706148f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"seqfish_mouse_organogenesis_imputed\",\n",
    "            \"seqfish_mouse_organogenesis_imputed_subsample_50pct\",\n",
    "            \"seqfish_mouse_organogenesis_imputed_subsample_25pct\",\n",
    "            \"seqfish_mouse_organogenesis_imputed_subsample_10pct\",\n",
    "            \"seqfish_mouse_organogenesis_imputed_subsample_5pct\",\n",
    "            \"seqfish_mouse_organogenesis_imputed_subsample_1pct\"]\n",
    "models = [\"nichecompass_gatv2conv\",\n",
    "          \"nichecompass_gcnconv\",\n",
    "          \"staci\",\n",
    "          \"graphst_paste\",\n",
    "          \"graphst\",\n",
    "          \"cellcharter\",\n",
    "          \"banksy\"]\n",
    "\n",
    "summary_df = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    dataset_df = pd.DataFrame()\n",
    "    for model in models:\n",
    "        try:\n",
    "            benchmark_df = pd.read_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\")\n",
    "            #adata = sc.read_h5ad(f\"../../artifacts/single_sample_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "            #training_durations = []\n",
    "            #for run_number in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "            #    training_durations.append(adata.uns[f\"{model.split('_')[0]}_model_training_duration_run{run_number}\"])\n",
    "            #benchmark_df[\"run_time\"] = training_durations\n",
    "            #benchmark_df = benchmark_df[[\"dataset\", \"run_number\", \"run_time\", \"gcs\", \"mlami\", \"cas\", \"clisis\", \"nasw\", \"cnmi\", \"cari\", \"casw\", \"clisi\"]]\n",
    "            #benchmark_df.to_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\", index=False)\n",
    "            benchmark_df[\"model\"] = model\n",
    "            dataset_df = pd.concat([dataset_df, benchmark_df], ignore_index=True)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Did not find file {benchmarking_folder_path}/{dataset}_{model}_metrics.csv. Continuing...\")\n",
    "            missing_run_data = {\n",
    "                \"dataset\": [dataset] * 8,\n",
    "                \"model\": [model] * 8,\n",
    "                \"run_number\": [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "                \"run_time\": [np.nan] * 8\n",
    "            }\n",
    "            missing_run_df = pd.DataFrame(missing_run_data)\n",
    "            dataset_df = pd.concat([dataset_df, missing_run_df], ignore_index=True)\n",
    "            \n",
    "    # Apply min-max scaling to metric columns\n",
    "    for i in range(len(metric_cols_sample_integration)):\n",
    "        min_val = dataset_df[metric_cols_sample_integration[i]].min()\n",
    "        max_val = dataset_df[metric_cols_sample_integration[i]].max()\n",
    "        dataset_df[metric_cols_sample_integration[i] + \"_scaled\"] = ((\n",
    "            dataset_df[metric_cols_sample_integration[i]] - min_val) / (max_val - min_val))\n",
    "\n",
    "    summary_df = pd.concat([summary_df, dataset_df], ignore_index=True)\n",
    "    continue\n",
    "    \n",
    "summary_df['pcr'] = summary_df['pcr'].fillna(0)\n",
    "summary_df['pcr_scaled'] = summary_df['pcr_scaled'].fillna(0)\n",
    "            \n",
    "cat_0_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_sample_integration[0:2]]\n",
    "cat_1_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_sample_integration[2:4]]\n",
    "cat_2_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_sample_integration[4:6]]\n",
    "cat_3_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_sample_integration[6:8]]\n",
    "    \n",
    "summary_df[category_cols_sample_integration[0]] = np.average(summary_df[cat_0_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_sample_integration[0:2],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_sample_integration[1]] = np.average(summary_df[cat_1_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_sample_integration[2:4],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_sample_integration[2]] = np.average(summary_df[cat_2_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_sample_integration[4:6],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_sample_integration[3]] = np.average(summary_df[cat_3_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_sample_integration[6:8],\n",
    "                                                        axis=1)\n",
    "summary_df[\"Overall Score\"] = np.average(summary_df[category_cols_sample_integration[:4]],\n",
    "                                         weights=category_col_weights_sample_integration[:4],\n",
    "                                         axis=1)\n",
    " \n",
    "# Reformat for plot\n",
    "summary_df.replace({\"nichecompass_gatv2conv\": \"NicheCompass\",\n",
    "                    \"nichecompass_gcnconv\": \"NicheCompass Light\",\n",
    "                    \"staci\": \"STACI\",\n",
    "                    \"graphst_paste\": \"GraphST\",\n",
    "                    \"graphst\": \"GraphST (No Prior Alignment)\",\n",
    "                    \"cellcharter\": \"CellCharter\",\n",
    "                    \"banksy\": \"BANKSY\"}, inplace=True)\n",
    "\n",
    "# Plot over all loss weights combinations\n",
    "# Prepare metrics table plot\n",
    "group_cols = [\"dataset\", \"model\"]\n",
    "aggregate_df = summary_df.groupby(group_cols).mean(\"Overall Score\").sort_values(\"Overall Score\", ascending=False)[\n",
    "    metric_cols_sample_integration + [\"Overall Score\"]].reset_index()\n",
    "\n",
    "unrolled_df = pd.melt(aggregate_df, \n",
    "   id_vars=group_cols,\n",
    "   value_vars=metric_cols_sample_integration + [\"Overall Score\"], # metric_cols_sample_integration, category_cols_sample_integration\n",
    "   var_name=\"score_type\", \n",
    "   value_name=\"score\")\n",
    "\n",
    "# Create spatial indicator column\n",
    "def is_spatially_aware_model(row):\n",
    "    if row[\"model\"] in [\"NicheCompass\", \"NicheCompass Light\", \"GraphST\", \"CellCharter\"]:\n",
    "        return True\n",
    "    return False\n",
    "unrolled_df[\"spatially_aware\"] = unrolled_df.apply(lambda row: is_spatially_aware_model(row), axis=1)\n",
    "unrolled_df = unrolled_df[[\"dataset\", \"spatially_aware\", \"model\", \"score_type\", \"score\"]]\n",
    "\n",
    "# Order datasets\n",
    "unrolled_df[\"dataset\"] = pd.Categorical(unrolled_df[\"dataset\"], categories=datasets, ordered=True)\n",
    "unrolled_df = unrolled_df.sort_values(by=\"dataset\")\n",
    "\n",
    "#print(summary_df[\"model\"].value_counts())\n",
    "#print(summary_df[summary_df.isna().any(axis=1)])\n",
    "\n",
    "summary_df[\"model\"] = summary_df[\"model\"].replace(\"NicheCompass GCN\", \"NicheCompass Light\")\n",
    "summary_df[\"model\"] = summary_df[\"model\"].replace(\"NicheCompass GATv2\", \"NicheCompass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5f9d18-1205-4f6b-8481-d9fc2acd924e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supplementary fig. 17: sample integration runtimes ###\n",
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 \"GraphST (No Prior Alignment)\": \"#b5bd61\",\n",
    "                 \"CellCharter\": \"#F46AA2\",\n",
    "                 \"BANKSY\": \"#556B2F\"}\n",
    "\n",
    "run_time_mean_df = summary_df.groupby([\"dataset\", \"model\"])[[\"run_time\"]].mean().reset_index()\n",
    "run_time_mean_df[\"run_time\"] = run_time_mean_df[\"run_time\"] / 60\n",
    "\n",
    "def create_dataset_share_col(row):\n",
    "    if row[\"dataset\"] == \"seqfish_mouse_organogenesis_imputed\":\n",
    "        return 100\n",
    "    elif row[\"dataset\"] == \"seqfish_mouse_organogenesis_imputed_subsample_50pct\":    \n",
    "        return 50\n",
    "    elif row[\"dataset\"] == \"seqfish_mouse_organogenesis_imputed_subsample_25pct\":    \n",
    "        return 25\n",
    "    elif row[\"dataset\"] == \"seqfish_mouse_organogenesis_imputed_subsample_10pct\":    \n",
    "        return 10\n",
    "    elif row[\"dataset\"] == \"seqfish_mouse_organogenesis_imputed_subsample_5pct\":    \n",
    "        return 5\n",
    "    elif row[\"dataset\"] == \"seqfish_mouse_organogenesis_imputed_subsample_1pct\":    \n",
    "        return 1\n",
    "    \n",
    "run_time_mean_df[\"dataset_share\"] = run_time_mean_df.apply(lambda row: create_dataset_share_col(row), axis=1)\n",
    "\n",
    "with sns.axes_style(\"ticks\"):\n",
    "    ax = sns.lineplot(data=run_time_mean_df,\n",
    "                      x=\"dataset_share\",\n",
    "                      y=\"run_time\",\n",
    "                      hue=\"model\",\n",
    "                      marker='o',\n",
    "                      palette=model_palette)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    plt.title(\"seqFISH Mouse Organogenesis (Imputed)\\n(57,536 Cells; 3,000 Genes)\")\n",
    "    plt.ylabel(\"Run Time (Minutes)\")\n",
    "    plt.xlabel(\"Dataset Size (%)\")\n",
    "    custom_y_ticks = [1, 10, 60, 180, 360, 720, 1440]  # Adjust the tick positions as needed\n",
    "    plt.yscale(\"log\")\n",
    "    plt.yticks(custom_y_ticks, custom_y_ticks)\n",
    "    legend = plt.gca().get_legend()\n",
    "    for handle in legend.legendHandles:\n",
    "        handle.set_linewidth(4.0)  # Adjust the size as needed\n",
    "    handles, labels = legend.legendHandles, [text.get_text() for text in legend.get_texts()]\n",
    "    order = [4, 5, 1, 0, 3, 2, 6]\n",
    "    ordered_handles = [handles[i] for i in order]\n",
    "    ordered_labels = [labels[i] for i in order]\n",
    "    lgd = plt.legend(ordered_handles, ordered_labels, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    ax = plt.gca()\n",
    "    #ax.legend().set_visible(False)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(benchmarking_folder_path + \"/benchmarking_runtimes_seqfish_mouse_organogenesis_imputed.svg\", bbox_inches=\"tight\", bbox_extra_artists=[lgd])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebe3955-f16e-44af-bd2c-0629c2a4859d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supplementary fig. 16b: sample integration metric averages ###\n",
    "plot_metrics_table(\n",
    "    df=unrolled_df,\n",
    "    model_col=\"model\",\n",
    "    model_col_width=3,\n",
    "    group_col=\"dataset\",\n",
    "    metric_cols=metric_cols_sample_integration, # metric_cols_sample_integration, category_cols_sample_integration\n",
    "    metric_col_weights=metric_col_weights_sample_integration, # metric_col_weights_sample_integration, category_col_weights_sample_integration\n",
    "    metric_col_titles=[col.replace(\" \", \"\\n\") for col in metric_col_titles_sample_integration], # category_col_titles_sample_integration\n",
    "    metric_col_width=0.5, # 0.8,\n",
    "    aggregate_col_width=0.8,\n",
    "    plot_width=43.5, # 32,\n",
    "    plot_height=6,\n",
    "    show=True,\n",
    "    save_dir=benchmarking_folder_path,\n",
    "    save_name=f\"benchmarking_metrics_seqfish_mouse_organogenesis_imputed.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54669deb-db35-4173-8dd0-5d84ce56e8d5",
   "metadata": {},
   "source": [
    "#### 2.1.4 All Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a0f1dc-20b3-4468-932f-775745c288cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define params for plot formatting\n",
    "fig_width_10_ticks = 8.2\n",
    "fig_width_9_ticks = 7.8\n",
    "fig_width_8_ticks = 7.4\n",
    "fig_width_7_ticks = 7.0\n",
    "fig_width_6_ticks = 6.6\n",
    "fig_width_5_ticks = 6.2\n",
    "fig_width_2_ticks = 5.1\n",
    "fig_width_3_ticks = 5.5\n",
    "fig_width_4_ticks = 5.85\n",
    "fig_height = 6 # 5\n",
    "fontsize = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17e71bc-e9b1-4da4-b2ad-505e59fff776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metrics\n",
    "datasets = [\"seqfish_mouse_organogenesis\",\n",
    "            \"seqfish_mouse_organogenesis_imputed\",\n",
    "            \"nanostring_cosmx_human_nsclc\"]\n",
    "models = [\"nichecompass_gatv2conv\",\n",
    "          \"nichecompass_gcnconv\",\n",
    "          \"staci\",\n",
    "          \"graphst_paste\",\n",
    "          \"cellcharter\",\n",
    "          # \"graphst\",\n",
    "          \"banksy\"\n",
    "         ]\n",
    "\n",
    "summary_df = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    dataset_df = pd.DataFrame()\n",
    "    for model in models:\n",
    "        try:\n",
    "            benchmark_df = pd.read_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\")\n",
    "            #adata = sc.read_h5ad(f\"../../artifacts/single_sample_method_benchmarking/{dataset}_{model}.h5ad\")\n",
    "            #training_durations = []\n",
    "            #for run_number in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "            #    training_durations.append(adata.uns[f\"{model.split('_')[0]}_model_training_duration_run{run_number}\"])\n",
    "            #benchmark_df[\"run_time\"] = training_durations\n",
    "            #benchmark_df = benchmark_df[[\"dataset\", \"run_number\", \"run_time\", \"gcs\", \"mlami\", \"cas\", \"clisis\", \"nasw\", \"cnmi\", \"cari\", \"casw\", \"clisi\"]]\n",
    "            #benchmark_df.to_csv(f\"{benchmarking_folder_path}/{dataset}_{model}_metrics.csv\", index=False)\n",
    "            benchmark_df[\"model\"] = model\n",
    "            dataset_df = pd.concat([dataset_df, benchmark_df], ignore_index=True)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Did not find file {benchmarking_folder_path}/{dataset}_{model}_metrics.csv. Continuing...\")\n",
    "            missing_run_data = {\n",
    "                \"dataset\": [dataset] * 8,\n",
    "                \"model\": [model] * 8,\n",
    "                \"run_number\": [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "                \"run_time\": [np.nan] * 8\n",
    "            }\n",
    "            missing_run_df = pd.DataFrame(missing_run_data)\n",
    "            dataset_df = pd.concat([dataset_df, missing_run_df], ignore_index=True)\n",
    "            \n",
    "    # Apply min-max scaling to metric columns\n",
    "    for i in range(len(metric_cols_sample_integration)):\n",
    "        min_val = dataset_df[metric_cols_sample_integration[i]].min()\n",
    "        max_val = dataset_df[metric_cols_sample_integration[i]].max()\n",
    "        dataset_df[metric_cols_sample_integration[i] + \"_scaled\"] = ((\n",
    "            dataset_df[metric_cols_sample_integration[i]] - min_val) / (max_val - min_val))\n",
    "\n",
    "    summary_df = pd.concat([summary_df, dataset_df], ignore_index=True)\n",
    "    continue\n",
    "            \n",
    "cat_0_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_sample_integration[0:2]]\n",
    "cat_1_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_sample_integration[2:4]]\n",
    "cat_2_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_sample_integration[4:6]]\n",
    "cat_3_scaled_metric_cols = [metric_col + \"_scaled\" for metric_col in metric_cols_sample_integration[6:8]]\n",
    "\n",
    "summary_df['pcr'] = summary_df['pcr'].fillna(0)\n",
    "summary_df['pcr_scaled'] = summary_df['pcr_scaled'].fillna(0)\n",
    "    \n",
    "summary_df[category_cols_sample_integration[0]] = np.average(summary_df[cat_0_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_sample_integration[0:2],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_sample_integration[1]] = np.average(summary_df[cat_1_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_sample_integration[2:4],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_sample_integration[2]] = np.average(summary_df[cat_2_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_sample_integration[4:6],\n",
    "                                                        axis=1)\n",
    "summary_df[category_cols_sample_integration[3]] = np.average(summary_df[cat_3_scaled_metric_cols],\n",
    "                                                        weights=metric_col_weights_sample_integration[6:8],\n",
    "                                                        axis=1)\n",
    "summary_df[\"Overall Score\"] = np.average(summary_df[category_cols_sample_integration[:4]],\n",
    "                                         weights=category_col_weights_sample_integration[:4],\n",
    "                                         axis=1)\n",
    " \n",
    "# Reformat for plot\n",
    "summary_df.replace({\"nichecompass_gatv2conv\": \"NicheCompass\",\n",
    "                    \"nichecompass_gcnconv\": \"NicheCompass Light\",\n",
    "                    \"staci\": \"STACI\",\n",
    "                    \"graphst_paste\": \"GraphST\",\n",
    "                    \"graphst\": \"GraphST (No Prior Alignment)\",\n",
    "                    \"cellcharter\": \"CellCharter\",\n",
    "                    \"banksy\": \"BANKSY\",\n",
    "                   }, inplace=True)\n",
    "\n",
    "# Plot over all loss weights combinations\n",
    "# Prepare metrics table plot\n",
    "group_cols = [\"dataset\", \"model\"]\n",
    "aggregate_df = summary_df.groupby(group_cols).mean(\"Overall Score\").sort_values(\"Overall Score\", ascending=False)[\n",
    "    metric_cols_sample_integration + [\"Overall Score\"]].reset_index()\n",
    "\n",
    "unrolled_df = pd.melt(aggregate_df, \n",
    "   id_vars=group_cols,\n",
    "   value_vars=metric_cols_sample_integration + [\"Overall Score\"], # metric_cols_sample_integration, category_cols_sample_integration\n",
    "   var_name=\"score_type\", \n",
    "   value_name=\"score\")\n",
    "\n",
    "# Create spatial indicator column\n",
    "def is_spatially_aware_model(row):\n",
    "    if row[\"model\"] in [\"NicheCompass GCN\", \"NicheCompass GATv2\", \"DeepLinc\", \"GraphST\", \"CellCharter\"]:\n",
    "        return True\n",
    "    return False\n",
    "unrolled_df[\"spatially_aware\"] = unrolled_df.apply(lambda row: is_spatially_aware_model(row), axis=1)\n",
    "unrolled_df = unrolled_df[[\"dataset\", \"spatially_aware\", \"model\", \"score_type\", \"score\"]]\n",
    "\n",
    "# Order datasets\n",
    "unrolled_df[\"dataset\"] = pd.Categorical(unrolled_df[\"dataset\"], categories=datasets, ordered=True)\n",
    "unrolled_df = unrolled_df.sort_values(by=\"dataset\")\n",
    "\n",
    "#print(summary_df[\"model\"].value_counts())\n",
    "#print(summary_df[summary_df.isna().any(axis=1)])\n",
    "\n",
    "summary_df[\"model\"] = summary_df[\"model\"].replace(\"NicheCompass GCN\", \"NicheCompass Light\")\n",
    "summary_df[\"model\"] = summary_df[\"model\"].replace(\"NicheCompass GATv2\", \"NicheCompass\")\n",
    "\n",
    "summary_df[\"dataset\"] = summary_df[\"dataset\"].replace(\n",
    "    {\"seqfish_mouse_organogenesis\": \"seqFISH Mouse Organogenesis\",\n",
    "     \"seqfish_mouse_organogenesis_imputed\": \"seqFISH Mouse Organogenesis (Imputed)\",\n",
    "     \"nanostring_cosmx_human_nsclc\": \"nanoString CosMx Human NSCLC\"})"
   ]
  },
  {
   "cell_type": "raw",
   "id": "800abdae-cc41-4d5a-9a17-ced1458f0247",
   "metadata": {},
   "source": [
    "metric = \"cas\"\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 #\"GraphST (No Prior Alignment)\": \"#b5bd61\",\n",
    "                 \"CellCharter\": \"#F46AA2\",\n",
    "                 \"BANKSY\": \"#556B2F\"}\n",
    "\n",
    "plt.figure(figsize=(fig_width_8_ticks, fig_height))\n",
    "ax = sns.barplot(data=summary_df,\n",
    "                 x=metric,\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette\n",
    "                )\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + 1 * i, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(metric.upper(), fontsize=fontsize)\n",
    "plt.yticks(fontsize=row_fontsize)\n",
    "plt.xticks([0., 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7], fontsize=fontsize)\n",
    "plt.xlim(0., 0.8)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_barplot_{metric}_score.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab76f3bc-fd89-41c2-a4b2-84c6612724da",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"cas\"  # Metric to plot\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 #\"GraphST (No Prior Alignment)\": \"#b5bd61\",\n",
    "                 \"CellCharter\": \"#F46AA2\",\n",
    "                 \"BANKSY\": \"#556B2F\"}\n",
    "\n",
    "plt.figure(figsize=(fig_width_8_ticks, fig_height))  # Adjust figure size\n",
    "\n",
    "# Boxplot\n",
    "ax = sns.boxplot(data=summary_df,\n",
    "                 x=metric,  # Use the variable metric for x-axis\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette,\n",
    "                 showcaps=False,  # Hide caps for cleaner look\n",
    "                 fliersize=0,  # Hide individual outlier markers\n",
    "                 boxprops={'alpha': 0.6},  # Semi-transparent boxes\n",
    "                 whiskerprops={'linewidth': 1.5})  # Thicker whiskers\n",
    "\n",
    "# Add horizontal lines between categories\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + i, color='gray', linestyle='--', linewidth=2, zorder=0)\n",
    "\n",
    "# Overlay with individual points\n",
    "sns.stripplot(data=summary_df,\n",
    "              x=metric,  # Use the variable metric for x-axis\n",
    "              y=\"dataset\",\n",
    "              hue=\"model\",\n",
    "              dodge=True,\n",
    "              palette=model_palette,\n",
    "              alpha=0.6,  # Transparent points\n",
    "              size=5,  # Adjust dot size\n",
    "              jitter=0.2,  # Slight jitter for better separation\n",
    "              edgecolor=\"black\",  # Add edge color\n",
    "              linewidth=0.5)\n",
    "\n",
    "# Add gridlines\n",
    "ax.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adjust legend to avoid duplication\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[:len(model_palette)], labels[:len(model_palette)],\n",
    "          loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Adjust axes and labels\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(metric.upper(), fontsize=fontsize)  # Convert metric name to uppercase\n",
    "plt.yticks(fontsize=fontsize)\n",
    "plt.xticks(fontsize=fontsize)  # Adjust ticks\n",
    "plt.xlim(0., 0.8)  # Set range to [0., 0.8]\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_boxplot_{metric}_score.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a4718cdb-1834-47cb-a2c5-e7a5310d47a9",
   "metadata": {},
   "source": [
    "metric = \"mlami\"\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 #\"GraphST (No Prior Alignment)\": \"#b5bd61\",\n",
    "                 \"CellCharter\": \"#F46AA2\",\n",
    "                 \"BANKSY\": \"#556B2F\"}\n",
    "\n",
    "plt.figure(figsize=(fig_width_7_ticks, fig_height))\n",
    "ax = sns.barplot(data=summary_df,\n",
    "                 x=metric,\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette\n",
    "                )\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + 1 * i, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(metric.upper(), fontsize=fontsize)\n",
    "plt.yticks(fontsize=row_fontsize)\n",
    "plt.xticks([0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8], fontsize=fontsize)\n",
    "plt.xlim(0.2, 0.9)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_barplot_{metric}_score.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a131fa37-8e0b-40f6-b814-540485309516",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"mlami\"  # Metric to plot\n",
    "\n",
    "plt.figure(figsize=(fig_width_7_ticks, fig_height))  # Adjust figure size\n",
    "\n",
    "# Boxplot\n",
    "ax = sns.boxplot(data=summary_df,\n",
    "                 x=metric,  # Use the variable metric for x-axis\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette,\n",
    "                 showcaps=False,  # Hide caps for cleaner look\n",
    "                 fliersize=0,  # Hide individual outlier markers\n",
    "                 boxprops={'alpha': 0.6},  # Semi-transparent boxes\n",
    "                 whiskerprops={'linewidth': 1.5})  # Thicker whiskers\n",
    "\n",
    "# Add horizontal lines between categories\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + i, color='gray', linestyle='--', linewidth=2, zorder=0)\n",
    "\n",
    "# Overlay with individual points\n",
    "sns.stripplot(data=summary_df,\n",
    "              x=metric,  # Use the variable metric for x-axis\n",
    "              y=\"dataset\",\n",
    "              hue=\"model\",\n",
    "              dodge=True,\n",
    "              palette=model_palette,\n",
    "              alpha=0.6,  # Transparent points\n",
    "              size=5,  # Adjust dot size\n",
    "              jitter=0.2,  # Slight jitter for better separation\n",
    "              edgecolor=\"black\",  # Add edge color\n",
    "              linewidth=0.5)\n",
    "\n",
    "# Add gridlines\n",
    "ax.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adjust legend to avoid duplication\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[:len(model_palette)], labels[:len(model_palette)],\n",
    "          loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Adjust axes and labels\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(metric.upper(), fontsize=fontsize)  # Convert metric name to uppercase\n",
    "plt.yticks(fontsize=fontsize)\n",
    "plt.xticks(fontsize=fontsize)  # Adjust ticks for the range\n",
    "plt.xlim(0.2, 0.9)  # Set range to [0.2, 0.9]\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_boxplot_{metric}_score.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4307893-3436-48b6-a53b-f5350fb97560",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df[\"Spatial Consistency Score\"] = (summary_df[\"Global Spatial Consistency Score\"] + summary_df[\"Local Spatial Consistency Score\"])/2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b32a4d79-91df-4e0b-974d-c286b66d6443",
   "metadata": {},
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 #\"GraphST (No Prior Alignment)\": \"#b5bd61\",\n",
    "                 \"CellCharter\": \"#F46AA2\",\n",
    "                 \"BANKSY\": \"#556B2F\"}\n",
    "\n",
    "plt.figure(figsize=(fig_width_9_ticks*0.85, fig_height))\n",
    "ax = sns.barplot(data=summary_df,\n",
    "                 x=\"Spatial Consistency Score\",\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette\n",
    "                )\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + 1 * i, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(\"Spatial Consistency Score\", fontsize=fontsize)\n",
    "plt.yticks(fontsize=row_fontsize)\n",
    "#plt.xticks([0., 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8], fontsize=fontsize)\n",
    "plt.xlim(0., 0.9)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_barplot_spatial_consistency_score.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2da684d-fad9-456a-83f0-7e61168f1da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(fig_width_10_ticks * 0.85, fig_height))  # Adjust figure size\n",
    "\n",
    "# Boxplot\n",
    "ax = sns.boxplot(data=summary_df,\n",
    "                 x=\"Spatial Consistency Score\",  # Use \"Spatial Consistency Score\" as the x-axis metric\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette,\n",
    "                 showcaps=False,  # Hide caps for cleaner look\n",
    "                 fliersize=0,  # Hide individual outlier markers\n",
    "                 boxprops={'alpha': 0.6},  # Semi-transparent boxes\n",
    "                 whiskerprops={'linewidth': 1.5})  # Thicker whiskers\n",
    "\n",
    "# Add horizontal lines between categories\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + i, color='gray', linestyle='--', linewidth=2, zorder=0)\n",
    "\n",
    "# Overlay with individual points\n",
    "sns.stripplot(data=summary_df,\n",
    "              x=\"Spatial Consistency Score\",  # Use \"Spatial Consistency Score\" for the x-axis\n",
    "              y=\"dataset\",\n",
    "              hue=\"model\",\n",
    "              dodge=True,\n",
    "              palette=model_palette,\n",
    "              alpha=0.6,  # Transparent points\n",
    "              size=5,  # Adjust dot size\n",
    "              jitter=0.2,  # Slight jitter for better separation\n",
    "              edgecolor=\"black\",  # Add edge color\n",
    "              linewidth=0.5)\n",
    "\n",
    "# Add gridlines\n",
    "ax.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adjust legend to avoid duplication\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[:len(model_palette)], labels[:len(model_palette)],\n",
    "          loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Adjust axes and labels\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(\"Spatial Consistency Score\", fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "plt.xticks(fontsize=fontsize)  # Adjust ticks for the range\n",
    "plt.xlim(0., 1.0)  # Set range to [0., 0.9]\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_boxplot_spatial_consistency_score.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf4834c-d385-4bcc-9491-efe6c41eb9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"seqFISH Mouse Organogenesis\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"Spatial Consistency Score\"]].mean()\n",
    "metrics_temp_df.loc[\"NicheCompass\"][0] - np.max(metrics_temp_df[~metrics_temp_df.index.isin([\"NicheCompass\", \"NicheCompass Light\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa64f1f-84a5-4fd0-a9ac-4b1e6e71eb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"seqFISH Mouse Organogenesis (Imputed)\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"Spatial Consistency Score\"]].mean()\n",
    "metrics_temp_df.loc[\"NicheCompass\"][0] - np.max(metrics_temp_df[~metrics_temp_df.index.isin([\"NicheCompass\", \"NicheCompass Light\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e242a6b-2106-4581-891b-34c5390c6f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"nanoString CosMx Human NSCLC\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"Spatial Consistency Score\"]].mean()\n",
    "metrics_temp_df.loc[\"NicheCompass\"][0] - np.max(metrics_temp_df[~metrics_temp_df.index.isin([\"NicheCompass\", \"NicheCompass Light\"])])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "efec4fa2-56f0-4bff-98fa-f7cd7674ef57",
   "metadata": {},
   "source": [
    "metric = \"clisis\"\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 #\"GraphST (No Prior Alignment)\": \"#b5bd61\",\n",
    "                 \"CellCharter\": \"#F46AA2\",\n",
    "                 \"BANKSY\": \"#556B2F\"}\n",
    "\n",
    "plt.figure(figsize=(fig_width_4_ticks, fig_height))\n",
    "ax = sns.barplot(data=summary_df,\n",
    "                 x=metric,\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette\n",
    "                )\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + 1 * i, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(metric.upper(), fontsize=fontsize)\n",
    "plt.yticks(fontsize=row_fontsize)\n",
    "plt.xticks([0.6, 0.7, 0.8, 0.9], fontsize=fontsize)\n",
    "plt.xlim(0.6, 1.0)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_barplot_{metric}_score.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aebc6cf-541a-4a7d-9061-6c561bcbdcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"clisis\"  # Metric to plot\n",
    "\n",
    "plt.figure(figsize=(fig_width_5_ticks, fig_height))  # Adjust figure size\n",
    "\n",
    "# Boxplot\n",
    "ax = sns.boxplot(data=summary_df,\n",
    "                 x=metric,  # Use the variable metric for x-axis\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette,\n",
    "                 showcaps=False,  # Hide caps for cleaner look\n",
    "                 fliersize=0,  # Hide individual outlier markers\n",
    "                 boxprops={'alpha': 0.6},  # Semi-transparent boxes\n",
    "                 whiskerprops={'linewidth': 1.5})  # Thicker whiskers\n",
    "\n",
    "# Add horizontal lines between categories\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + i, color='gray', linestyle='--', linewidth=2, zorder=0)\n",
    "\n",
    "# Overlay with individual points\n",
    "sns.stripplot(data=summary_df,\n",
    "              x=metric,  # Use the variable metric for x-axis\n",
    "              y=\"dataset\",\n",
    "              hue=\"model\",\n",
    "              dodge=True,\n",
    "              palette=model_palette,\n",
    "              alpha=0.6,  # Transparent points\n",
    "              size=5,  # Adjust dot size\n",
    "              jitter=0.2,  # Slight jitter for better separation\n",
    "              edgecolor=\"black\",  # Add edge color\n",
    "              linewidth=0.5)\n",
    "\n",
    "# Add gridlines\n",
    "ax.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adjust legend to avoid duplication\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[:len(model_palette)], labels[:len(model_palette)],\n",
    "          loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Adjust axes and labels\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(metric.upper(), fontsize=fontsize)  # Convert metric name to uppercase\n",
    "plt.yticks(fontsize=fontsize)\n",
    "plt.xticks(fontsize=fontsize)  # Adjust ticks for the range\n",
    "plt.xlim(0.6, 1.0)  # Set range to [0.6, 1.0]\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_boxplot_{metric}_score.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "64e4dceb-3a6f-4f2f-859a-69fcd73b166b",
   "metadata": {},
   "source": [
    "metric = \"gcs\"\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 #\"GraphST (No Prior Alignment)\": \"#b5bd61\",\n",
    "                 \"CellCharter\": \"#F46AA2\",\n",
    "                 \"BANKSY\": \"#556B2F\"}\n",
    "\n",
    "plt.figure(figsize=(fig_width_3_ticks, fig_height))\n",
    "ax = sns.barplot(data=summary_df,\n",
    "                 x=metric,\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette\n",
    "                )\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + 1 * i, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(metric.upper(), fontsize=fontsize)\n",
    "plt.yticks(fontsize=row_fontsize)\n",
    "plt.xticks([0.7, 0.8, 0.9], fontsize=fontsize)\n",
    "plt.xlim(0.7, 1.0)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_barplot_{metric}_score.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674b566c-c875-47a5-8662-99ba3b3ccaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"gcs\"  # Metric to plot\n",
    "\n",
    "plt.figure(figsize=(fig_width_4_ticks, fig_height))  # Adjust figure size\n",
    "\n",
    "# Boxplot\n",
    "ax = sns.boxplot(data=summary_df,\n",
    "                 x=metric,  # Use the variable metric for x-axis\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette,\n",
    "                 showcaps=False,  # Hide caps for cleaner look\n",
    "                 fliersize=0,  # Hide individual outlier markers\n",
    "                 boxprops={'alpha': 0.6},  # Semi-transparent boxes\n",
    "                 whiskerprops={'linewidth': 1.5})  # Thicker whiskers\n",
    "\n",
    "# Add horizontal lines between categories\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + i, color='gray', linestyle='--', linewidth=2, zorder=0)\n",
    "\n",
    "# Overlay with individual points\n",
    "sns.stripplot(data=summary_df,\n",
    "              x=metric,  # Use the variable metric for x-axis\n",
    "              y=\"dataset\",\n",
    "              hue=\"model\",\n",
    "              dodge=True,\n",
    "              palette=model_palette,\n",
    "              alpha=0.6,  # Transparent points\n",
    "              size=5,  # Adjust dot size\n",
    "              jitter=0.2,  # Slight jitter for better separation\n",
    "              edgecolor=\"black\",  # Add edge color\n",
    "              linewidth=0.5)\n",
    "\n",
    "# Add gridlines\n",
    "ax.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adjust legend to avoid duplication\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[:len(model_palette)], labels[:len(model_palette)],\n",
    "          loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Adjust axes and labels\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(metric.upper(), fontsize=fontsize)  # Convert metric name to uppercase\n",
    "plt.yticks(fontsize=fontsize)\n",
    "plt.xticks(fontsize=fontsize)  # Adjust ticks for the range\n",
    "plt.xlim(0.7, 1.0)  # Set range to [0.7, 1.0]\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_boxplot_{metric}_score.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cba253ae-51d2-4415-9b1f-f0dde7a61c12",
   "metadata": {},
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 #\"GraphST (No Prior Alignment)\": \"#b5bd61\",\n",
    "                 \"CellCharter\": \"#F46AA2\",\n",
    "                 \"BANKSY\": \"#556B2F\"}\n",
    "\n",
    "plt.figure(figsize=(fig_width_9_ticks*0.85, fig_height))\n",
    "ax = sns.barplot(data=summary_df,\n",
    "                 x=\"Niche Coherence Score\",\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette\n",
    "                )\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + 1 * i, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(\"Niche Coherence Score\", fontsize=fontsize)\n",
    "plt.yticks(fontsize=row_fontsize)\n",
    "#plt.xticks([0., 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], fontsize=fontsize)\n",
    "plt.xlim(0., 1.0)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_barplot_niche_coherence_score.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffc9279-9ce7-42ba-9868-b476a58398d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(fig_width_9_ticks * 0.85, fig_height))  # Adjust figure size\n",
    "\n",
    "# Boxplot\n",
    "ax = sns.boxplot(data=summary_df,\n",
    "                 x=\"Niche Coherence Score\",  # Use \"Niche Coherence Score\" as the x-axis metric\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette,\n",
    "                 showcaps=False,  # Hide caps for cleaner look\n",
    "                 fliersize=0,  # Hide individual outlier markers\n",
    "                 boxprops={'alpha': 0.6},  # Semi-transparent boxes\n",
    "                 whiskerprops={'linewidth': 1.5})  # Thicker whiskers\n",
    "\n",
    "# Add horizontal lines between categories\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + i, color='gray', linestyle='--', linewidth=2, zorder=0)\n",
    "\n",
    "# Overlay with individual points\n",
    "sns.stripplot(data=summary_df,\n",
    "              x=\"Niche Coherence Score\",  # Use \"Niche Coherence Score\" for the x-axis\n",
    "              y=\"dataset\",\n",
    "              hue=\"model\",\n",
    "              dodge=True,\n",
    "              palette=model_palette,\n",
    "              alpha=0.6,  # Transparent points\n",
    "              size=5,  # Adjust dot size\n",
    "              jitter=0.2,  # Slight jitter for better separation\n",
    "              edgecolor=\"black\",  # Add edge color\n",
    "              linewidth=0.5)\n",
    "\n",
    "# Add gridlines\n",
    "ax.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adjust legend to avoid duplication\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[:len(model_palette)], labels[:len(model_palette)],\n",
    "          loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Adjust axes and labels\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(\"Niche Coherence Score\", fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "plt.xticks(fontsize=fontsize)  # Adjust ticks for the range\n",
    "plt.xlim(0., 1.0)  # Set range to [0., 1.0]\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_boxplot_niche_coherence_score.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1507ea8b-e46e-47d5-be22-be163dd6bb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"seqFISH Mouse Organogenesis\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"Niche Coherence Score\"]].mean()\n",
    "metrics_temp_df.loc[\"NicheCompass\"][0] - np.max(metrics_temp_df[~metrics_temp_df.index.isin([\"NicheCompass\", \"NicheCompass Light\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b96c8b-bcf9-41d5-a0a9-15a90ce18a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"seqFISH Mouse Organogenesis (Imputed)\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"Niche Coherence Score\"]].mean()\n",
    "metrics_temp_df.loc[\"NicheCompass\"][0] - np.max(metrics_temp_df[~metrics_temp_df.index.isin([\"NicheCompass\", \"NicheCompass Light\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917b8a0c-b5ee-4dce-8422-2b44f9d92d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"nanoString CosMx Human NSCLC\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"Niche Coherence Score\"]].mean()\n",
    "metrics_temp_df.loc[\"NicheCompass\"][0] - np.max(metrics_temp_df[~metrics_temp_df.index.isin([\"NicheCompass\", \"NicheCompass Light\"])])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b33ff739-5071-45e6-955c-4bd6c783e7f5",
   "metadata": {},
   "source": [
    "metric = \"cnmi\"\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 #\"GraphST (No Prior Alignment)\": \"#b5bd61\",\n",
    "                 \"CellCharter\": \"#F46AA2\",\n",
    "                 \"BANKSY\": \"#556B2F\"}\n",
    "\n",
    "plt.figure(figsize=(fig_width_7_ticks, fig_height))\n",
    "ax = sns.barplot(data=summary_df,\n",
    "                 x=metric,\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette\n",
    "                )\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + 1 * i, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(metric.upper(), fontsize=fontsize)\n",
    "plt.yticks(fontsize=row_fontsize)\n",
    "plt.xticks([0., 0.1, 0.2, 0.3, 0.4, 0.5, 0.6], fontsize=fontsize)\n",
    "plt.xlim(0., 0.7)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_barplot_{metric}_score.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f52f11-84bf-40af-96df-ebbcc14d6a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"cnmi\"  # Metric to plot\n",
    "\n",
    "plt.figure(figsize=(fig_width_7_ticks, fig_height))  # Adjust figure size\n",
    "\n",
    "# Boxplot\n",
    "ax = sns.boxplot(data=summary_df,\n",
    "                 x=metric,  # Use the variable metric for x-axis\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette,\n",
    "                 showcaps=False,  # Hide caps for cleaner look\n",
    "                 fliersize=0,  # Hide individual outlier markers\n",
    "                 boxprops={'alpha': 0.6},  # Semi-transparent boxes\n",
    "                 whiskerprops={'linewidth': 1.5})  # Thicker whiskers\n",
    "\n",
    "# Add horizontal lines between categories\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + i, color='gray', linestyle='--', linewidth=2, zorder=0)\n",
    "\n",
    "# Overlay with individual points\n",
    "sns.stripplot(data=summary_df,\n",
    "              x=metric,  # Use the variable metric for x-axis\n",
    "              y=\"dataset\",\n",
    "              hue=\"model\",\n",
    "              dodge=True,\n",
    "              palette=model_palette,\n",
    "              alpha=0.6,  # Transparent points\n",
    "              size=5,  # Adjust dot size\n",
    "              jitter=0.2,  # Slight jitter for better separation\n",
    "              edgecolor=\"black\",  # Add edge color\n",
    "              linewidth=0.5)\n",
    "\n",
    "# Add gridlines\n",
    "ax.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adjust legend to avoid duplication\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[:len(model_palette)], labels[:len(model_palette)],\n",
    "          loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Adjust axes and labels\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(metric.upper(), fontsize=fontsize)  # Convert metric name to uppercase\n",
    "plt.yticks(fontsize=fontsize)\n",
    "plt.xticks(fontsize=fontsize)  # Adjust ticks for the range\n",
    "plt.xlim(0., 0.7)  # Set range to [0., 0.7]\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_boxplot_{metric}_score.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "275acc5f-5103-4e42-8aa5-62fb19e07551",
   "metadata": {},
   "source": [
    "metric = \"nasw\"\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 #\"GraphST (No Prior Alignment)\": \"#b5bd61\",\n",
    "                 \"CellCharter\": \"#F46AA2\",\n",
    "                 \"BANKSY\": \"#556B2F\"}\n",
    "\n",
    "plt.figure(figsize=(fig_width_3_ticks, fig_height))\n",
    "ax = sns.barplot(data=summary_df,\n",
    "                 x=metric,\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette\n",
    "                )\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + 1 * i, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(metric.upper(), fontsize=fontsize)\n",
    "plt.yticks(fontsize=row_fontsize)\n",
    "plt.xticks([0.4, 0.5, 0.6], fontsize=fontsize)\n",
    "plt.xlim(0.4, 0.7)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_barplot_{metric}_score.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9de844-29f6-4189-a983-c0813beee49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"nasw\"  # Metric to plot\n",
    "\n",
    "plt.figure(figsize=(fig_width_3_ticks, fig_height))  # Adjust figure size\n",
    "\n",
    "# Boxplot\n",
    "ax = sns.boxplot(data=summary_df,\n",
    "                 x=metric,  # Use the variable metric for x-axis\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette,\n",
    "                 showcaps=False,  # Hide caps for cleaner look\n",
    "                 fliersize=0,  # Hide individual outlier markers\n",
    "                 boxprops={'alpha': 0.6},  # Semi-transparent boxes\n",
    "                 whiskerprops={'linewidth': 1.5})  # Thicker whiskers\n",
    "\n",
    "# Add horizontal lines between categories\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + i, color='gray', linestyle='--', linewidth=2, zorder=0)\n",
    "\n",
    "# Overlay with individual points\n",
    "sns.stripplot(data=summary_df,\n",
    "              x=metric,  # Use the variable metric for x-axis\n",
    "              y=\"dataset\",\n",
    "              hue=\"model\",\n",
    "              dodge=True,\n",
    "              palette=model_palette,\n",
    "              alpha=0.6,  # Transparent points\n",
    "              size=5,  # Adjust dot size\n",
    "              jitter=0.2,  # Slight jitter for better separation\n",
    "              edgecolor=\"black\",  # Add edge color\n",
    "              linewidth=0.5)\n",
    "\n",
    "# Add gridlines\n",
    "ax.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adjust legend to avoid duplication\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[:len(model_palette)], labels[:len(model_palette)],\n",
    "          loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Adjust axes and labels\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(metric.upper(), fontsize=fontsize)  # Convert metric name to uppercase\n",
    "plt.yticks(fontsize=fontsize)\n",
    "plt.xticks(fontsize=fontsize)  # Adjust ticks for the range\n",
    "plt.xlim(0.4, 0.7)  # Set range to [0.4, 0.7]\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_boxplot_{metric}_score.svg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8f69d957-c3ed-489a-ae2b-6e341b6f0bec",
   "metadata": {},
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 #\"GraphST (No Prior Alignment)\": \"#b5bd61\",\n",
    "                 \"CellCharter\": \"#F46AA2\",\n",
    "                 \"BANKSY\": \"#556B2F\"}\n",
    "\n",
    "plt.figure(figsize=(fig_width_9_ticks*0.85, fig_height))\n",
    "ax = sns.barplot(data=summary_df,\n",
    "                 x=\"Batch Correction Score\",\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette\n",
    "                )\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + 1 * i, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(\"Batch Correction Score\", fontsize=fontsize)\n",
    "plt.yticks(fontsize=row_fontsize)\n",
    "#plt.xticks([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], fontsize=fontsize)\n",
    "plt.xlim(0., 1.0)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_barplot_batch_correction_score.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acebe4b7-7bee-4cf4-942c-df8d8f385006",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(fig_width_9_ticks * 0.85, fig_height))  # Adjust figure size\n",
    "\n",
    "# Boxplot\n",
    "ax = sns.boxplot(data=summary_df,\n",
    "                 x=\"Batch Correction Score\",  # Use \"Batch Correction Score\" as the x-axis metric\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette,\n",
    "                 showcaps=False,  # Hide caps for cleaner look\n",
    "                 fliersize=0,  # Hide individual outlier markers\n",
    "                 boxprops={'alpha': 0.6},  # Semi-transparent boxes\n",
    "                 whiskerprops={'linewidth': 1.5})  # Thicker whiskers\n",
    "\n",
    "# Add horizontal lines between categories\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + i, color='gray', linestyle='--', linewidth=2, zorder=0)\n",
    "\n",
    "# Overlay with individual points\n",
    "sns.stripplot(data=summary_df,\n",
    "              x=\"Batch Correction Score\",  # Use \"Batch Correction Score\" for the x-axis\n",
    "              y=\"dataset\",\n",
    "              hue=\"model\",\n",
    "              dodge=True,\n",
    "              palette=model_palette,\n",
    "              alpha=0.6,  # Transparent points\n",
    "              size=5,  # Adjust dot size\n",
    "              jitter=0.2,  # Slight jitter for better separation\n",
    "              edgecolor=\"black\",  # Add edge color\n",
    "              linewidth=0.5)\n",
    "\n",
    "# Add gridlines\n",
    "ax.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adjust legend to avoid duplication\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[:len(model_palette)], labels[:len(model_palette)],\n",
    "          loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Adjust axes and labels\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(\"Batch Correction Score\", fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "plt.xticks(fontsize=fontsize)  # Adjust ticks for the range\n",
    "plt.xlim(0., 1.0)  # Set range to [0., 1.0]\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_boxplot_batch_correction_score.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba4ba19-d4b4-4168-bf97-54decbe3e566",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"seqFISH Mouse Organogenesis\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"Batch Correction Score\"]].mean()\n",
    "metrics_temp_df.loc[\"NicheCompass\"][0] - np.max(metrics_temp_df[~metrics_temp_df.index.isin([\"NicheCompass\", \"NicheCompass Light\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5fa2cf-520a-4e99-aa23-3740b8640ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"seqFISH Mouse Organogenesis (Imputed)\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"Batch Correction Score\"]].mean()\n",
    "metrics_temp_df.loc[\"NicheCompass\"][0] - np.max(metrics_temp_df[~metrics_temp_df.index.isin([\"NicheCompass\", \"NicheCompass Light\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb92d69-52e7-4448-b74f-e39bbab30d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"nanoString CosMx Human NSCLC\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"Batch Correction Score\"]].mean()\n",
    "metrics_temp_df.loc[\"NicheCompass\"][0] - np.max(metrics_temp_df[~metrics_temp_df.index.isin([\"NicheCompass\", \"NicheCompass Light\"])])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6ebb8911-d071-4d1b-b784-4e86e241647b",
   "metadata": {},
   "source": [
    "metric = \"blisi\"\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 #\"GraphST (No Prior Alignment)\": \"#b5bd61\",\n",
    "                 \"CellCharter\": \"#F46AA2\",\n",
    "                 \"BANKSY\": \"#556B2F\"}\n",
    "\n",
    "plt.figure(figsize=(fig_width_7_ticks, fig_height))\n",
    "ax = sns.barplot(data=summary_df,\n",
    "                 x=metric,\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette\n",
    "                )\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + 1 * i, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(metric.upper(), fontsize=fontsize)\n",
    "plt.yticks(fontsize=row_fontsize)\n",
    "plt.xticks([0, 0.1, 0.2, 0.3, 0.4, 0.5], fontsize=fontsize)\n",
    "plt.xlim(0., 0.6)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_barplot_{metric}_score.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fde867-d43f-413d-931b-3433d2fb9ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"blisi\"  # Metric to plot\n",
    "\n",
    "plt.figure(figsize=(fig_width_7_ticks, fig_height))  # Adjust figure size\n",
    "\n",
    "# Boxplot\n",
    "ax = sns.boxplot(data=summary_df,\n",
    "                 x=metric,  # Use the variable metric for x-axis\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette,\n",
    "                 showcaps=False,  # Hide caps for cleaner look\n",
    "                 fliersize=0,  # Hide individual outlier markers\n",
    "                 boxprops={'alpha': 0.6},  # Semi-transparent boxes\n",
    "                 whiskerprops={'linewidth': 1.5})  # Thicker whiskers\n",
    "\n",
    "# Add horizontal lines between categories\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + i, color='gray', linestyle='--', linewidth=2, zorder=0)\n",
    "\n",
    "# Overlay with individual points\n",
    "sns.stripplot(data=summary_df,\n",
    "              x=metric,  # Use the variable metric for x-axis\n",
    "              y=\"dataset\",\n",
    "              hue=\"model\",\n",
    "              dodge=True,\n",
    "              palette=model_palette,\n",
    "              alpha=0.6,  # Transparent points\n",
    "              size=5,  # Adjust dot size\n",
    "              jitter=0.2,  # Slight jitter for better separation\n",
    "              edgecolor=\"black\",  # Add edge color\n",
    "              linewidth=0.5)\n",
    "\n",
    "# Add gridlines\n",
    "ax.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adjust legend to avoid duplication\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[:len(model_palette)], labels[:len(model_palette)],\n",
    "          loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Adjust axes and labels\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(metric.upper(), fontsize=fontsize)  # Convert metric name to uppercase\n",
    "plt.yticks(fontsize=fontsize)\n",
    "plt.xticks(fontsize=fontsize)  # Adjust ticks for the range\n",
    "plt.xlim(0., 0.6)  # Set range to [0., 0.6]\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_boxplot_{metric}_score.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9b778e5a-0f1c-4aab-9973-8eb20970bff6",
   "metadata": {},
   "source": [
    "metric = \"pcr\"\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 #\"GraphST (No Prior Alignment)\": \"#b5bd61\",\n",
    "                 \"CellCharter\": \"#F46AA2\",\n",
    "                 \"BANKSY\": \"#556B2F\"}\n",
    "\n",
    "plt.figure(figsize=(fig_width_10_ticks, fig_height))\n",
    "ax = sns.barplot(data=summary_df,\n",
    "                 x=metric,\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette\n",
    "                )\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + 1 * i, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(metric.upper(), fontsize=fontsize)\n",
    "plt.yticks(fontsize=row_fontsize)\n",
    "plt.xticks([0., 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], fontsize=fontsize)\n",
    "plt.xlim(0., 1.0)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_barplot_{metric}_score.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7325d1a0-6b13-43ee-abf8-70342b975aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"pcr\"  # Metric to plot\n",
    "\n",
    "plt.figure(figsize=(fig_width_10_ticks, fig_height))  # Adjust figure size\n",
    "\n",
    "# Boxplot\n",
    "ax = sns.boxplot(data=summary_df,\n",
    "                 x=metric,  # Use the variable metric for x-axis\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette,\n",
    "                 showcaps=False,  # Hide caps for cleaner look\n",
    "                 fliersize=0,  # Hide individual outlier markers\n",
    "                 boxprops={'alpha': 0.6},  # Semi-transparent boxes\n",
    "                 whiskerprops={'linewidth': 1.5})  # Thicker whiskers\n",
    "\n",
    "# Add horizontal lines between categories\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + i, color='gray', linestyle='--', linewidth=2, zorder=0)\n",
    "\n",
    "# Overlay with individual points\n",
    "sns.stripplot(data=summary_df,\n",
    "              x=metric,  # Use the variable metric for x-axis\n",
    "              y=\"dataset\",\n",
    "              hue=\"model\",\n",
    "              dodge=True,\n",
    "              palette=model_palette,\n",
    "              alpha=0.6,  # Transparent points\n",
    "              size=5,  # Adjust dot size\n",
    "              jitter=0.2,  # Slight jitter for better separation\n",
    "              edgecolor=\"black\",  # Add edge color\n",
    "              linewidth=0.5)\n",
    "\n",
    "# Add gridlines\n",
    "ax.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adjust legend to avoid duplication\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[:len(model_palette)], labels[:len(model_palette)],\n",
    "          loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Adjust axes and labels\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(metric.upper(), fontsize=fontsize)  # Convert metric name to uppercase\n",
    "plt.yticks(fontsize=fontsize)\n",
    "plt.xticks(fontsize=fontsize)  # Adjust ticks for the range\n",
    "plt.xlim(0., 1.0)  # Set range to [0., 1.0]\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_boxplot_{metric}_score.svg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f559066d-1179-4254-bcf2-5dfdb920738c",
   "metadata": {},
   "source": [
    "## sns.set_style(\"whitegrid\")\n",
    "\n",
    "model_palette = {\"NicheCompass\": \"#8C96C6\",\n",
    "                 \"NicheCompass Light\": \"#42B6C7\",\n",
    "                 \"STACI\": \"#FFD700\",\n",
    "                 \"GraphST\": \"#D78FF8\",\n",
    "                 #\"GraphST (No Prior Alignment)\": \"#b5bd61\",\n",
    "                 \"CellCharter\": \"#F46AA2\",\n",
    "                 \"BANKSY\": \"#556B2F\"}\n",
    "\n",
    "plt.figure(figsize=(fig_width_6_ticks*0.85, fig_height))\n",
    "ax = sns.barplot(data=summary_df,\n",
    "                 x=\"Overall Score\",\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette\n",
    "                )\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + 1 * i, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(\"Overall Score\", fontsize=fontsize)\n",
    "plt.yticks(fontsize=row_fontsize)\n",
    "#plt.xticks([0.3, 0.4, 0.5, 0.6], fontsize=fontsize)\n",
    "plt.xlim(0.1, 0.7)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_barplot_overall_score.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234ac1bc-8b44-477a-a8bf-a66cdcb6af7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(fig_width_7_ticks * 0.85, fig_height))  # Adjust figure size\n",
    "\n",
    "# Boxplot\n",
    "ax = sns.boxplot(data=summary_df,\n",
    "                 x=\"Overall Score\",  # Use \"Overall Score\" as the x-axis metric\n",
    "                 y=\"dataset\",\n",
    "                 hue=\"model\",\n",
    "                 orient=\"h\",\n",
    "                 palette=model_palette,\n",
    "                 showcaps=False,  # Hide caps for cleaner look\n",
    "                 fliersize=0,  # Hide individual outlier markers\n",
    "                 boxprops={'alpha': 0.6},  # Semi-transparent boxes\n",
    "                 whiskerprops={'linewidth': 1.5})  # Thicker whiskers\n",
    "\n",
    "# Add horizontal lines between categories\n",
    "for i in range(summary_df[\"dataset\"].nunique()):\n",
    "    ax.axhline(0.5 + i, color='gray', linestyle='--', linewidth=2, zorder=0)\n",
    "\n",
    "# Overlay with individual points\n",
    "sns.stripplot(data=summary_df,\n",
    "              x=\"Overall Score\",  # Use \"Overall Score\" for the x-axis\n",
    "              y=\"dataset\",\n",
    "              hue=\"model\",\n",
    "              dodge=True,\n",
    "              palette=model_palette,\n",
    "              alpha=0.6,  # Transparent points\n",
    "              size=5,  # Adjust dot size\n",
    "              jitter=0.2,  # Slight jitter for better separation\n",
    "              edgecolor=\"black\",  # Add edge color\n",
    "              linewidth=0.5)\n",
    "\n",
    "# Add gridlines\n",
    "ax.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adjust legend to avoid duplication\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[:len(model_palette)], labels[:len(model_palette)],\n",
    "          loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Adjust axes and labels\n",
    "new_labels = [label.get_text().replace(' ', '\\n') if i < 3 else label.get_text().replace(' H', '\\nH', -1).replace(' N', '\\nN', -1).replace(' CosMx', '\\nCosMx', -1) for i, label in enumerate(ax.get_yticklabels())]\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_yticklabels(new_labels)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(\"Overall Score\", fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "plt.xticks(fontsize=fontsize)  # Adjust ticks for the range\n",
    "plt.xlim(0.1, 0.8)  # Set range to [0.1, 0.7]\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{benchmarking_folder_path}/benchmarking_boxplot_overall_score.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195eab1e-3244-4396-af83-7a8066ee7aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"seqFISH Mouse Organogenesis\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"Overall Score\"]].mean()\n",
    "metrics_temp_df.loc[\"NicheCompass\"][0] - np.max(metrics_temp_df[~metrics_temp_df.index.isin([\"NicheCompass\", \"NicheCompass Light\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50c554b-6b22-4cad-9251-34cdbe8952d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"seqFISH Mouse Organogenesis (Imputed)\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"Overall Score\"]].mean()\n",
    "metrics_temp_df.loc[\"NicheCompass\"][0] - np.max(metrics_temp_df[~metrics_temp_df.index.isin([\"NicheCompass\", \"NicheCompass Light\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6944647f-95e4-443c-9932-86901f220d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = summary_df[summary_df[\"dataset\"] == \"nanoString CosMx Human NSCLC\"]\n",
    "metrics_temp_df = temp_df.groupby(\"model\")[[\"Overall Score\"]].mean()\n",
    "metrics_temp_df.loc[\"NicheCompass\"][0] - np.max(metrics_temp_df[~metrics_temp_df.index.isin([\"NicheCompass\", \"NicheCompass Light\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5751cab8-6cf1-4197-b830-07cf0a2fc982",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supplementary fig. 17: gene scalability analysis ###\n",
    "size_dict = {}\n",
    "size_dict[\"dataset\"] = [] \n",
    "size_dict[\"n_genes\"] = []\n",
    "size_dict[\"n_gps\"] = []\n",
    "size_dict[\"n_params\"] = []\n",
    "\n",
    "model_label = \"gatv2conv_sample_integration_method_benchmarking\"\n",
    "run = \"run1\"\n",
    "\n",
    "for dataset, timestamp in zip(\n",
    "    [\"seqfish_mouse_organogenesis\", # 256 edge batch size\n",
    "     \"seqfish_mouse_organogenesis_imputed\", # 2048 edge batch size\n",
    "     \"nanostring_cosmx_human_nsclc\"], # 512 edge batch size\n",
    "    [\"22082023_184821_1\",\n",
    "     \"28082023_181323_1\",\n",
    "     \"21082023_190305_1\"]):\n",
    "\n",
    "    model_folder_path = f\"{artifact_folder_path}/{dataset}/models/{model_label}/{timestamp}/{run}\"\n",
    "    model = NicheCompass.load(dir_path=model_folder_path,\n",
    "                              adata=None,\n",
    "                              adata_file_name=f\"{dataset}_{model_label}.h5ad\",\n",
    "                              gp_names_key=\"nichecompass_gp_names\")\n",
    "\n",
    "    size_dict[\"dataset\"].append(dataset)\n",
    "    size_dict[\"n_genes\"].append(len(model.adata.var))\n",
    "    size_dict[\"n_gps\"].append(model.adata.obsm[\"nichecompass_latent\"].shape[1])\n",
    "    size_dict[\"n_params\"].append(sum(p.numel() for p in model.model.parameters()))\n",
    "    \n",
    "size_df = pd.DataFrame(size_dict)\n",
    "size_df.to_csv(f\"{benchmarking_folder_path}/model_sizes.csv\", index=False)\n",
    "size_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a26e90f-0474-4cb1-9502-be5f99e25a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_df = pd.read_csv(f\"{benchmarking_folder_path}/model_sizes.csv\")\n",
    "\n",
    "size_df.columns = [\"Dataset\", \"Number of Genes\", \"Number of GPs\", \"Number of Params\"]\n",
    "\n",
    "size_df[\"Dataset\"].replace({\"seqfish_mouse_organogenesis\": \"seqFISH Mouse Organogenesis\",\n",
    "                            \"seqfish_mouse_organogenesis_imputed\": \"seqFISH Mouse Organogenesis (Imputed)\",\n",
    "                            \"nanostring_cosmx_human_nsclc\": \"Nanostring CosMx Human NSCLC\"}, inplace=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 2))\n",
    "ax.axis('off')\n",
    "ax.axis('tight')\n",
    "table = ax.table(cellText=size_df.values,\n",
    "                 colLabels=size_df.columns,\n",
    "                 cellLoc='center',\n",
    "                 loc='center',\n",
    "                 colColours=[\"lightblue\"] + [\"darkgrey\"]*(len(size_df.columns) -1))\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(14)\n",
    "table.scale(2.2, 2.)\n",
    "plt.savefig(f\"{benchmarking_folder_path}/model_sizes.svg\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00a0302-c715-402d-b1e1-adfeb372c5f6",
   "metadata": {},
   "source": [
    "## 3. Compute Metrics on Analysis Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec63af7-6b2e-45b6-a8c1-3f195fe372c6",
   "metadata": {},
   "source": [
    "### 3.1 Xenium Human Breast Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d550884-d17a-47b4-9c6b-4a951fbd7302",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"xenium_human_breast_cancer\"\n",
    "timestamp = \"26102023_153021\"\n",
    "model_label = \"reference\"\n",
    "model_folder_path = f\"{artifact_folder_path}/{dataset}/models/{model_label}/{timestamp}\"\n",
    "metrics = \"gcs mlami cas clisis nasw cnmi cari casw clisi blisi pcr\"\n",
    "cell_type_key = \"cell_type\"\n",
    "batch_key = \"batch\"\n",
    "spatial_key = \"spatial\"\n",
    "latent_key = \"nichecompass_latent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e5424a-e76d-463c-9407-e51574af5f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NicheCompass.load(dir_path=model_folder_path,\n",
    "                          adata=None,\n",
    "                          adata_file_name=f\"{dataset}_{model_label}.h5ad\",\n",
    "                          gp_names_key=\"nichecompass_gp_names\")\n",
    "\n",
    "if dataset == \"xenium_human_breast_cancer\":\n",
    "    model.adata.obs[\"batch\"] = model.adata.obs[\"batch\"].replace({\"sample1\": \"Replicate 1\", \"sample2\": \"Replicate 2\"})\n",
    "    \n",
    "    trans_from=[['Epi_ABCC11+', 'Epi_FOXA1+', 'Epi_AGR3+', 'Epi_CENPF+', 'mgEpi_KRT14+', 'Epi_KRT14+'],['EC_CLEC14A+', 'EC_CAVIN2+'],['adipo_FB', 'GJB2+iKC-FB'],['EMT-Epi1_CEACAM6+', 'EMT-Epi2_CEACAM6+', 'EMT-Epi_SERPINA3+', 'EMT-Epi_KRT23+'],['DERL3+B', 'BANK1+B', 'B'],['eff_CD8+T1', 'eff_CD8+T2',],['tcm_CD4+T', 'CD161+FOXP3+T'],['NK/T'],['ADIPOQ+Mast'],['M2M', 'MMP12+miM'], ['DC1']]\n",
    "    trans_to = ['Epithelial', 'Endothelial', 'Fibroblast', 'EMT', 'B_cells', 'CD8+T', 'CD4+T', 'NK/T', 'Mast', 'M', 'DC']\n",
    "\n",
    "    model.adata.obs['cell_type'] = [str(i) for i in model.adata.obs['cell_states']]\n",
    "    for leiden,celltype in zip(trans_from, trans_to):\n",
    "        for leiden_from in leiden:\n",
    "            model.adata.obs['cell_type'][model.adata.obs['cell_type'] == leiden_from] = celltype\n",
    "            \n",
    "    model.adata.obs[cell_type_key] = model.adata.obs[cell_type_key].replace(\"M\", \"M\")\n",
    "    model.adata.obs[\"cell_states\"] = model.adata.obs[\"cell_states\"].replace(\"M2M\", \"M2M\").replace(\"MMP12+miM\", \"MMP12+miM\")\n",
    "    \n",
    "model.adata.obs[cell_type_key] = model.adata.obs[cell_type_key].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4936d88f-7989-4401-a505-209eab90e61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"pcr\" in metrics:\n",
    "    sc.tl.pca(model.adata, use_highly_variable=False)\n",
    "    pcr_X_pre = model.adata.obsm[\"X_pca\"]\n",
    "else:\n",
    "    pcr_X_pre = None\n",
    "\n",
    "benchmark_dict = compute_benchmarking_metrics(\n",
    "        adata=model.adata,\n",
    "        metrics=metrics,\n",
    "        cell_type_key=cell_type_key,\n",
    "        batch_key=batch_key,\n",
    "        spatial_key=spatial_key,\n",
    "        latent_key=latent_key,\n",
    "        pcr_X_pre=pcr_X_pre,\n",
    "        n_jobs=1,\n",
    "        seed=0,\n",
    "        mlflow_experiment_id=None)\n",
    "\n",
    "benchmark_df = pd.DataFrame(benchmark_dict.values(), index=benchmark_dict.keys()).T\n",
    "benchmark_df.to_csv(f\"{benchmarking_folder_path}/{dataset}_metrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d5ff0b-1cfe-4bc8-9991-5c3d79d65cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
